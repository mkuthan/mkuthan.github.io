---
title: "Apache Beam SQL"
date: 2022-09-14
categories: []
tagline: ""
header:
    overlay_image: /assets/images/mj-tangonan-wKfTNWaDYgs-unsplash.webp
    overlay_filter: 0.2
---

Beam 2.38.0 (see: https://github.com/apache/beam/issues/22615).

Build Apache Beam SQL shell:

```shell
.$ /gradlew -p sdks/java/extensions/sql/shell \
    -Pbeam.sql.shell.bundled=':sdks:java:io:google-cloud-platform,:runners:google-cloud-dataflow-java' \
    installDist
(...)
BUILD SUCCESSFUL in 22s
88 actionable tasks: 43 executed, 35 from cache, 10 up-to-date
```

Create Pubsub topics:

```shell
$ gcloud pubsub topics create marcin-atm22-stream-1
Created topic [projects/sc-9366-nga-dev/topics/marcin-atm22-stream-1].
$ gcloud pubsub topics create marcin-atm22-stream-2
Created topic [projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2].
```

Generator:

```python
import argparse
import json
from datetime import datetime, timezone, timedelta
from random import random
from time import sleep

from google.cloud import pubsub_v1


def generate_event(delay):
    ts = datetime.now(tz=timezone.utc) - timedelta(seconds=delay)
    return {
        'ts': ts.isoformat(timespec='seconds'),
        'val': round(random(), 2)
    }


def publish_event(publisher, topic, event):
    data = json.dumps(event).encode('utf-8')
    publisher.publish(topic, data=data, ts=event['ts'])


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--topic', required=True)
    parser.add_argument("--delay", default=0, type=int)
    args = parser.parse_args()

    publisher = pubsub_v1.PublisherClient()

    while True:
        event = generate_event(args.delay)
        print(event)
        publish_event(publisher, args.topic, event)
        sleep(1)
```

Run generator for topic `stream-1`:

```
$ python generator.py --topic projects/sc-9366-nga-dev/topics/marcin-atm22-stream-1
{'ts': '2022-08-07T10:28:28+00:00', 'val': 0.69}
{'ts': '2022-08-07T10:28:29+00:00', 'val': 0.67}
{'ts': '2022-08-07T10:28:30+00:00', 'val': 0.89}
(...)
```

Run generator for topic `stream-2`:

```
$ python generator.py --topic projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2
{'ts': '2022-08-07T10:29:28+00:00', 'val': 0.53}
{'ts': '2022-08-07T10:29:29+00:00', 'val': 0.76}
{'ts': '2022-08-07T10:29:30+00:00', 'val': 0.94}
(...)
```

Run Apache Beam SQL shell:

```shell
$ ./sdks/java/extensions/sql/shell/build/install/shell/bin/shell
Welcome to Beam SQL 2.38.0-SNAPSHOT (based on sqlline version 1.4.0)
0: BeamSQL> !tables
+-----------+-------------+------------+--------------+---------+----------+------------+-----------+---------------------------+----------------+
| TABLE_CAT | TABLE_SCHEM | TABLE_NAME | TABLE_TYPE   | REMARKS | TYPE_CAT | TYPE_SCHEM | TYPE_NAME | SELF_REFERENCING_COL_NAME | REF_GENERATION |
+-----------+-------------+------------+--------------+---------+----------+------------+-----------+---------------------------+----------------+
|           | metadata    | COLUMNS    | SYSTEM TABLE |         |          |            |           |                           |                |
|           | metadata    | TABLES     | SYSTEM TABLE |         |          |            |           |                           |                |
+-----------+-------------+------------+-----------  -+---------+----------+------------+-----------+---------------------------+----------------+
0: BeamSQL> !quit
Closing: org.apache.beam.sdk.extensions.sql.impl.JdbcConnection
```

Create external table for topics:

```shell
0: BeamSQL> CREATE EXTERNAL TABLE stream1 (event_timestamp TIMESTAMP, attributes MAP<VARCHAR, VARCHAR>, payload ROW<ts TIMESTAMP, val DOUBLE>)
. . . . . > TYPE pubsub
. . . . . > LOCATION 'projects/sc-9366-nga-dev/topics/marcin-atm22-stream-1'
. . . . . > TBLPROPERTIES  '{"format": "json", "timestampAttributeKey":"ts"}';
No rows affected (0.819 seconds)
0: BeamSQL> CREATE EXTERNAL TABLE stream2 (event_timestamp TIMESTAMP, attributes MAP<VARCHAR, VARCHAR>, payload ROW<ts TIMESTAMP, val DOUBLE>)
. . . . . > TYPE pubsub
. . . . . > LOCATION 'projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2'
. . . . . > TBLPROPERTIES  '{"format": "json", "timestampAttributeKey":"ts"}';
No rows affected (0.019 seconds)
```

Test external tables:

```shell
0: BeamSQL> SELECT current_timestamp, event_timestamp, stream1.payload.ts, stream1.payload.val FROM stream1 LIMIT 5;
+---------------------+---------------------+---------------------+------+
| current_timestamp   | event_timestamp     |   ts                | val  |
+---------------------+---------------------+---------------------+------+
| 2022-08-07 10:39:13 | 2022-08-07 10:39:07 | 2022-08-07 10:39:07 | 0.14 |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:05 | 2022-08-07 10:39:05 | 0.2  |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:09 | 2022-08-07 10:39:09 | 0.05 |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:08 | 2022-08-07 10:39:08 | 0.95 |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:01 | 2022-08-07 10:39:01 | 0.63 |
+---------------------+---------------------+---------------------+------+
5 rows selected (26.292 seconds)
0: BeamSQL> SELECT current_timestamp, event_timestamp, stream2.payload.ts, stream2.payload.val FROM stream2 LIMIT 5;
+---------------------+---------------------+---------------------+------+
| current_timestamp   | event_timestamp     |   ts                | val  |
+---------------------+---------------------+---------------------+------+
| 2022-08-07 10:42:52 | 2022-08-07 10:42:49 | 2022-08-07 10:42:49 | 0.99 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:50 | 2022-08-07 10:42:50 | 0.36 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:47 | 2022-08-07 10:42:47 | 0.78 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:48 | 2022-08-07 10:42:48 | 0.52 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:40 | 2022-08-07 10:42:40 | 0.72 |
+---------------------+---------------------+---------------------+------+
5 rows selected (16.239 seconds)
```

Create table definition for the results:

```shell
0: BeamSQL> CREATE EXTERNAL TABLE results (created_at TIMESTAMP, window_start TIMESTAMP, window_end TIMESTAMP, samples INT, value_max DOUBLE)
. . . . . > TYPE bigquery
. . . . . > LOCATION 'sc-9366-nga-dev:marcin_atm22.results';
No rows affected (0.013 seconds)
```

Check the schema (fragment):

```shell
0: BeamSQL> !describe results
+-----------+-------------+------------+--------------+-----------+--------------+
| TABLE_CAT | TABLE_SCHEM | TABLE_NAME | COLUMN_NAME  | DATA_TYPE | TYPE_NAME    |
+-----------+-------------+------------+--------------+-----------+--------------+
|           | beam        | results    | created_at   | 93        | TIMESTAMP(6) |
|           | beam        | results    | window_start | 93        | TIMESTAMP(6) |
|           | beam        | results    | window_end   | 93        | TIMESTAMP(6) |
|           | beam        | results    | samples      | 4         | INTEGER      |
|           | beam        | results    | value_max    | 8         | DOUBLE       |
+-----------+-------------+------------+--------------+-----------+--------------+
```

Check the table (does not exist yet):

```shell
0: BeamSQL> select count(*) from results;
Error: Error while executing SQL "select count(*) from results": com.google.api.gax.rpc.NotFoundException: io.grpc.StatusRuntimeException: NOT_FOUND: Not found: Table sc-9366-nga-dev:marcin_atm22.results (state=,code=0)
```

Change runner to Dataflow runner:

```shell
0: BeamSQL> SET runner = DataflowRunner;
No rows affected (0.017 seconds)
0: BeamSQL> set region = 'europe-west1';
No rows affected (0.004 seconds)
0: BeamSQL> set gcpTempLocation = 'gs://sc-9366-nga-dev-marcin/tmp';
No rows affected (0.015 seconds)
```

The query:

```sql
SELECT 
    CURRENT_TIMESTAMP, s1.window_start, s1.window_end, 
    s1.samples + COALESCE(s2.samples, 0), 
    (s1.value_max + COALESCE(s2.value_max, s1.value_max)) / 2
FROM (
    SELECT
        TUMBLE_START(event_timestamp, INTERVAL '5' SECOND) AS window_start,
        TUMBLE_END(event_timestamp, INTERVAL '5' SECOND) AS window_end,
        MAX(stream1.payload.val) AS value_max,
        COUNT(*) AS samples
    FROM stream1
    GROUP BY TUMBLE(event_timestamp, INTERVAL '5' SECOND)) s1
RIGHT OUTER JOIN (
    SELECT
        TUMBLE_START(event_timestamp, INTERVAL '5' SECOND) AS window_start,
        TUMBLE_END(event_timestamp, INTERVAL '5' SECOND) AS window_end,
        MAX(stream2.payload.val) AS value_max,
        COUNT(*) AS samples
    FROM stream2
    GROUP BY TUMBLE(event_timestamp, INTERVAL '5' SECOND)) s2
ON s1.window_start = s2.window_start AND s1.window_end = s2.window_end 
```

Execute final query:

```shell
0: BeamSQL> INSERT INTO results
. . . . . > SELECT (...);
(...)
INFO: To cancel the job using the 'gcloud' tool, run:
> gcloud dataflow jobs --project=sc-9366-nga-dev cancel --region=europe-west1 2022-08-07_04_04_14-1079245398928473428
No rows affected (26.455 seconds)
```

Check the results again using DirectRunner:

```shell
0: BeamSQL> SET runner = DirectRunner;
No rows affected (0.017 seconds)
0: BeamSQL> SELECT COUNT(*) FROM results;
+---------------------+
|       EXPR$0        |
+---------------------+
| 128                 |
+---------------------+
1 row selected (6.868 seconds)
0: BeamSQL> SELECT * FROM results ORDER BY created_at DESC LIMIT 5;
+---------------------+---------------------+---------------------+------------+-----------------+
| created_at          | window_start        | window_end          |  samples   |    value_max    |
+---------------------+---------------------+---------------------+------------+-----------------+
| 2022-08-07 11:17:35 | 2022-08-07 11:17:10 | 2022-08-07 11:17:15 | 10         | 0.94            |
| 2022-08-07 11:17:35 | 2022-08-07 11:17:05 | 2022-08-07 11:17:10 | 10         | 0.76            |
| 2022-08-07 11:17:27 | 2022-08-07 11:17:00 | 2022-08-07 11:17:05 | 10         | 0.9099999999999 |
| 2022-08-07 11:17:19 | 2022-08-07 11:16:55 | 2022-08-07 11:17:00 | 10         | 0.825           |
| 2022-08-07 11:17:19 | 2022-08-07 11:16:50 | 2022-08-07 11:16:55 | 10         | 0.915           |
+---------------------+---------------------+---------------------+------------+-----------------+
5 rows selected (4.314 seconds) 
```

Stop the job:

```shell
$ gcloud dataflow jobs --project=sc-9366-nga-dev cancel --region=europe-west1 2022-08-07_04_04_14-1079245398928473428
Cancelled job [2022-08-07_04_04_14-1079245398928473428]
```

