---
title: "Apache Beam SQL"
date: 2022-09-14
categories: [Stream Processing, Apache Beam, SQL, GCP, Dataflow]
tagline: ""
header:
    overlay_image: /assets/images/marek-piwnicki-6GF7BeT8g30-unsplash.webp
    overlay_filter: 0.2
---

Checkout Apache Beam 2.38.0 (see: https://github.com/apache/beam/issues/22615).

Build Apache Beam SQL shell:

```shell
$ ./gradlew -p sdks/java/extensions/sql/shell \
    -Pbeam.sql.shell.bundled=':sdks:java:io:google-cloud-platform,:runners:google-cloud-dataflow-java' \
    installDist
(...)
BUILD SUCCESSFUL in 22s
88 actionable tasks: 43 executed, 35 from cache, 10 up-to-date
```

Create Pubsub topics:

```shell
$ gcloud pubsub topics create marcin-atm22-stream-1
Created topic [projects/sc-9366-nga-dev/topics/marcin-atm22-stream-1].
$ gcloud pubsub topics create marcin-atm22-stream-2
Created topic [projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2].
```

Synthetic data generator:

```python
import argparse
import json
from datetime import datetime, timezone, timedelta
from random import random
from time import sleep

from google.cloud import pubsub_v1


def generate_event(delay):
    ts = datetime.now(tz=timezone.utc) - timedelta(seconds=delay)
    return {
        'ts': ts.isoformat(timespec='seconds'),
        'val': round(random(), 2)
    }


def publish_event(publisher, topic, event):
    data = json.dumps(event).encode('utf-8')
    publisher.publish(topic, data=data, ts=event['ts'])


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--topic', required=True)
    parser.add_argument("--delay", default=0, type=int)
    args = parser.parse_args()

    publisher = pubsub_v1.PublisherClient()

    while True:
        event = generate_event(args.delay)
        print(event)
        publish_event(publisher, args.topic, event)
        sleep(1)
```

Run Apache Beam SQL shell:

```shell
$ ./sdks/java/extensions/sql/shell/build/install/shell/bin/shell
Welcome to Beam SQL 2.38.0-SNAPSHOT (based on sqlline version 1.4.0)
0: BeamSQL> !tables
+-----------+-------------+------------+--------------+---------+----------+------------+-----------+---------------------------+----------------+
| TABLE_CAT | TABLE_SCHEM | TABLE_NAME | TABLE_TYPE   | REMARKS | TYPE_CAT | TYPE_SCHEM | TYPE_NAME | SELF_REFERENCING_COL_NAME | REF_GENERATION |
+-----------+-------------+------------+--------------+---------+----------+------------+-----------+---------------------------+----------------+
|           | metadata    | COLUMNS    | SYSTEM TABLE |         |          |            |           |                           |                |
|           | metadata    | TABLES     | SYSTEM TABLE |         |          |            |           |                           |                |
+-----------+-------------+------------+-----------  -+---------+----------+------------+-----------+---------------------------+----------------+
0: BeamSQL> !quit
Closing: org.apache.beam.sdk.extensions.sql.impl.JdbcConnection
```

Create external table for topics:

```shell
0: BeamSQL> CREATE EXTERNAL TABLE stream1 (event_timestamp TIMESTAMP, attributes MAP<VARCHAR, VARCHAR>, payload ROW<ts TIMESTAMP, val DOUBLE>)
. . . . . > TYPE pubsub
. . . . . > LOCATION 'projects/sc-9366-nga-dev/topics/marcin-atm22-stream-1'
. . . . . > TBLPROPERTIES '{"format": "json", "timestampAttributeKey":"ts"}';
No rows affected (0.819 seconds)
0: BeamSQL> CREATE EXTERNAL TABLE stream2 (event_timestamp TIMESTAMP, attributes MAP<VARCHAR, VARCHAR>, payload ROW<ts TIMESTAMP, val DOUBLE>)
. . . . . > TYPE pubsub
. . . . . > LOCATION 'projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2'
. . . . . > TBLPROPERTIES '{"format": "json", "timestampAttributeKey":"ts"}';
No rows affected (0.019 seconds)
```

Test external tables:

```shell
0: BeamSQL> SELECT current_timestamp, event_timestamp, stream1.payload.ts, stream1.payload.val FROM stream1 LIMIT 5;
+---------------------+---------------------+---------------------+------+
| current_timestamp   | event_timestamp     |   ts                | val  |
+---------------------+---------------------+---------------------+------+
| 2022-08-07 10:39:13 | 2022-08-07 10:39:07 | 2022-08-07 10:39:07 | 0.14 |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:05 | 2022-08-07 10:39:05 | 0.2  |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:09 | 2022-08-07 10:39:09 | 0.05 |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:08 | 2022-08-07 10:39:08 | 0.95 |
| 2022-08-07 10:39:13 | 2022-08-07 10:39:01 | 2022-08-07 10:39:01 | 0.63 |
+---------------------+---------------------+---------------------+------+
5 rows selected (26.292 seconds)
0: BeamSQL> SELECT current_timestamp, event_timestamp, stream2.payload.ts, stream2.payload.val FROM stream2 LIMIT 5;
+---------------------+---------------------+---------------------+------+
| current_timestamp   | event_timestamp     |   ts                | val  |
+---------------------+---------------------+---------------------+------+
| 2022-08-07 10:42:52 | 2022-08-07 10:42:49 | 2022-08-07 10:42:49 | 0.99 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:50 | 2022-08-07 10:42:50 | 0.36 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:47 | 2022-08-07 10:42:47 | 0.78 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:48 | 2022-08-07 10:42:48 | 0.52 |
| 2022-08-07 10:42:52 | 2022-08-07 10:42:40 | 2022-08-07 10:42:40 | 0.72 |
+---------------------+---------------------+---------------------+------+
5 rows selected (16.239 seconds)
```

Create external table for the results:

```shell
0: BeamSQL> CREATE EXTERNAL TABLE results (created_at TIMESTAMP, window_start TIMESTAMP, window_end TIMESTAMP, samples INT, avg_diff DOUBLE)
. . . . . > TYPE bigquery
. . . . . > LOCATION 'sc-9366-nga-dev:marcin_atm22.results'
. . . . . > TBLPROPERTIES '{"writeDisposition": "WRITE_TRUNCATE"}';
No rows affected (0.013 seconds)
```

Check the table schema (fragment):

```shell
0: BeamSQL> !describe results
+-----------+-------------+------------+--------------+-----------+--------------+
| TABLE_CAT | TABLE_SCHEM | TABLE_NAME | COLUMN_NAME  | DATA_TYPE | TYPE_NAME    |
+-----------+-------------+------------+--------------+-----------+--------------+
|           | beam        | results    | created_at   | 93        | TIMESTAMP(6) |
|           | beam        | results    | window_start | 93        | TIMESTAMP(6) |
|           | beam        | results    | window_end   | 93        | TIMESTAMP(6) |
|           | beam        | results    | samples      | 4         | INTEGER      |
|           | beam        | results    | avg_diff     | 8         | DOUBLE       |
+-----------+-------------+------------+--------------+-----------+--------------+
```

Try to query the table (table will be created just before first insert):

```shell
0: BeamSQL> select count(*) from results;
Error: Error while executing SQL "select count(*) from results": com.google.api.gax.rpc.NotFoundException: io.grpc.StatusRuntimeException: NOT_FOUND: Not found: Table sc-9366-nga-dev:marcin_atm22.results (state=,code=0)
```

Change runner to Dataflow:

```shell
0: BeamSQL> SET runner = DataflowRunner;
No rows affected (0.017 seconds)
0: BeamSQL> set region = 'europe-west1';
No rows affected (0.004 seconds)
0: BeamSQL> set gcpTempLocation = 'gs://sc-9366-nga-dev-marcin/tmp';
No rows affected (0.015 seconds)
```

The query:

* Calculate AVG using 5 seconds tumble window for both streams
* Join `stream-2` into `stream-1` and calculate difference between averages
* If `stream-2` is not available fallback to scenario with `stream-1` only data

```sql
SELECT 
    CURRENT_TIMESTAMP, s1.window_start, s1.window_end, 
    s1.samples + COALESCE(s2.samples, 0),
    s1.value_avg - COALESCE(s2.value_avg, 0.0)       
FROM (
    SELECT
        TUMBLE_START(event_timestamp, INTERVAL '5' SECOND) AS window_start,
        TUMBLE_END(event_timestamp, INTERVAL '5' SECOND) AS window_end,
        AVG(stream1.payload.val) AS value_avg,
        COUNT(*) AS samples
    FROM stream1
    GROUP BY TUMBLE(event_timestamp, INTERVAL '5' SECOND)) s1
LEFT OUTER JOIN (
    SELECT
        TUMBLE_START(event_timestamp, INTERVAL '5' SECOND) AS window_start,
        TUMBLE_END(event_timestamp, INTERVAL '5' SECOND) AS window_end,
        AVG(stream2.payload.val) AS value_avg,
        COUNT(*) AS samples
    FROM stream2
    GROUP BY TUMBLE(event_timestamp, INTERVAL '5' SECOND)) s2
ON s1.window_start = s2.window_start AND s1.window_end = s2.window_end 
```

Execute final query:

```shell
0: BeamSQL> INSERT INTO results
. . . . . > SELECT
. . . . . >     CURRENT_TIMESTAMP, s1.window_start, s1.window_end,
. . . . . >     s1.samples + COALESCE(s2.samples, 0),
. . . . . >     CASE WHEN s1.value_min <= COALESCE(s2.value_min, 1.0) THEN s1.value_min ELSE s2.value_min END,
. . . . . >     CASE WHEN s1.value_max >= COALESCE(s2.value_max, 0.0) THEN s1.value_max ELSE s2.value_max END
. . . . . > FROM (
. . . . . >     SELECT
. . . . . >         TUMBLE_START(event_timestamp, INTERVAL '5' SECOND) AS window_start,
. . . . . >         TUMBLE_END(event_timestamp, INTERVAL '5' SECOND) AS window_end,
. . . . . >         MIN(stream1.payload.val) AS value_min,
. . . . . >         MAX(stream1.payload.val) AS value_max,
. . . . . >         COUNT(*) AS samples
. . . . . >     FROM stream1
. . . . . >     GROUP BY TUMBLE(event_timestamp, INTERVAL '5' SECOND)) s1
. . . . . > LEFT OUTER JOIN (
. . . . . >     SELECT
. . . . . >         TUMBLE_START(event_timestamp, INTERVAL '5' SECOND) AS window_start,
. . . . . >         TUMBLE_END(event_timestamp, INTERVAL '5' SECOND) AS window_end,
. . . . . >         MIN(stream2.payload.val) AS value_min,
. . . . . >         MAX(stream2.payload.val) AS value_max,
. . . . . >         COUNT(*) AS samples
. . . . . >     FROM stream2
. . . . . >     GROUP BY TUMBLE(event_timestamp, INTERVAL '5' SECOND)) s2
. . . . . > ON s1.window_start = s2.window_start AND s1.window_end = s2.window_end
. . . . . > ;
(...)
Executing pipeline on the Dataflow Service, which will have billing implications related to Google Compute Engine usage and other Google Cloud Services.
To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobs/europe-west1/2022-08-08_11_52_01-1894085106596231231?project=sc-9366-nga-dev
(...)
INFO: To cancel the job using the 'gcloud' tool, run:
> gcloud dataflow jobs --project=sc-9366-nga-dev cancel --region=europe-west1 2022-08-07_04_04_14-1079245398928473428
No rows affected (26.455 seconds)
```

It could take a few minutes until job creates subscriptions and connect to Pubsub. 
In the meantime start data generators for topics `stream-1` and `stream-2`:

```
$ python generator.py --topic projects/sc-9366-nga-dev/topics/marcin-atm22-stream-1
{'ts': '2022-08-07T10:28:28+00:00', 'val': 0.69}
{'ts': '2022-08-07T10:28:29+00:00', 'val': 0.67}
{'ts': '2022-08-07T10:28:30+00:00', 'val': 0.89}
(...)
```

```
$ python generator.py --topic projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2
{'ts': '2022-08-07T10:29:28+00:00', 'val': 0.53}
{'ts': '2022-08-07T10:29:29+00:00', 'val': 0.76}
{'ts': '2022-08-07T10:29:30+00:00', 'val': 0.94}
(...)
```

Examine logical graph:

![Dataflow logical graph](/assets/images/beam_sql_logical_graph.png)

Examine execution graph for data freshness:

![Dataflow execution graph](/assets/images/beam_sql_execution_graph_1.png)

Configure Beam SQL to use Direct runner again:

```shell
0: BeamSQL> SET runner = DirectRunner;
No rows affected (0.017 seconds)
```

Examine the results of the job:

```shell
0: BeamSQL> SELECT
. . . . . >   window_start,
. . . . . >   window_end,
. . . . . >   created_at,
. . . . . >   TIMESTAMPDIFF(SECOND, created_at, window_end) AS delay_secs,
. . . . . >   samples AS no_of_samples,
. . . . . >   ROUND(avg_diff, 2) AS avg_diff
. . . . . > FROM results
. . . . . > ORDER BY window_end DESC
. . . . . > LIMIT 5;
+---------------------+---------------------+---------------------+------------+---------------+----------+
| window_start        | window_end          | created_at          | delay_secs | no_of_samples | avg_diff |
+---------------------+---------------------+---------------------+------------+---------------+----------+
| 2022-08-08 19:07:10 | 2022-08-08 19:07:15 | 2022-08-08 19:07:43 | -28        | 5             | 0.64     |
| 2022-08-08 19:07:05 | 2022-08-08 19:07:10 | 2022-08-08 19:07:36 | -26        | 4             | 0.52     |
| 2022-08-08 19:07:00 | 2022-08-08 19:07:05 | 2022-08-08 19:07:32 | -27        | 5             | 0.26     |
| 2022-08-08 19:06:55 | 2022-08-08 19:07:00 | 2022-08-08 19:07:30 | -30        | 5             | 0.53     |
| 2022-08-08 19:06:50 | 2022-08-08 19:06:55 | 2022-08-08 19:07:22 | -27        | 5             | 0.5      |
+---------------------+---------------------+---------------------+------------+---------------+----------+
```

Start second generator for `stream-2` but within configured delay of 30 seconds:

```shell
python generator.py --topic projects/sc-9366-nga-dev/topics/marcin-atm22-stream-2 --delay 30
```

Examine execution graph for data freshness:

![Dataflow execution graph](/assets/images/beam_sql_execution_graph_2.png)


Examine results:

```shell
TODO
```

Stop all generators for `stream-2` topic, and watch the execution graph:

TODO
TODO

Stop the job:

```shell
$ gcloud dataflow jobs --project=sc-9366-nga-dev cancel --region=europe-west1 2022-08-07_04_04_14-1079245398928473428
Cancelled job [2022-08-07_04_04_14-1079245398928473428]
```
