<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Passionate Developer]]></title>
  <link href="http://mkuthan.github.io/atom.xml" rel="self"/>
  <link href="http://mkuthan.github.io/"/>
  <updated>2017-11-26T21:35:57+00:00</updated>
  <id>http://mkuthan.github.io/</id>
  <author>
    <name><![CDATA[Marcin Kuthan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Kafka Streams DSL vs Processor API]]></title>
    <link href="http://mkuthan.github.io/blog/2017/11/02/kafka-streams-dsl-vs-processor-api/"/>
    <updated>2017-11-02T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2017/11/02/kafka-streams-dsl-vs-processor-api</id>
    <content type="html"><![CDATA[<p><a href="https://docs.confluent.io/current/streams/index.html">Kafka Streams</a> is a Java library
for building real-time, highly scalable, fault tolerant, distributed applications.
The library is fully integrated with <a href="https://kafka.apache.org/documentation/">Kafka</a> and leverages
Kafka producer and consumer semantics (e.g: partitioning, rebalancing, data retention and compaction).
What is really unique, the only dependency to run Kafka Streams application is a running Kafka cluster.
Even local state stores are backed by Kafka topics to make the processing fault tolerant &ndash; brilliant!</p>

<p>Kafka Streams provides all necessary stream processing primitives like one-record-at-a-time processing,
event time processing, windowing support and local state management.
Application developer can choose from three different Kafka Streams APIs: DSL, Processor or KSQL.</p>

<ul>
<li><p><a href="https://docs.confluent.io/current/streams/developer-guide.html#kafka-streams-dsl">Kafka Streams DSL</a>
(Domain Specific Language) &ndash; recommended way for most users
because business logic can be expressed in a few lines of code.
All stateless and stateful transformations are defined using declarative,
functional programming style (filter, map, flatMap, reduce, aggregate operations).
Kafka Stream DSL encapsulates most of the stream processing complexity
but unfortunately it also hides many useful knobs and switches.</p></li>
<li><p><a href="https://docs.confluent.io/current/streams/developer-guide.html#processor-api">Kafka Processor API</a>
provides a low level, imperative way to define stream processing logic.
At first sight Processor API could look hostile but finally gives much more flexibility to developer.
With this blog post I would like to demonstrate that hand-crafted stream processors might be a magnitude more efficient
than a naive implementation using Kafka DSL.</p></li>
<li><p><a href="https://www.confluent.io/product/ksql/">KSQL</a>
is a promise that stream processing could be expressed by anyone using SQL as the language.
It offers an easy way to express stream processing transformations as an alternative to writing
an application in a programming language such as Java.
Moreover, processing transformation written in SQL like language can be highly optimized
by execution engine without any developer effort.
KSQL was released recently and it is still at very early development stage.</p></li>
</ul>


<p>In the first part of this blog post I&rsquo;ll define simple but still realistic business problem to solve.
Then you will learn how to implement this use case with Kafka Stream DSL
and how much the processing performance is affected by this naive solution.
At this moment you could stop reading and scale-up Kafka cluster ten times to fulfill business requirements
or you could continue reading and learn how to optimize the processing with low level Kafka Processor API.</p>

<h2>Business Use Case</h2>

<p>Let&rsquo;s imagine a web based e-commerce platform with fabulous recommendation and advertisement systems.
Every client during visit gets personalized recommendations and advertisements,
the conversion is extraordinarily high and platform earns additional profits from advertisers.
To build comprehensive recommendation models,
such system needs to know everything about clients traits and their behaviour.</p>

<p>To make it possible, e-commerce platform reports all clients activities as an unbounded stream
of page views and events.
Every time the client enters web page, a so-called page view is sent to Kafka cluster.
A page view contains web page attributes like request URI, referrer URI, user agent, active A/B experiments
and many more.
In addition to page view all important actions are reported as custom events, e.g: search, add to cart or checkout.
To get a complete view of the activity stream, collected events need to be enriched with data from page views.</p>

<h2>Data Model</h2>

<p>Because most of the processing logic is built within context of given client,
page views and events are evenly partitioned on Kafka topics by the client identifier.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">type</span> <span class="kt">ClientId</span> <span class="o">=</span> <span class="nc">String</span>
</span><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">ClientKey</span><span class="o">(</span><span class="n">clientId</span><span class="k">:</span> <span class="kt">ClientId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">bob</span> <span class="k">=</span> <span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">)</span>
</span><span class='line'><span class="k">val</span> <span class="n">jim</span> <span class="k">=</span> <span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;jim&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Page view and event structures are different so messages are published to separate Kafka topics
using ingestion time as the event time.
Our system should not rely on page view or event creation time due to high client clocks variance.
The topic key is always <code>ClientKey</code> and value is either <code>Pv</code> or <code>Ev</code> presented below.
For better examples readability page view and event payload is defined as simplified single value field.
Events are uniquely identified by <code>pvId</code> and <code>evId</code> pair, <code>pvId</code> could be a random identifier, <code>evId</code>
a sequence number.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">type</span> <span class="kt">PvId</span> <span class="o">=</span> <span class="nc">String</span>
</span><span class='line'><span class="k">type</span> <span class="kt">EvId</span> <span class="o">=</span> <span class="nc">String</span>
</span><span class='line'>
</span><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">Pv</span><span class="o">(</span><span class="n">pvId</span><span class="k">:</span> <span class="kt">PvId</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>
</span><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">Ev</span><span class="o">(</span><span class="n">evId</span><span class="k">:</span> <span class="kt">EvId</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">pvId</span><span class="k">:</span> <span class="kt">PvId</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Enriched results <code>EvPv</code> is published to output Kafka topic using <code>ClientKey</code> as message key.
This topic is then consumed directly by advertisement and recommendation systems.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">EvPv</span><span class="o">(</span><span class="n">evId</span><span class="k">:</span> <span class="kt">EvId</span><span class="o">,</span> <span class="n">evValue</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">pvId</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">PvId</span><span class="o">],</span> <span class="n">pvValue</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Example Scenario</h2>

<p>For client &ldquo;bob&rdquo; the following page views and events are collected by the system.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// Bob enters main page</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Pv</span><span class="o">(</span><span class="s">&quot;pv0&quot;</span><span class="o">,</span> <span class="s">&quot;/&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// A few impression events collected almost immediately</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Ev</span><span class="o">(</span><span class="s">&quot;ev0&quot;</span><span class="o">,</span> <span class="s">&quot;show header&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">)</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Ev</span><span class="o">(</span><span class="s">&quot;ev1&quot;</span><span class="o">,</span> <span class="s">&quot;show ads&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">)</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Ev</span><span class="o">(</span><span class="s">&quot;ev2&quot;</span><span class="o">,</span> <span class="s">&quot;show recommendation&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// There is also single duplicated event, welcome to distributed world</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Pv</span><span class="o">(</span><span class="s">&quot;ev1&quot;</span><span class="o">,</span> <span class="s">&quot;show ads&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// A dozen seconds later Bob clicks on one of the offers presented on the main page</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Pv</span><span class="o">(</span><span class="s">&quot;ev3&quot;</span><span class="o">,</span> <span class="s">&quot;click recommendation&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Out of order event collected before page view on the offer page </span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Ev</span><span class="o">(</span><span class="s">&quot;ev0&quot;</span><span class="o">,</span> <span class="s">&quot;show header&quot;</span><span class="o">,</span> <span class="s">&quot;pv1&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Offer page view</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Pv</span><span class="o">(</span><span class="s">&quot;pv1&quot;</span><span class="o">,</span> <span class="s">&quot;/offer?id=1234&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// An impression event published almost immediately after page view</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Ev</span><span class="o">(</span><span class="s">&quot;ev1&quot;</span><span class="o">,</span> <span class="s">&quot;show ads&quot;</span><span class="o">,</span> <span class="s">&quot;pv1&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Late purchase event, Bob took short coffee break before the final decision</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">Ev</span><span class="o">(</span><span class="s">&quot;ev2&quot;</span><span class="o">,</span> <span class="s">&quot;add to cart&quot;</span><span class="o">,</span> <span class="s">&quot;pv1&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>For above clickstream the following enriched events output stream is expected.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// Events from main page without duplicates</span>
</span><span class='line'>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev0&quot;</span><span class="o">,</span> <span class="s">&quot;show header&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">,</span> <span class="s">&quot;/&quot;</span><span class="o">)</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev1&quot;</span><span class="o">,</span> <span class="s">&quot;show ads&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">,</span> <span class="s">&quot;/&quot;</span><span class="o">)</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev2&quot;</span><span class="o">,</span> <span class="s">&quot;show recommendation&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">,</span> <span class="s">&quot;/&quot;</span><span class="o">)</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev3&quot;</span><span class="o">,</span> <span class="s">&quot;click recommendation&quot;</span><span class="o">,</span> <span class="s">&quot;pv0&quot;</span><span class="o">,</span> <span class="s">&quot;/&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Events from offer page, somehow incomplete due to streaming semantics limitations</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// early event</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev0&quot;</span><span class="o">,</span> <span class="s">&quot;show header&quot;</span><span class="o">,</span> <span class="nc">None</span><span class="o">,</span> <span class="nc">None</span><span class="o">)</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev1&quot;</span><span class="o">,</span> <span class="s">&quot;show ads&quot;</span><span class="o">,</span> <span class="s">&quot;pv1&quot;</span><span class="o">,</span> <span class="s">&quot;/offer?id=1234&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// late event</span>
</span><span class='line'><span class="nc">ClientKey</span><span class="o">(</span><span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="nc">EvPv</span><span class="o">(</span><span class="s">&quot;ev2&quot;</span><span class="o">,</span> <span class="s">&quot;add to cart&quot;</span><span class="o">,</span> <span class="nc">None</span><span class="o">,</span> <span class="nc">None</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Kafka Stream DSL</h2>

<p>Now we are ready to implement above use case with recommended Kafka Streams DSL.
The code could be optimized but I would like to present the canonical way of using DSL
without exploring DSL internals.
All examples are implemented using the latest Kafka Streams 1.0.0 version.</p>

<p>Create two input streams for page views and events
connected to &ldquo;clickstream.events&rdquo; and &ldquo;clickstream.page_views&rdquo; Kafka topics.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">builder</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StreamsBuilder</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evStream</span> <span class="k">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">stream</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Ev</span><span class="o">](</span><span class="s">&quot;clickstream.events&quot;</span><span class="o">)</span>
</span><span class='line'><span class="k">val</span> <span class="n">pvStream</span> <span class="k">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">stream</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Pv</span><span class="o">](</span><span class="s">&quot;clickstream.page_views&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Repartition topics by client and page view identifiers <code>PvKey</code>
as a prerequisite to join events with page view.
Method <code>selectKey</code> sets a new key for every input record,
and marks derived stream for repartitioning.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">PvKey</span><span class="o">(</span><span class="n">clientId</span><span class="k">:</span> <span class="kt">ClientId</span><span class="o">,</span> <span class="n">pvId</span><span class="k">:</span> <span class="kt">PvId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evToPvKeyMapper</span><span class="k">:</span> <span class="kt">KeyValueMapper</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Ev</span>, <span class="kt">PvKey</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">(</span><span class="n">clientKey</span><span class="o">,</span> <span class="n">ev</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">PvKey</span><span class="o">(</span><span class="n">clientKey</span><span class="o">.</span><span class="n">clientId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">pvId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evByPvKeyStream</span> <span class="k">=</span> <span class="n">evStream</span><span class="o">.</span><span class="n">selectKey</span><span class="o">(</span><span class="n">evToPvKeyMapper</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">pvToPvKeyMapper</span><span class="k">:</span> <span class="kt">KeyValueMapper</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Pv</span>, <span class="kt">PvKey</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">(</span><span class="n">clientKey</span><span class="o">,</span> <span class="n">pv</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">PvKey</span><span class="o">(</span><span class="n">clientKey</span><span class="o">.</span><span class="n">clientId</span><span class="o">,</span> <span class="n">pv</span><span class="o">.</span><span class="n">pvId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">pvByPvKeyStream</span> <span class="k">=</span> <span class="n">pvStream</span><span class="o">.</span><span class="n">selectKey</span><span class="o">(</span><span class="n">pvToPvKeyMapper</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Join event with page view streams by selected previously <code>PvKey</code>,
left join is used because we are interested also in events without matched page view.
Every incoming event is enriched by matched page view into <code>EvPv</code> structure.</p>

<p>The join window duration is set to reasonable 10 minutes.
It means, that Kafka Streams will look for messages in &ldquo;event&rdquo; and &ldquo;page view&rdquo; sides of the join
10 minutes in the past and 10 minutes in the future (using event time, not wall-clock time).
Because we are not interested in late events out of defined window,
the retention is 2 times longer than window, to hold events from the past and the future.
If you are interested why 1 milliseconds needs to be added to the retention,
please ask Kafka Streams authors not me ;)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">evPvJoiner</span><span class="k">:</span> <span class="kt">ValueJoiner</span><span class="o">[</span><span class="kt">Ev</span>, <span class="kt">Pv</span>, <span class="kt">EvPv</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span> <span class="o">(</span><span class="n">ev</span><span class="o">,</span> <span class="n">pv</span><span class="o">)</span> <span class="k">=&gt;</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">(</span><span class="n">pv</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="nc">EvPv</span><span class="o">(</span><span class="n">ev</span><span class="o">.</span><span class="n">evId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">value</span><span class="o">,</span> <span class="nc">None</span><span class="o">,</span> <span class="nc">None</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>    <span class="nc">EvPv</span><span class="o">(</span><span class="n">ev</span><span class="o">.</span><span class="n">evId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">value</span><span class="o">,</span> <span class="nc">Some</span><span class="o">(</span><span class="n">pv</span><span class="o">.</span><span class="n">pvId</span><span class="o">),</span> <span class="nc">Some</span><span class="o">(</span><span class="n">pv</span><span class="o">.</span><span class="n">value</span><span class="o">))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">joinWindowDuration</span> <span class="k">=</span> <span class="mi">10</span> <span class="n">minutes</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">joinRetention</span> <span class="k">=</span> <span class="n">joinWindowDuration</span><span class="o">.</span><span class="n">toMillis</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class='line'><span class="k">val</span> <span class="n">joinWindow</span> <span class="k">=</span> <span class="nc">JoinWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">joinWindowDuration</span><span class="o">.</span><span class="n">toMillis</span><span class="o">).</span><span class="n">until</span><span class="o">(</span><span class="n">joinRetention</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evPvStream</span> <span class="k">=</span> <span class="n">evByPvKeyStream</span><span class="o">.</span><span class="n">leftJoin</span><span class="o">(</span><span class="n">pvByPvKeyStream</span><span class="o">,</span> <span class="n">evPvJoiner</span><span class="o">,</span> <span class="n">joinWindow</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now it&rsquo;s time to fight with duplicated enriched events.
Duplicates come from unreliable nature of the network between client browser and our system.
Most real-time processing pipelines in advertising and recommendation systems are counting events,
so duplicates in the enriched clickstream could cause inaccuracies.</p>

<p>The most straightforward deduplication method is to compare incoming event with state of previously processed events.
If the event has been already processed it should be skipped.</p>

<p>Unfortunately DSL does not provide &ldquo;deduplicate&rdquo; method out-of-the-box but similar logic might be implemented with
&ldquo;reduce&rdquo; operation.</p>

<p>First we need to define deduplication window.
Deduplication window can be much shorter than join window,
we do not expect duplicates more than 10 seconds between each other.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">deduplicationWindowDuration</span> <span class="k">=</span> <span class="mi">10</span> <span class="n">seconds</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">deduplicationRetention</span> <span class="k">=</span> <span class="n">deduplicationWindowDuration</span><span class="o">.</span><span class="n">toMillis</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class='line'><span class="k">val</span> <span class="n">deduplicationWindow</span> <span class="k">=</span> <span class="nc">TimeWindows</span><span class="o">.</span><span class="n">of</span><span class="o">(</span><span class="n">deduplicationWindowDuration</span><span class="o">.</span><span class="n">toMillis</span><span class="o">).</span><span class="n">until</span><span class="o">(</span><span class="n">deduplicationRetention</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Joined stream needs to be repartitioned again by compound key <code>EvPvKey</code> composed of
client, page view and event identifiers.
This key will be used to decide if <code>EvPv</code> is a duplicate or not.
Next, the stream is grouped by selected key into KGroupedStream and
deduplicated with reduce function, where first observed event wins.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">EvPvKey</span><span class="o">(</span><span class="n">clientId</span><span class="k">:</span> <span class="kt">ClientId</span><span class="o">,</span> <span class="n">pvId</span><span class="k">:</span> <span class="kt">PvId</span><span class="o">,</span> <span class="n">evId</span><span class="k">:</span> <span class="kt">EvId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evPvToEvPvKeyMapper</span><span class="k">:</span> <span class="kt">KeyValueMapper</span><span class="o">[</span><span class="kt">PvKey</span>, <span class="kt">EvPv</span>, <span class="kt">EvPvKey</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">(</span><span class="n">pvKey</span><span class="o">,</span> <span class="n">evPv</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">EvPvKey</span><span class="o">(</span><span class="n">pvKey</span><span class="o">.</span><span class="n">clientId</span><span class="o">,</span> <span class="n">pvKey</span><span class="o">.</span><span class="n">pvId</span><span class="o">,</span> <span class="n">evPv</span><span class="o">.</span><span class="n">evId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evPvByEvPvKeyStream</span> <span class="k">=</span> <span class="n">evPvStream</span><span class="o">.</span><span class="n">selectKey</span><span class="o">(</span><span class="n">evPvToEvPvKeyMapper</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evPvDeduplicator</span><span class="k">:</span> <span class="kt">Reducer</span><span class="o">[</span><span class="kt">EvPv</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">(</span><span class="n">evPv1</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">evPv1</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">deduplicatedStream</span> <span class="k">=</span> <span class="n">evPvByEvPvKeyStream</span>
</span><span class='line'>  <span class="o">.</span><span class="n">groupByKey</span><span class="o">()</span>
</span><span class='line'>  <span class="o">.</span><span class="n">reduce</span><span class="o">(</span><span class="n">evPvDeduplicator</span><span class="o">,</span> <span class="n">deduplicationWindow</span><span class="o">,</span> <span class="s">&quot;evpv-store&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">toStream</span><span class="o">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>This deduplication implementation is debatable, due to &ldquo;continue stream&rdquo; semantics of KTable/KStream.
Reduce operation creates KTable, and this KTable is transformed again into KStream of continuous updates of the same key.
It could lead to duplicates again if the update frequency is higher than inverse of deduplication window period.
For 10 seconds deduplication window the updates should not be emitted more often than every 10 seconds but
lower updates frequency leads to higher latency.
The updates frequency is controlled globally using &ldquo;cache.max.bytes.buffering&rdquo; and &ldquo;commit.interval.ms&rdquo;
Kafka Streams properties.
See reference documentation for details:
<a href="https://docs.confluent.io/current/streams/developer-guide.html#streams-developer-guide-memory-management">Record caches in the DSL</a>.</p>

<p>I did not find another way to deduplicate events with DSL, please let me know if better implementation exists.</p>

<p>In the last stage the stream needs to be repartitioned again by client id
and published to &ldquo;clickstream.events_enriched&rdquo; Kafka topic for downstream subscribers.
In the same step mapper gets rid of the windowed key produced by windowed reduce function.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">evPvToClientKeyMapper</span><span class="k">:</span> <span class="kt">KeyValueMapper</span><span class="o">[</span><span class="kt">Windowed</span><span class="o">[</span><span class="kt">EvPvKey</span><span class="o">]</span>, <span class="kt">EvPv</span>, <span class="kt">ClientId</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">(</span><span class="n">windowedEvPvKey</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">windowedEvPvKey</span><span class="o">.</span><span class="n">key</span><span class="o">.</span><span class="n">clientId</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">finalStream</span> <span class="k">=</span> <span class="n">deduplicatedStream</span><span class="o">.</span><span class="n">selectKey</span><span class="o">(</span><span class="n">evPvToClientKeyMapper</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">finalStream</span><span class="o">.</span><span class="n">to</span><span class="o">(</span><span class="s">&quot;clickstream.events_enriched&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Under The Hood</h2>

<p>Kafka Stream DSL is quite descriptive, isn&rsquo;t it?
Especially developers with strong functional programming skills appreciate the overall design.
But you will shortly see how much unexpected traffic to Kafka cluster is generated during runtime.</p>

<p>I like numbers so let&rsquo;s estimate the traffic,
based on real clickstream ingestion platform I develop on daily basis:</p>

<ul>
<li>1 kB &ndash; average page view size</li>
<li>600 B &ndash; average event size</li>
<li>4k &ndash; page views / second</li>
<li>20k &ndash; events / second</li>
</ul>


<p>It gives 24k msgs/s and 16MB/s traffic-in total, the traffic easily handled even by small Kafka cluster.</p>

<p>When stream of data is repartitioned Kafka Streams creates additional intermediate topic
and publishes on the topic whole traffic partitioned by selected key.
To be more precise it happens twice in our case, for repartitioned page views and events before join.
We need to add 24k msgs/s and 16MB/s more traffic-in to the calculation.</p>

<p>When streams of data are joined using window, Kafka Streams sends both sides of the join
to two intermediate topics again. Even if you don&rsquo;t need fault tolerance,
logging into Kafka cannot be disabled using DSL.
You cannot also get rid of window for &ldquo;this&rdquo; side of the join (window for events), more about it later on.
Add 24k msgs/s and 16MB/s more traffic-in to the calculation again.</p>

<p>To deduplicate events, joined stream goes again into Kafka Streams intermediate topic.
Add 20k msgs/s and (1kB + 1.6kB) * 20k = 52MB/s more traffic-in to the calculation again.</p>

<p>The last repartitioning by client identifier adds 20k msgs/s and 52MB/s more traffic-in.</p>

<p>Finally, instead of <strong>24k</strong> msgs/s and <strong>16MB/s</strong> traffic-in we have got
<strong>112k</strong> msgs/s and <strong>152MB</strong> traffic-in.
And I did not even count traffic from internal topics replication and standby replicas
<a href="https://docs.confluent.io/current/streams/developer-guide.html#recommended-configuration-parameters-for-resiliency">recommended for resiliency</a>.</p>

<p>Be aware that this is calculation for simple join of events and pages views generated by
local e-commerce platform in central Europe country (~20M clients).
I could also easily imagine much more complex stream topology, with tens of repartitions, joins and aggregations.</p>

<p>If you are not careful, your Kafka Streams application could easily kill your Kafka cluster.
At least our application did it once. Application deployed on 10 <a href="http://mesos.apache.org/">Mesos</a>
nodes (4CPU, 4GB RAM) almost killed Kafka cluster deployed also on 10 physical machines (32CPU, 64GB RAM, SSD).
Application was started after some time of inactivity and processed 3 hours of retention in 5 minutes
(yep, it&rsquo;s a well known vulnerability until
<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-13+-+Quotas">KIP-13</a> is open).</p>

<h2>Kafka Processor API</h2>

<p>Now it&rsquo;s time to check Processor API and figure out how to optimize our stream topology.</p>

<p>Create the sources from input topics &ldquo;clickstream.events&rdquo; and &ldquo;clickstream.page_views&rdquo;.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">new</span> <span class="nc">Topology</span><span class="o">()</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="s">&quot;ev-source&quot;</span><span class="o">,</span> <span class="s">&quot;clickstream.events&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="s">&quot;pv-source&quot;</span><span class="o">,</span> <span class="s">&quot;clickstream.page_views&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Because we need to join an incoming event with the collected page view in the past,
create processor which stores page view in windowed store.
The processor puts observed page views into window store for joining in the next processor.
The processed page views do not even need to be forwarded to downstream.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">PvWindowProcessor</span><span class="o">(</span><span class="k">val</span> <span class="n">pvStoreName</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">AbstractProcessor</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Pv</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">pvStore</span> <span class="k">=</span>
</span><span class='line'>    <span class="n">context</span><span class="o">().</span><span class="n">getStateStore</span><span class="o">(</span><span class="n">pvStoreName</span><span class="o">).</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">WindowStore</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Pv</span><span class="o">]]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">override</span> <span class="k">def</span> <span class="n">process</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">ClientKey</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">Pv</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span>
</span><span class='line'>    <span class="n">pvStore</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Store for page views is configured with the same size of window and retention.
This store is configured to keep duplicates due to the fact
that the key is a client id not page view id (retainDuplicates parameter).
Because join window is typically quite long (minutes) the store should be fault tolerant (logging enabled).
Even if one of the stream instances fails,
another one will continue processing with persistent window state built by failed node, cool!
Finally, the internal kafka topic can be easily configured using loggingConfig map
(replication factor, number of partitions, etc.).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">pvStoreWindowDuration</span> <span class="k">=</span> <span class="mi">10</span> <span class="n">minutes</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">retention</span> <span class="k">=</span> <span class="n">pvStoreWindowDuration</span><span class="o">.</span><span class="n">toMillis</span>
</span><span class='line'><span class="k">val</span> <span class="n">window</span> <span class="k">=</span> <span class="n">pvStoreWindowDuration</span><span class="o">.</span><span class="n">toMillis</span>
</span><span class='line'><span class="k">val</span> <span class="n">segments</span> <span class="k">=</span> <span class="mi">3</span>
</span><span class='line'><span class="k">val</span> <span class="n">retainDuplicates</span> <span class="k">=</span> <span class="kc">true</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">loggingConfig</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">]()</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">pvWindowStore</span> <span class="k">=</span> <span class="nc">Stores</span><span class="o">.</span><span class="n">windowStoreBuilder</span><span class="o">(</span>
</span><span class='line'>  <span class="nc">Stores</span><span class="o">.</span><span class="n">persistentWindowStore</span><span class="o">(</span><span class="s">&quot;pv-window-store&quot;</span><span class="o">,</span> <span class="n">retention</span><span class="o">,</span> <span class="n">segments</span><span class="o">,</span> <span class="n">window</span><span class="o">,</span> <span class="n">retainDuplicates</span><span class="o">),</span>
</span><span class='line'>  <span class="nc">ClientKeySerde</span><span class="o">,</span>
</span><span class='line'>  <span class="nc">PvSerde</span>
</span><span class='line'><span class="o">).</span><span class="n">withLoggingEnabled</span><span class="o">(</span><span class="n">loggingConfig</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The first optimization you could observe is that in our scenario only one window store is created &ndash; for page views.
The window store for events is not needed, if page view is collected by system after event it does not trigger new join.</p>

<p>Add page view processor to the topology and connect with page view source upstream.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">pvWindowProcessor</span><span class="k">:</span> <span class="kt">ProcessorSupplier</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Pv</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">()</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">PvWindowProcessor</span><span class="o">(</span><span class="s">&quot;pv-window-store&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">new</span> <span class="nc">Topology</span><span class="o">()</span>
</span><span class='line'>  <span class="o">(...)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addProcessor</span><span class="o">(</span><span class="s">&quot;pv-window-processor&quot;</span><span class="o">,</span> <span class="n">pvWindowProcessor</span><span class="o">,</span> <span class="s">&quot;pv-source&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, it&rsquo;s time for event and page view join processor, heart of the topology.
It seems to be complex but this processor also deduplicates joined stream using <code>evPvStore</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">EvJoinProcessor</span><span class="o">(</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">pvStoreName</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">evPvStoreName</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">joinWindow</span><span class="k">:</span> <span class="kt">FiniteDuration</span><span class="o">,</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">deduplicationWindow</span><span class="k">:</span> <span class="kt">FiniteDuration</span>
</span><span class='line'><span class="o">)</span> <span class="k">extends</span> <span class="nc">AbstractProcessor</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Ev</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">import</span> <span class="nn">scala.collection.JavaConverters._</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">pvStore</span> <span class="k">=</span>
</span><span class='line'>    <span class="n">context</span><span class="o">().</span><span class="n">getStateStore</span><span class="o">(</span><span class="n">pvStoreName</span><span class="o">).</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">WindowStore</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Pv</span><span class="o">]]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">evPvStore</span> <span class="k">=</span>
</span><span class='line'>    <span class="n">context</span><span class="o">().</span><span class="n">getStateStore</span><span class="o">(</span><span class="n">evPvStoreName</span><span class="o">).</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">WindowStore</span><span class="o">[</span><span class="kt">EvPvKey</span>, <span class="kt">EvPv</span><span class="o">]]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">override</span> <span class="k">def</span> <span class="n">process</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">ClientKey</span><span class="o">,</span> <span class="n">ev</span><span class="k">:</span> <span class="kt">Ev</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">timestamp</span> <span class="k">=</span> <span class="n">context</span><span class="o">().</span><span class="n">timestamp</span><span class="o">()</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">evPvKey</span> <span class="k">=</span> <span class="nc">EvPvKey</span><span class="o">(</span><span class="n">key</span><span class="o">.</span><span class="n">clientId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">pvId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">evId</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="o">(</span><span class="n">isNotDuplicate</span><span class="o">(</span><span class="n">evPvKey</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">,</span> <span class="n">deduplicationWindow</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">evPv</span> <span class="k">=</span> <span class="n">storedPvs</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">,</span> <span class="n">joinWindow</span><span class="o">)</span>
</span><span class='line'>        <span class="o">.</span><span class="n">find</span> <span class="o">{</span> <span class="n">pv</span> <span class="k">=&gt;</span>
</span><span class='line'>          <span class="n">pv</span><span class="o">.</span><span class="n">pvId</span> <span class="o">==</span> <span class="n">ev</span><span class="o">.</span><span class="n">pvId</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>        <span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">pv</span> <span class="k">=&gt;</span>
</span><span class='line'>          <span class="nc">EvPv</span><span class="o">(</span><span class="n">ev</span><span class="o">.</span><span class="n">evId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">value</span><span class="o">,</span> <span class="nc">Some</span><span class="o">(</span><span class="n">pv</span><span class="o">.</span><span class="n">pvId</span><span class="o">),</span> <span class="nc">Some</span><span class="o">(</span><span class="n">pv</span><span class="o">.</span><span class="n">value</span><span class="o">))</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>        <span class="o">.</span><span class="n">getOrElse</span> <span class="o">{</span>
</span><span class='line'>          <span class="nc">EvPv</span><span class="o">(</span><span class="n">ev</span><span class="o">.</span><span class="n">evId</span><span class="o">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">value</span><span class="o">,</span> <span class="nc">None</span><span class="o">,</span> <span class="nc">None</span><span class="o">)</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">context</span><span class="o">().</span><span class="n">forward</span><span class="o">(</span><span class="n">evPvKey</span><span class="o">,</span> <span class="n">evPv</span><span class="o">)</span>
</span><span class='line'>      <span class="n">evPvStore</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="n">evPvKey</span><span class="o">,</span> <span class="n">evPv</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">def</span> <span class="n">isNotDuplicate</span><span class="o">(</span><span class="n">evPvKey</span><span class="k">:</span> <span class="kt">EvPvKey</span><span class="o">,</span> <span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">deduplicationWindow</span><span class="k">:</span> <span class="kt">FiniteDuration</span><span class="o">)</span> <span class="k">=</span>
</span><span class='line'>    <span class="n">evPvStore</span><span class="o">.</span><span class="n">fetch</span><span class="o">(</span><span class="n">evPvKey</span><span class="o">,</span> <span class="n">timestamp</span> <span class="o">-</span> <span class="n">deduplicationWindow</span><span class="o">.</span><span class="n">toMillis</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">).</span><span class="n">asScala</span><span class="o">.</span><span class="n">isEmpty</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">def</span> <span class="n">storedPvs</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">ClientKey</span><span class="o">,</span> <span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">joinWindow</span><span class="k">:</span> <span class="kt">FiniteDuration</span><span class="o">)</span> <span class="k">=</span>
</span><span class='line'>    <span class="n">pvStore</span><span class="o">.</span><span class="n">fetch</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">timestamp</span> <span class="o">-</span> <span class="n">joinWindow</span><span class="o">.</span><span class="n">toMillis</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">).</span><span class="n">asScala</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">value</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>First processor performs a lookup for previously joined <code>PvEv</code> by <code>PvEvKey</code>.
If <code>PvEv</code> is found the processing is skipped because <code>EvPv</code> has been already processed.</p>

<p>Next, try to match page view to event using simple filter <code>pv.pvId == ev.pvId</code>.
We don&rsquo;t need any repartitioning to do that, only get all page views from given client
and join with event in the processor itself.
It should be very efficient because every client generates up do hundred page views in 10 minutes.
If there is no matched page view in the configured window,
<code>EvPv</code> without page view details is forwarded to the downstream.</p>

<p>Perceptive reader noticed that processor also changes the key from <code>ClientId</code> to <code>EvPvKey</code>
for deduplication purposes.
Everything is still within given client context without the need for any repartitioning.
This is possible due to the fact, that new key is more detailed than the original one.</p>

<p>As before, windowed store for deduplication needs to be configured.
Because deduplication is done in a very short window (10 seconds or so),
the logging to backed internal Kafka topic is disabled at all.
If one of the stream instance fails, we could get some duplicates during this short window, not a big deal.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">evPvStoreWindowDuration</span> <span class="k">=</span> <span class="mi">10</span> <span class="n">seconds</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">retention</span> <span class="k">=</span> <span class="n">evPvStoreWindowDuration</span><span class="o">.</span><span class="n">toMillis</span>
</span><span class='line'><span class="k">val</span> <span class="n">window</span> <span class="k">=</span> <span class="n">evPvStoreWindowDuration</span><span class="o">.</span><span class="n">toMillis</span>
</span><span class='line'><span class="k">val</span> <span class="n">segments</span> <span class="k">=</span> <span class="mi">3</span>
</span><span class='line'><span class="k">val</span> <span class="n">retainDuplicates</span> <span class="k">=</span> <span class="kc">false</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">evPvStore</span> <span class="k">=</span> <span class="nc">Stores</span><span class="o">.</span><span class="n">windowStoreBuilder</span><span class="o">(</span>
</span><span class='line'>  <span class="nc">Stores</span><span class="o">.</span><span class="n">persistentWindowStore</span><span class="o">(</span><span class="s">&quot;ev-pv-window-store&quot;</span><span class="o">,</span> <span class="n">retention</span><span class="o">,</span> <span class="n">segments</span><span class="o">,</span> <span class="n">window</span><span class="o">,</span> <span class="n">retainDuplicates</span><span class="o">),</span>
</span><span class='line'>  <span class="nc">EvPvKeySerde</span><span class="o">,</span>
</span><span class='line'>  <span class="nc">EvPvSerde</span>
</span><span class='line'><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Add join processor to the topology and connect with event source upstream.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">evJoinProcessor</span><span class="k">:</span> <span class="kt">ProcessorSupplier</span><span class="o">[</span><span class="kt">ClientKey</span>, <span class="kt">Ev</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">()</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">EvJoinProcessor</span><span class="o">(</span><span class="s">&quot;pv-window-store&quot;</span><span class="o">,</span> <span class="s">&quot;ev-pv-window-store&quot;</span><span class="o">,</span> <span class="n">pvStoreWindowDuration</span><span class="o">,</span> <span class="n">evPvStoreWindowDuration</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">new</span> <span class="nc">Topology</span><span class="o">()</span>
</span><span class='line'>  <span class="o">(...)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addProcessor</span><span class="o">(</span><span class="s">&quot;ev-join-processor&quot;</span><span class="o">,</span> <span class="n">evJoinProcessor</span><span class="o">,</span> <span class="s">&quot;ev-source&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The last processor maps compound key <code>EvPvKey</code> again into <code>ClientId</code>.
Because client identifier is already a part of the compound key,
mapping is done by the processor without the need for further repartitioning.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">EvPvMapProcessor</span> <span class="k">extends</span> <span class="nc">AbstractProcessor</span><span class="o">[</span><span class="kt">EvPvKey</span>, <span class="kt">EvPv</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">override</span> <span class="k">def</span> <span class="n">process</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">EvPvKey</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">EvPv</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span>
</span><span class='line'>    <span class="n">context</span><span class="o">().</span><span class="n">forward</span><span class="o">(</span><span class="nc">ClientKey</span><span class="o">(</span><span class="n">key</span><span class="o">.</span><span class="n">clientId</span><span class="o">),</span> <span class="n">value</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Add the map processor to the topology.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">evPvMapProcessor</span><span class="k">:</span> <span class="kt">ProcessorSupplier</span><span class="o">[</span><span class="kt">EvPvKey</span>, <span class="kt">EvPv</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="o">()</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">EvPvMapProcessor</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'><span class="k">new</span> <span class="nc">Topology</span><span class="o">()</span>
</span><span class='line'>  <span class="o">(...)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addProcessor</span><span class="o">(</span><span class="s">&quot;ev-pv-map-processor&quot;</span><span class="o">,</span> <span class="n">evPvMapProcessor</span><span class="o">,</span> <span class="s">&quot;ev-pv-join-processor&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally publish join results to &ldquo;clickstream.events_enriched&rdquo; Kafka topic.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">new</span> <span class="nc">Topology</span><span class="o">()</span>
</span><span class='line'>  <span class="o">(...)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addSink</span><span class="o">(</span><span class="s">&quot;ev-pv-sink&quot;</span><span class="o">,</span> <span class="nc">EvPvTopic</span><span class="o">,</span> <span class="s">&quot;clickstream.events_enriched&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>If a processor requires access to the store this fact must be registered.
It would be nice to have statically typed Topology API for registration,
but now if the store is not connected to the processor,
or is connected to the wrong store,
runtime exception is thrown during application startup.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">new</span> <span class="nc">Topology</span><span class="o">()</span>
</span><span class='line'>  <span class="o">(...)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addStateStore</span><span class="o">(</span><span class="n">pvStore</span><span class="o">,</span> <span class="s">&quot;pv-window-processor&quot;</span><span class="o">,</span> <span class="s">&quot;ev-join-processor&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">.</span><span class="n">addStateStore</span><span class="o">(</span><span class="n">evPvStore</span><span class="o">,</span> <span class="s">&quot;ev-join-processor&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s count Kafka Streams internal topics overhead for Processor API version.
Wait, there is only one internal topic, for page view join window!
It gives 4k messages per second and 4MB traffic-in overhead, not more.</p>

<p><strong>28k</strong> instead of <strong>112k</strong> messages per second and <strong>20MB</strong> instead of <strong>152MB</strong> traffic-in in total.
It is a noticeable difference between Processor API and DSL topology versions,
especially if we keep in mind that enrichment results are almost identical to results from DSL version.</p>

<h2>Summary</h2>

<p>Dear readers, are you still with me after long lecture with not so easy to digest Scala code?
I hope so :)</p>

<p>My final thoughts about Kafka Streams:</p>

<ul>
<li>Kafka DSL looks great at first, functional and declarative API sells the product, no doubts.</li>
<li>Unfortunately Kafka DSL hides a lot of internals which should be exposed via the API
(stores configuration, join semantics, repartitioning) &ndash; see
<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-182%3A+Reduce+Streams+DSL+overloads+and+allow+easier+use+of+custom+storage+engines">KIP-182</a>.</li>
<li>Processor API seems to be more complex and less sexy than DSL.</li>
<li>But Processor API allows you to create hand-crafted, very efficient stream topologies.</li>
<li>I did not present any Kafka Streams test (what&rsquo;s the shame &ndash; I&rsquo;m sorry)
but I think testing would be easier with Processor API than DSL.
With DSL it has to be an integration test, processors can be easily unit tested in separation with a few mocks.</li>
<li>As Scala developer I prefer Processor API than DSL,
e.g. Scala compiler could not infer KStream generic types.</li>
<li>It&rsquo;s a pleasure to work with processor and fluent Topology APIs.</li>
<li>I&rsquo;m really keen on KSQL future, it would be great to get optimized engine like
<a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">Spark Catalyst</a> eventually.</li>
<li>Finally, Kafka Streams library is extraordinarily fast and hardware efficient, if you know what you are doing.</li>
</ul>


<p>As always working code is published on
<a href="https://github.com/mkuthan/example-kafkastreams">https://github.com/mkuthan/example-kafkastreams</a>.
The project is configured with <a href="https://github.com/manub/scalatest-embedded-kafka">Embedded Kafka</a>
and does not require any additional setup.
Just uncomment either DSL or Processor API version, run main class and observe enriched stream of events on the console.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache BigData Europe Conference Summary]]></title>
    <link href="http://mkuthan.github.io/blog/2016/11/18/apache-bigdata-europe/"/>
    <updated>2016-11-18T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2016/11/18/apache-bigdata-europe</id>
    <content type="html"><![CDATA[<p>Last week I attended <a href="http://events.linuxfoundation.org/events/apache-big-data-europe">Apache Big Data Europe</a> held in Sevilla, Spain.
The event concentrates around big data projects under <a href="https://www.apache.org/">Apache Foundation</a> umbrella.
Below you can find my overall impression on the conference and notes from several interesting sessions.
The notes are presented as a short checklists, if some aspect was particularly interesting I put the reference to supplementary materials.</p>

<h2>Key takeaways</h2>

<ul>
<li>At <a href="http://allegro.tech/">Allegro</a> we are on track with our clickstream ingestion platform.
<a href="https://kafka.apache.org/">Apache Kafka</a>, <a href="https://avro.apache.org/">Apache Avro</a>, <a href="https://parquet.apache.org/">Apache Parquet</a>, <a href="https://spark.apache.org/">Apache Spark</a>, <a href="https://hive.apache.org/">Apache Hive</a> and last but not least <a href="http://druid.io/">Apache Druid</a> are key players for us, all hosted under <a href="https://www.apache.org/">Apache Foundation</a>!</li>
<li><a href="https://ignite.apache.org/">Apache Ignite</a> might solve many performance issues in Spark jobs (shared RDD) but also in MR jobs (in-memory MR, HDFS cache).
Has to be verified during next Allegro internal hackaton, for sure.</li>
<li>Integration between <a href="https://hive.apache.org/">Apache Hive</a> and <a href="http://druid.io/">Apache Druid</a> looks really promising.
Both tools are very important for Hadoop ecosystem and they complement each other quite well.</li>
<li><a href="https://calcite.apache.org/">Apache Calcite</a> seems to be important element in the Hadoop ecosystem.
I hope that the gap to mature RDBMS optimizers will be somehow filled.
It would be also great to see <a href="http://people.csail.mit.edu/matei/papers/2015/sigmod_spark_sql.pdf">Spark Catalyst</a> and <a href="https://calcite.apache.org/">Apache Calcite</a> cooperation, keep your fingers crossed.</li>
<li>Stephan Even should improve <a href="https://flink.apache.org/">Apache Flink</a> keynotes if DataArtisans want to compete with DataBricks.
<a href="https://flink.apache.org/">Apache Flink</a> architecture and overall design is awesome, FTW.</li>
<li><a href="https://www.confluent.io/blog/unifying-stream-processing-and-interactive-queries-in-apache-kafka">Queryable state in stream processing</a> is quite interesting idea to decrease latency in access to pre-aggregated data.</li>
<li><a href="https://kudu.apache.org/">Apache Kudu</a> and <a href="https://impala.apache.org/">Apache Impala</a> are on dead end, IMHO.
The concept to execute analytical queries (fast SQL on Impala) against whole set of raw data (kept in Kudu) is unrealistic.
Cloudera gains mastery in keeping their own technologies alive (e.g: <a href="https://flume.apache.org/">Apache Flume</a>).</li>
<li><a href="https://gearpump.apache.org/">Apache Gearpump</a> from Intel has lost its momentum. I really liked idea of distributed streaming framework built on Akka.</li>
<li>I was really surprised that CSV format is heavily used and what is even worse, conference speakers still talk about it.</li>
<li>Unfortunately there was no session about <a href="http://kylin.apache.org/">Apache Kylin</a>, so sad.</li>
</ul>


<h2>TL;DR</h2>

<h3>Stream processing as a foundational paradigm and Apache Flink&rsquo;s approach to it by Stephan Ewen (Data Artisans)</h3>

<ul>
<li>With Flink you dont have to trade off either latency, throughput, or result accuracy &ndash; nice, single sentence to describe the framework.</li>
<li>Asynchronous Distributed Snapshot is a key to achieve fault tolerance and avoid stop the world.
See also:
<a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html">https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html</a></li>
<li>Application rolling updates with state versioning.
See also:
<a href="http://data-artisans.com/how-apache-flink-enables-new-streaming-applications/">http://data-artisans.com/how-apache-flink-enables-new-streaming-applications/</a></li>
<li>Roadmap: <a href="http://flink-forward.org/wp-content/uploads/2016/07/Till-Rohrmann-Dynamic-Scaling-How-Apache-Flink-adapts-to-changing-workloads.pdf">elastic parallelism</a> (to scale out/in stateful jobs),
realtime queries using <a href="https://calcite.apache.org/docs/stream.html">Apache Calcite Streaming SQL</a>.</li>
</ul>


<h3>Apache Gearpump next-gen streaming engine by Karol Brejna, Huafeng Wang (Intel)</h3>

<ul>
<li><a href="http://trustedanalytics.org/">Trusted Analytics Platform</a> &ndash; self service platform for data scientists, developers and system operators.</li>
<li>Roadmap: integration with <a href="http://beam.incubator.apache.org/">Apache Beam</a>, materializer for <a href="http://akka.io/">Akka Streams</a>.</li>
<li>Oh, I forgot &ndash; chinese english is terrible.</li>
</ul>


<h3>An overview on optimization in Apache Hive: past, present, future by Jesus Rodriguez (HortonWorks)</h3>

<ul>
<li>Goals &ndash; sub-seconds latency, petabyte scale, ANSI SQL &ndash; never ending story.</li>
<li>Metastore is often a bottleneck (DataNucleus ORM).
See also:
<a href="https://cwiki.apache.org/confluence/display/Hive/Design#Design-MetastoreArchitecture">https://cwiki.apache.org/confluence/display/Hive/Design#Design-MetastoreArchitecture</a></li>
<li>Metastore on HBase (Hive 2.x, alpha).</li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive">Cost Based Optimizer</a> (Apache Calcite), integrated from 0.14, enabled by default from 2.0.</li>
<li>Optimizations: push down projections, push down filtering,
join reordering (<a href="http://hortonworks.com/blog/hive-0-14-cost-based-optimizer-cbo-technical-overview/">bushy joins</a>),
propagate projections, propagate filtering and more.</li>
<li>New feature: materialized views. Cons: up-to-date statistics, optimizer could use view instead of table.
See more:
<a href="https://issues.apache.org/jira/browse/HIVE-10459">HIVE-10459</a></li>
<li>Roadmap: optimizations based on CPU/MEM/IO costs.</li>
</ul>


<h3>Distributed in-database machine learning with Apache MADlib by Roman Shaposhnik (Pivotal)</h3>

<ul>
<li>Machine learning algorithms implemented as distributed UDFs.</li>
<li>Works on PostgreSQL and its forks (<a href="http://greenplum.org/">Pivotal Greenplum</a>, <a href="http://hawq.incubator.apache.org/">Apache HAWQ</a>).</li>
<li>PivotalR + RPostgres for data scientists.
See more:
<a href="https://cran.r-project.org/web/packages/PivotalR/PivotalR.pdf">https://cran.r-project.org/web/packages/PivotalR/PivotalR.pdf</a></li>
<li>Roadmap: more algorithms, execution on GPU with <a href="http://www.nvidia.com/object/cuda_home_new.html">CUDA</a>.</li>
</ul>


<h3>Interactive analytics at scale in Hive using Druid by Jesus Rodriguez (HortonWorks)</h3>

<ul>
<li>It works, at least on Jesus laptop with unreleased Hive version.</li>
<li>Druid is used as a library (more or less).</li>
<li>Druid indexing service is not used for indexing (regular Hive MR is used instead).</li>
<li>Druid broker is used for querying but there are plans to bypass broker and access historical/realtime/indexing nodes directly.
Right now the broker might be a bottleneck.</li>
<li><a href="https://calcite.apache.org/docs/druid_adapter.html">Apache Calcite</a> is a key player in the integration.</li>
<li>Pros: schema discovery.</li>
<li>Cons: dims/metrics are inferred, right now there is no way to specify all important index details (e.g: time granularities).</li>
<li>Roadmap: push down more things into the Druid for better query performance.
See more:
<a href="https://cwiki.apache.org/confluence/display/Hive/Druid+Integration">https://cwiki.apache.org/confluence/display/Hive/Druid+Integration</a></li>
</ul>


<h3>Hadoop at Uber by Mayank Basal (Uber)</h3>

<ul>
<li>Fast pace of changes, respect!</li>
<li>Shared cluster for batch jobs (YARN) and realtime jobs (Mesos) &ndash;> better resources utilization.</li>
<li><a href="https://myriad.apache.org/">Apache Myriad</a> (YARN on Mesos): static allocation, no global quotas, no global priorities and many more limitations and problems.</li>
<li>Unified Scheduler &ndash; just the name without any details yet.</li>
</ul>


<h3>Spark Performance by Tim Ellison (IBM)</h3>

<ul>
<li>Contribution to Spark in IBM way (closed solutions, heavily dependant on IBM JVM and IBM hardware).</li>
<li><a href="https://www.ibm.com/developerworks/java/jdk/spark/">Spark-kit</a> (e.g custom block manager).</li>
<li>Scala code (higher order functions) is extremely hard to optimize by JMV (e.g. using inlining)</li>
<li>Mentioned benchmarks: <a href="http://www.tpc.org/tpch/">TCP-H</a>, <a href="https://github.com/intel-hadoop/HiBench">HiBench</a></li>
<li>Remote Access Memory Access (<a href="https://en.wikipedia.org/wiki/Remote_direct_memory_access">RDMA</a>) &ndash; zero copy networking</li>
<li>Java Socket Over RDMA (<a href="http://www.ibm.com/developerworks/library/j-transparentaccel/">JSOR</a>)</li>
<li>Coherent Accelerator Processor Interface (CAPI) to delegate processing to GPU
<a href="https://en.wikipedia.org/wiki/Coherent_Accelerator_Processor_Interface">https://en.wikipedia.org/wiki/Coherent_Accelerator_Processor_Interface</a></li>
<li>Algebraic operations on GPU (performance gain only for huge matrices, there is a noticeable overhead when data is copied between CPU and GPU).</li>
<li>And much more, low level technical details, look into the presentation by yourself:
<a href="http://www.slideshare.net/JontheBeach/a-java-implementers-guide-to-boosting-apache-spark-performance-by-tim-ellison">http://www.slideshare.net/JontheBeach/a-java-implementers-guide-to-boosting-apache-spark-performance-by-tim-ellison</a></li>
</ul>


<h3>Apache Calcite and Apache Geode by Christian Tzolov (Pivotal)</h3>

<ul>
<li>Apache Geode (AKA Gemfire) &ndash; distributed hashmap, consistent, transactional, partitioned, replicated, etc.</li>
<li><a href="https://cwiki.apache.org/confluence/display/GEODE/PDX+Serialization+Internals">PDX serialization</a>, on field level, type registry.</li>
<li>Nested regions.</li>
<li>Embeddable.</li>
<li>Object Query Language (OQL) ~ SQL.</li>
<li>Apache Calcite adapter (work in progress).
The adapter might be implemented gradually (from in-memory enumerable to advanced pushdowns/optimizations and bindable generated code).</li>
<li><a href="https://github.com/apache/calcite/tree/master/linq4j">Linq4j</a> ported from .NET.</li>
</ul>


<h3>Data processing pipeline at Trivago by Clemens Valiente (Trivago)</h3>

<ul>
<li>Separated datacenters, REST collectors with HDD fallback, Apache Kafka, Camus, CSV.</li>
<li>Hive MR jobs prepare aggregates and data subsets for Apache Impala, <a href="http://oozie.apache.org/">Apache Oozie</a> used as scheduler.</li>
<li>Problems with memory leaks in Apache Impala.</li>
<li><a href="http://shiny.rstudio.com/">R/Shiny</a> connected to Impala for analytical purposes.</li>
<li>Roadmap: <a href="https://www.confluent.io/product/kafka-streams/">Kafka Streams</a>, Impala + Kudu, Kylin + HBase.</li>
<li>Interesting concept: direct access to Kafka Streams state (queryable <a href="http://rocksdb.org/">RocksDB</a>).</li>
</ul>


<h3>Implementing BigPetStore in Spark and Flink by Marton Balasi (Cloudera)</h3>

<ul>
<li><a href="https://github.com/apache/bigtop">BigTop</a> &ndash; way to build packages or setup big data servers and tools locally.</li>
<li><a href="https://github.com/apache/bigtop/tree/master/bigtop-bigpetstore">BigPetStore</a> &ndash; generates synthethic data + sample stats calculation + sample recommendation (collaborative filtering).</li>
<li>MR, Spark, <a href="https://github.com/bigpetstore/bigpetstore-flink">Flink</a> implementations &ndash; nice method to learn Flink if you already know Spark.</li>
</ul>


<h3>Introduction to TensorFlow by Gemma Parreno</h3>

<ul>
<li>Global finalist of <a href="https://2016.spaceappschallenge.org/challenges/solar-system/near-earth-objects-machine-learning/projects/deep-asteriod">NASA Space App Challenge</a>, congrats!</li>
<li>Extremely interesting session, but Ive been totally lost &ndash; too much science :&ndash;(</li>
</ul>


<h3>&ldquo;Shared Memory Layer and Faster SQL for Spark Applications&rdquo; by Dmitriy Setrakyan (GridGain)</h3>

<ul>
<li>Apache Ignite is a in-memory data grid, compute grid, service grid, messaging and more.</li>
<li>Off heap, <a href="https://en.wikipedia.org/wiki/Slab_allocation">slab allocation</a></li>
<li>Run on <a href="https://apacheignite.readme.io/docs/yarn-deployment">YARN</a></li>
<li>Run on <a href="https://apacheignite.readme.io/docs/mesos-deployment">Mesos/Marathon</a></li>
<li>Shared, mutable, indexed, queryable RDD.
See more:
<a href="https://ignite.apache.org/use-cases/spark/shared-memory-layer.html">https://ignite.apache.org/use-cases/spark/shared-memory-layer.html</a></li>
<li>In-memory MR (name node, job tracker and task trackers are totally bypassed).
See more:
<a href="https://ignite.apache.org/use-cases/hadoop/mapreduce">https://ignite.apache.org/use-cases/hadoop/mapreduce</a></li>
<li>HDFS cache (e.g: for caching hot data sets).
See more:
<a href="https://ignite.apache.org/use-cases/hadoop/hdfs-cache">https://ignite.apache.org/use-cases/hadoop/hdfs-cache</a></li>
<li>Roadmap: dataframe compatible queries.</li>
</ul>


<h3>&ldquo;Apache CouchDB&rdquo; by Jan Lehnardt (Neighbourhoodie Software)</h3>

<ul>
<li>Master-master key-value store.</li>
<li>HTTP as protocol.</li>
<li>JSON as storage format.</li>
<li>Simplified vector clock for conflicts handling (document hashes, consistent across cluster).</li>
<li>Entertaining part about handling time in distributed systems, highly recommended.</li>
<li><a href="https://arxiv.org/pdf/1608.03960.pdf">Conflict-Free Replicated JSON Datatype</a> was mentioned by Jan during talk, interesting.</li>
<li>Roadmap: HTTP2, pluggable storage format, improved protocol for high latency networks.</li>
</ul>


<h3>Java memory leaks in modular environment by Mark Thomas (Pivotal)</h3>

<ul>
<li>Did you remember OutOfMemoryError: PermGen space in Tomcat? It is mostly not Tomcat fault.</li>
<li>You should always set <code>-XX:MaxMetaspaceSize</code> in production systems.</li>
<li>Excellent memory leaks analysis live demo using YourKit profiler (leaks in awt, java2d, rmi, xml).
<a href="https://github.com/markt-asf/memory-leaks">https://github.com/markt-asf/memory-leaks</a></li>
</ul>


<h3>Children and the art of coding by Sebastien Blanc (RedHat)</h3>

<ul>
<li>The best, entertaining session on the conference, IMHO!
If you are happy parent, you should watch Sebastien&rsquo;s session (unfortunately sessions were not recorded, AFAIK).</li>
<li>Logo, Scratch, Groovy, Arduino and <a href="http://makeymakey.com/">Makey Makey</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Long-running Spark Streaming Jobs on YARN Cluster]]></title>
    <link href="http://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/"/>
    <updated>2016-09-30T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn</id>
    <content type="html"><![CDATA[<p>A long-running Spark Streaming job, once submitted to the YARN cluster should run forever until it is intentionally stopped.
Any interruption introduces substantial processing delays and could lead to data loss or duplicates.
Neither YARN nor Apache Spark have been designed for executing long-running services.
But they have been successfully adapted to growing needs of near real-time processing implemented as long-running jobs.
Successfully does not necessarily mean without technological challenges.</p>

<p>This blog post summarizes my experiences in running mission critical, long-running Spark Streaming jobs on a secured YARN cluster.
You will learn how to submit Spark Streaming application to a YARN cluster to avoid sleepless nights during on-call hours.</p>

<h2>Fault tolerance</h2>

<p>In the YARN cluster mode Spark driver runs in the same container as the Application Master,
the first YARN container allocated by the application.
This process is responsible for driving the application and requesting resources (Spark executors) from YARN.
What is important, Application Master eliminates need for any another process that run during application lifecycle.
Even if an edge Hadoop cluster node where the Spark Streaming job was submitted fails, the application stays unaffected.</p>

<p>To run Spark Streaming application in the cluster mode, ensure that the following parameters are given to spark-submit command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster</span></code></pre></td></tr></table></div></figure>


<p>Because Spark driver and Application Master share a single JVM, any error in Spark driver stops our long-running job.
Fortunately it is possible to configure maximum number of attempts that will be made to re-run the application.
It is reasonable to set higher value than default 2 (derived from YARN cluster property <code>yarn.resourcemanager.am.max-attempts</code>).
For me 4 works quite well, higher value may cause unnecessary restarts even if the reason of the failure is permanent.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>    --conf spark.yarn.maxAppAttempts=4</span></code></pre></td></tr></table></div></figure>


<p>If the application runs for days or weeks without restart or redeployment on highly utilized cluster, 4 attempts could be exhausted in few hours.
To avoid this situation, the attempt counter should be reset on every hour of so.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>    --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>    --conf spark.yarn.am.attemptFailuresValidityInterval=1h</span></code></pre></td></tr></table></div></figure>


<p>Another important setting is a maximum number of executor failures before the application fails.
By default it is <code>max(2 * num executors, 3)</code>, well suited for batch jobs but not for long-running jobs.
The property comes with corresponding validity interval which also should be set.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>    --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>    --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>    --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>    --conf spark.yarn.executor.failuresValidityInterval=1h</span></code></pre></td></tr></table></div></figure>


<p>For long-running jobs you could also consider to boost maximum number of task failures before giving up the job.
By default tasks will be retried 4 times and then job fails.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>    --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>    --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>    --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>    --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>    --conf spark.task.maxFailures=8</span></code></pre></td></tr></table></div></figure>


<p></p>

<h2>Performance</h2>

<p>When a Spark Streaming application is submitted to the cluster, YARN queue where the job runs must be defined.
I strongly recommend using YARN <a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
and submitting long-running jobs to separate queue.
Without a separate YARN queue your long-running job will be preempted by a massive Hive query sooner or later.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>    --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>    --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>    --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>    --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>    --conf spark.task.maxFailures=8 \
</span><span class='line'>    --queue realtime_queue</span></code></pre></td></tr></table></div></figure>


<p>Another important issue for Spark Streaming job is keeping processing time stable and highly predictable.
Processing time should stay below batch duration to avoid delays.
I&rsquo;ve found that Spark speculative execution helps a lot, especially on a busy cluster.
Batch processing times are much more stable when speculative execution is enabled.
Unfortunately speculative mode can be enabled only if Spark actions are idempotent.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>    --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>    --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>    --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>    --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>    --conf spark.task.maxFailures=8 \
</span><span class='line'>    --queue realtime_queue \
</span><span class='line'>    --conf spark.speculation=true</span></code></pre></td></tr></table></div></figure>


<h2>Security</h2>

<p>On a secured HDFS cluster, long-running Spark Streaming jobs fails due to Kerberos ticket expiration.
Without additional settings, Kerberos ticket is issued when Spark Streaming job is submitted to the cluster.
When ticket expires Spark Streaming job is not able to write or read data from HDFS anymore.</p>

<p>In theory (based on documentation) it should be enough to pass Kerberos principal and keytab as spark-submit command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>     --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>     --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>     --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>     --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>     --conf spark.task.maxFailures=8 \
</span><span class='line'>     --queue realtime_queue \
</span><span class='line'>     --conf spark.speculation=true \
</span><span class='line'>     --principal user/hostname@domain \
</span><span class='line'>     --keytab /path/to/foo.keytab</span></code></pre></td></tr></table></div></figure>


<p>In practice, due to several bugs (<a href="https://issues.apache.org/jira/browse/HDFS-9276">HDFS-9276</a>, <a href="https://issues.apache.org/jira/browse/SPARK-11182">SPARK-11182</a>)
HDFS cache must be disabled. If not, Spark will not be able to read updated token from file on HDFS.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>     --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>     --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>     --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>     --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>     --conf spark.task.maxFailures=8 \
</span><span class='line'>     --queue realtime_queue \
</span><span class='line'>     --conf spark.speculation=true \
</span><span class='line'>     --principal user/hostname@domain \
</span><span class='line'>     --keytab /path/to/foo.keytab \
</span><span class='line'>     --conf spark.hadoop.fs.hdfs.impl.disable.cache=true</span></code></pre></td></tr></table></div></figure>


<p>Mark Grover pointed out that those bugs only affect HDFS cluster configured with NameNodes in
<a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">HA mode</a>.
Thanks, Mark.</p>

<h2>Logging</h2>

<p>The easiest way to access Spark application logs is to configure Log4j console appender,
wait for application termination and use <code>yarn logs -applicationId [applicationId]</code> command.
Unfortunately it is not feasible to terminate long-running Spark Streaming jobs to access the logs.</p>

<p>I recommend to install and configure Elastic, Logstash and Kibana (<a href="https://www.elastic.co/">ELK</a> stack).
ELK installation and configuration is out of this blog post scope,
but remember to log the following context fields:</p>

<ul>
<li>YARN application id</li>
<li>YARN container hostname</li>
<li>Executor id (Spark driver is always 000001, Spark executors start from 000002)</li>
<li>YARN attempt (to check how many times Spark driver has been restarted)</li>
</ul>


<p>Log4j configuration with Logstash specific appender and layout definition should be passed to spark-submit command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>     --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>     --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>     --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>     --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>     --conf spark.task.maxFailures=8 \
</span><span class='line'>     --queue realtime_queue \
</span><span class='line'>     --conf spark.speculation=true \
</span><span class='line'>     --principal user/hostname@domain \
</span><span class='line'>     --keytab /path/to/foo.keytab \
</span><span class='line'>     --conf spark.hadoop.fs.hdfs.impl.disable.cache=true \
</span><span class='line'>     --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties \
</span><span class='line'>     --conf spark.executor.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties \
</span><span class='line'>     --files /path/to/log4j.properties</span></code></pre></td></tr></table></div></figure>


<p>Finally Kibana dashboard for Spark Job might look like:</p>

<p><img src="http://mkuthan.github.io/images/blog/spark_job_logging.png" title="[spark job logging]" ></p>

<h2>Monitoring</h2>

<p>Long running job runs 24/7 so it is important to have an insight into historical metrics.
Spark UI keeps statistics only for limited number of batches, and after restart all metrics are gone.
Again, external tools are needed.
I recommend to install <a href="https://graphiteapp.org/">Graphite</a> for collecting metrics
and <a href="http://grafana.org/">Grafana</a> for building dashboards.</p>

<p>First, Spark needs to be configured to report metrics into Graphite, prepare the <code>metrics.properties</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>*.sink.graphite.class=org.apache.spark.metrics.sink.GraphiteSink
</span><span class='line'>*.sink.graphite.host=[hostname]
</span><span class='line'>*.sink.graphite.port=[port]
</span><span class='line'>*.sink.graphite.prefix=some_meaningful_name
</span><span class='line'>
</span><span class='line'>driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource
</span><span class='line'>executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource</span></code></pre></td></tr></table></div></figure>


<p>And configure spark-submit command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-submit --master yarn --deploy-mode cluster \
</span><span class='line'>     --conf spark.yarn.maxAppAttempts=4 \
</span><span class='line'>     --conf spark.yarn.am.attemptFailuresValidityInterval=1h \
</span><span class='line'>     --conf spark.yarn.max.executor.failures={8 * num_executors} \
</span><span class='line'>     --conf spark.yarn.executor.failuresValidityInterval=1h \
</span><span class='line'>     --conf spark.task.maxFailures=8 \
</span><span class='line'>     --queue realtime_queue \
</span><span class='line'>     --conf spark.speculation=true \
</span><span class='line'>     --principal user/hostname@domain \
</span><span class='line'>     --keytab /path/to/foo.keytab \
</span><span class='line'>     --conf spark.hadoop.fs.hdfs.impl.disable.cache=true \
</span><span class='line'>     --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties \
</span><span class='line'>     --conf spark.executor.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties \
</span><span class='line'>     --files /path/to/log4j.properties:/path/to/metrics.properties</span></code></pre></td></tr></table></div></figure>


<h3>Metrics</h3>

<p>Spark publishes tons of metrics from driver and executors.
If I were to choose the most important one, it would be the last received batch records.
When <code>StreamingMetrics.streaming.lastReceivedBatch_records == 0</code> it probably means that Spark Streaming job has been stopped or failed.</p>

<p>Other important metrics are listed below:</p>

<ul>
<li>When total delay is greater than batch interval, latency of the processing pipeline increases.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>driver.StreamingMetrics.streaming.lastCompletedBatch_totalDelay</span></code></pre></td></tr></table></div></figure>


<ul>
<li>When number of active tasks is lower than <code>number of executors * number of cores</code>, allocated YARN resources are not fully utilized.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>executor.threadpool.activeTasks</span></code></pre></td></tr></table></div></figure>


<ul>
<li>How much RAM is used for RDD cache.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>driver.BlockManager.memory.memUsed_MB</span></code></pre></td></tr></table></div></figure>


<ul>
<li>When there is not enough RAM for RDD cache, how much data has been spilled to disk.
You should increase executor memory or change <code>spark.memory.fraction</code> Spark property to avoid performance degradation.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>driver.BlockManager.disk.diskSpaceUsed_MB</span></code></pre></td></tr></table></div></figure>


<ul>
<li>What is JVM memory utilization on Spark driver.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>driver.jvm.heap.used
</span><span class='line'>driver.jvm.non-heap.used
</span><span class='line'>driver.jvm.pools.G1-Old-Gen.used
</span><span class='line'>driver.jvm.pools.G1-Eden-Space.used
</span><span class='line'>driver.jvm.pools.G1-Survivor-Space.used</span></code></pre></td></tr></table></div></figure>


<ul>
<li>How much time is spent on GC on Spark driver.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>driver.jvm.G1-Old-Generation.time
</span><span class='line'>driver.jvm.G1-Young-Generation.time</span></code></pre></td></tr></table></div></figure>


<ul>
<li>What is JMV memory utilization on Spark executors.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[0-9]*.jvm.heap.used
</span><span class='line'>[0-9]*.jvm.non-heap.used
</span><span class='line'>[0-9]*.jvm.pools.G1-Old-Gen.used
</span><span class='line'>[0-9]*.jvm.pools.G1-Survivor-Space.used
</span><span class='line'>[0-9]*.jvm.pools.G1-Eden-Space.used</span></code></pre></td></tr></table></div></figure>


<ul>
<li>How much time is spent on GC on Spark executors.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[0-9]*.jvm.G1-Old-Generation.time
</span><span class='line'>[0-9]*.jvm.G1-Young-Generation.time</span></code></pre></td></tr></table></div></figure>


<h3>Grafana</h3>

<p>While you configure first Grafana dashboard for Spark application, the first problem pops up:</p>

<blockquote><p>How to configure Graphite query when metrics for every Spark application run are reported under its own application id?</p></blockquote>

<p>If you are lucky and brave enough to use Spark 2.1, pin the application metric into static application name:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>--conf spark.metrics.namespace=my_application_name</span></code></pre></td></tr></table></div></figure>


<p>For Spark versions older than 2.1, a few tricks with Graphite built-in functions are needed.</p>

<p>Driver metrics use wildcard <code>.*(application_[0-9]+).*</code>
and <code>aliasSub</code> Graphite function to present &lsquo;application id&rsquo; as graph legend:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>aliasSub(stats.analytics.$job_name.*.prod.$dc.*.driver.jvm.heap.used, ".*(application_[0-9]+).*", "heap: \1")</span></code></pre></td></tr></table></div></figure>


<p>For executor metrics again use wildcard <code>.*(application_[0-9]+).*</code>,
<code>groupByNode</code> Graphite function to sum metrics from all Spark executors
and finally <code>aliasSub</code> Graphite function to present &lsquo;application id&rsquo; as graph legend:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>aliasSub(groupByNode(stats.analytics.$job_name.*.prod.$dc.*.[0-9]*.jvm.heap.used, 6, "sumSeries"), "(.*)", "heap: \1")</span></code></pre></td></tr></table></div></figure>


<p>Finally Grafana dashboard for Spark Job might look like:</p>

<p><img src="http://mkuthan.github.io/images/blog/spark_job_monitoring.png" title="[spark job monitoring]" ></p>

<p>If Spark application is restarted frequently, metrics for old, already finished runs should be deleted from Graphite.
Because Graphite does not compact inactive metrics, old metrics slow down Graphite itself and Grafana queries.</p>

<h2>Graceful stop</h2>

<p>The last puzzle element is how to stop Spark Streaming application deployed on YARN in a graceful way.
The standard method for stopping (or rather killing) YARN application is using a command <code>yarn application -kill [applicationId]</code>.
And this command stops the Spark Streaming application but this could happen in the middle of a batch.
So if the job reads data from Kafka, saves processing results on HDFS and finally commits Kafka offsets
you should expect duplicated data on HDFS when job was stopped just before committing offsets.</p>

<p>The first attempt to solve graceful shutdown issue was to call Spark streaming context stop method in a shutdown hook.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">sys</span><span class="o">.</span><span class="n">addShutdownHook</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">streamingContext</span><span class="o">.</span><span class="n">stop</span><span class="o">(</span><span class="n">stopSparkContext</span> <span class="k">=</span> <span class="kc">true</span><span class="o">,</span> <span class="n">stopGracefully</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Disappointingly a shutdown hook is called too late to finish started batch and Spark application is killed almost immediately.
Moreover there is no guarantee that a shutdown hook will be called by JVM at all.</p>

<p>At the time of writing this blog post the only confirmed way to shutdown gracefully Spark Streaming application on YARN
is to notifying somehow the application about planned shutdown, and then stop streaming context programmatically (but not from shutdown hook).
Command <code>yarn application -kill</code> should be used only as a last resort if notified application did not stop after defined timeout.</p>

<p>The application can be notified about planned shutdown using marker file on HDFS (the easiest way),
or using simple Socket/HTTP endpoint exposed on the driver (sophisticated way).</p>

<p>Because I like KISS principle, below you can find shell script pseudo-code for starting / stopping Spark Streaming application using marker file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>start<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    hdfs dfs -touchz /path/to/marker/my_job_unique_name
</span><span class='line'>    spark-submit ...
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'>stop<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    hdfs dfs -rm /path/to/marker/my_job_unique_name
</span><span class='line'>    <span class="nv">force_kill</span><span class="o">=</span><span class="nb">true</span>
</span><span class='line'><span class="nb">    </span><span class="nv">application_id</span><span class="o">=</span><span class="k">$(</span>yarn application -list | grep -oe <span class="s2">&quot;application_[0-9]*_[0-9]*&quot;</span><span class="sb">`</span><span class="o">)</span>
</span><span class='line'>    <span class="k">for </span>i in <span class="sb">`</span>seq 1 10<span class="sb">`</span>; <span class="k">do</span>
</span><span class='line'><span class="k">        </span><span class="nv">application_status</span><span class="o">=</span><span class="k">$(</span>yarn application -status <span class="k">${</span><span class="nv">application_id</span><span class="k">}</span> | grep <span class="s2">&quot;State : \(RUNNING\|ACCEPTED\)&quot;</span><span class="k">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">[</span> -n <span class="s2">&quot;$application_status&quot;</span> <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">            </span>sleep 60s
</span><span class='line'>        <span class="k">else</span>
</span><span class='line'><span class="k">            </span><span class="nv">force_kill</span><span class="o">=</span><span class="nb">false</span>
</span><span class='line'><span class="nb">            break</span>
</span><span class='line'><span class="nb">        </span><span class="k">fi</span>
</span><span class='line'><span class="k">    done</span>
</span><span class='line'>    <span class="nv">$force_kill</span> <span class="o">&amp;&amp;</span> yarn application -kill <span class="k">${</span><span class="nv">application_id</span><span class="k">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the Spark Streaming application, background thread should monitor marker file,
and when the file disappears stop the context calling <code>streamingContext.stop(stopSparkContext = true, stopGracefully = true)</code>.</p>

<h2>Summary</h2>

<p>As you could see, configuration for mission critical Spark Streaming application deployed on YARN is quite complex.
It has been long, tedious and iterative learning process of all presented techniques by a few very smart devs.
But at the end, long-running Spark Streaming applications deployed on highly utilized YARN cluster are extraordinarily stable.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark Application Assembly for Cluster Deployments]]></title>
    <link href="http://mkuthan.github.io/blog/2016/03/11/spark-application-assembly/"/>
    <updated>2016-03-11T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2016/03/11/spark-application-assembly</id>
    <content type="html"><![CDATA[<p>When I tried to deploy my first Spark application on a YARN cluster,
I realized that there was no clear and concise instruction how to prepare the application for deployment.
This blog post could be treated as missing manual on how to build Spark application written in Scala to get deployable binary.</p>

<p>This blog post assumes that your Spark application is built with <a href="http://www.scala-sbt.org/">SBT</a>.
As long as SBT is a mainstream tool for building Scala applications the assumption seems legit.
Please ensure that your project is configured with at least SBT 0.13.6.
Open <code>project/build.properties</code> file, verify the version and update SBT if needed:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sbt.version=0.13.11</span></code></pre></td></tr></table></div></figure>


<h2>SBT Assembly Plugin</h2>

<p>The <code>spark-submit</code> script is a convenient way to launch Spark application on the YARN or Mesos cluster.
However, due to distributed nature of the cluster the application has to be prepared as single Java ARchive (JAR).
This archive includes all classes from your project with all of its dependencies.
This application assembly can be prepared using <a href="https://github.com/sbt/sbt-assembly">SBT Assembly Plugin</a>.</p>

<p>To enable SBT Assembly Plugin, add the plugin dependency to the <code>project/plugins.sbt</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.14.1")</span></code></pre></td></tr></table></div></figure>


<p>This basic setup can be verified by calling <code>sbt assembly</code> command.
The final assembly location depend on the Scala version, application name and application version.
The build result could be assembled into <code>target/scala-2.11/myapp-assembly-1.0.jar</code> file.</p>

<p>You can configure many aspects of SBT Assembly Plugin like custom merge strategy
but I found that it is much easier to keep the defaults and follow the plugin conventions.
And what is even more important you don&rsquo;t have to change defaults to get correct, deployable application binary assembled by the plugin.</p>

<h2>Provided dependencies scope</h2>

<p>As long as cluster provides Spark classes at runtime, Spark dependencies must be excluded from the assembled JAR.
If not, you should expect weird errors from Java classloader during application startup.
Additional benefit of assembly without Spark dependencies is faster deployment.
Please remember that application assembly must be copied over the network to the location accessible by all cluster nodes (e.g: HDFS or S3).</p>

<p>Look at dependency section in your build file, it should look similar to the code snippet below:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val sparkVersion = "1.6.0"
</span><span class='line'>
</span><span class='line'>"org.apache.spark" %% "spark-core" % sparkVersion,
</span><span class='line'>"org.apache.spark" %% "spark-sql" % sparkVersion,
</span><span class='line'>"org.apache.spark" %% "spark-hive" % sparkVersion,
</span><span class='line'>"org.apache.spark" %% "spark-mlib" % sparkVersion,
</span><span class='line'>"org.apache.spark" %% "spark-graphx" % sparkVersion,
</span><span class='line'>"org.apache.spark" %% "spark-streaming" % sparkVersion,
</span><span class='line'>"org.apache.spark" %% "spark-streaming-kafka" % sparkVersion,
</span><span class='line'>(...)</span></code></pre></td></tr></table></div></figure>


<p>The list of the Spark dependencies is always project specific.
SQL, Hive, MLib, GraphX and Streaming extensions are defined only for reference.
All defined dependencies are required by local build to compile code and run
<a href="http://mkuthan.github.io/blog/2015/03/01/spark-unit-testing/">tests</a>.
So they could not be removed from the build definition in the ordinary way because it will break the build at all.</p>

<p>SBT Assembly Plugin comes with additional dependency scope &ldquo;provided&rdquo;.
The scope is very similar to <a href="https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html">Maven provided scope</a>.
The provided dependency will be part of compilation and test, but excluded from the application assembly.</p>

<p>To configure provided scope for Spark dependencies change the definition as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val sparkVersion = "1.6.0"
</span><span class='line'>
</span><span class='line'>"org.apache.spark" %% "spark-core" % sparkVersion % "provided",
</span><span class='line'>"org.apache.spark" %% "spark-sql" % sparkVersion % "provided",
</span><span class='line'>"org.apache.spark" %% "spark-hive" % sparkVersion % "provided",
</span><span class='line'>"org.apache.spark" %% "spark-mlib" % sparkVersion % "provided",
</span><span class='line'>"org.apache.spark" %% "spark-graphx" % sparkVersion % "provided",
</span><span class='line'>"org.apache.spark" %% "spark-streaming" % sparkVersion % "provided",
</span><span class='line'>"org.apache.spark" %% "spark-streaming-kafka" % sparkVersion
</span><span class='line'>  exclude("log4j", "log4j")
</span><span class='line'>  exclude("org.spark-project.spark", "unused"),
</span><span class='line'>(...)</span></code></pre></td></tr></table></div></figure>


<p>Careful readers should notice that &ldquo;spark-streaming-kafka&rdquo; dependency has not been listed and marked as &ldquo;provided&rdquo;.
It was done by purpose because integration with Kafka is not part of Spark distribution assembly
and has to be assembled into application JAR.
The exclusion rules for &ldquo;spark-streaming-kafka&rdquo; dependency will be discussed later.</p>

<p>Ok, but how to recognize which libraries are part of Spark distribution assembly?
There is no simple answer to this question.
Look for <code>spark-assembly-*-1.6.0.jar</code> file on the cluster classpath,
list the assembly content and verify what is included and what is not.
In the assembly on my cluster I found core, sql, hive, mlib, graphx and streaming classes are embedded but not integration with Kafka.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tar -tzf spark-assembly-1.6.0.jar
</span><span class='line'>META-INF/
</span><span class='line'>META-INF/MANIFEST.MF
</span><span class='line'>org/
</span><span class='line'>org/apache/
</span><span class='line'>org/apache/spark/
</span><span class='line'>org/apache/spark/HeartbeatReceiver
</span><span class='line'>(...)
</span><span class='line'>org/apache/spark/ml/
</span><span class='line'>org/apache/spark/ml/Pipeline$SharedReadWrite$$anonfun$2.class
</span><span class='line'>org/apache/spark/ml/tuning/
</span><span class='line'>(...)
</span><span class='line'>org/apache/spark/sql/
</span><span class='line'>org/apache/spark/sql/UDFRegistration$$anonfun$3.class
</span><span class='line'>org/apache/spark/sql/SQLContext$$anonfun$range$2.class
</span><span class='line'>(...)
</span><span class='line'>reference.conf
</span><span class='line'>META-INF/NOTICE</span></code></pre></td></tr></table></div></figure>


<h2>SBT run and run-main</h2>

<p>Provided dependency scope unfortunately breaks SBT <code>run</code> and <code>run-main</code> tasks.
Because provided dependencies are excluded from the runtime classpath, you should expect <code>ClassNotFoundException</code> during application startup on local machine.
To fix this issue, provided dependencies must be explicitly added to all SBT tasks used for local run, e.g.:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>run in Compile &lt;&lt;= Defaults.runTask(fullClasspath in Compile, mainClass in(Compile, run), runner in(Compile, run))
</span><span class='line'>runMain in Compile &lt;&lt;= Defaults.runMainTask(fullClasspath in Compile, runner in(Compile, run))</span></code></pre></td></tr></table></div></figure>


<h2>How to exclude Log4j from application assembly?</h2>

<p>Without Spark classes the application assembly is quite lightweight.
But the assembly size might be reduced event more!</p>

<p>Let assume that your application requires some logging provider.
As long as Spark internally uses Log4j, it means that Log4j is already on the cluster classpath.
But you may say that there is much better API for Scala than origin Log4j &ndash; and you are totally right.</p>

<p>The snippet below configure excellent Typesafe (Lightbend nowadays) <a href="https://github.com/typesafehub/scala-logging">Scala Logging Library</a> dependency.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>"com.typesafe.scala-logging" %% "scala-logging" % "3.1.0",
</span><span class='line'>
</span><span class='line'>"org.slf4j" % "slf4j-api" % "1.7.10",
</span><span class='line'>"org.slf4j" % "slf4j-log4j12" % "1.7.10" exclude("log4j", "log4j"),
</span><span class='line'>
</span><span class='line'>"log4j" % "log4j" % "1.2.17" % "provided",</span></code></pre></td></tr></table></div></figure>


<p>Scala Logging is a thin wrapper for SLF4J implemented using Scala macros.
The &ldquo;slf4j-log4j12&rdquo; is a binding library between SLF4J API and Log4j logger provider.
Three layers of indirection but who cares :&ndash;)</p>

<p>There is also top-level dependency to Log4J defined with provided scope.
But this is not enough to get rid of Log4j classes from the application assembly.
Because Log4j is also a transitive dependency of &ldquo;slf4j-log4j12&rdquo; it must be explicitly excluded.
If not, SBT Assembly Plugin adds Log4j classes to the assembly even if top level &ldquo;log4j&rdquo; dependency is marked as &ldquo;provided&rdquo;.
Not very intuitive but SBT Assembly Plugin works this way.</p>

<p>Alternatively you could disable transitive dependencies for &ldquo;slf4j-log4j12&rdquo; at all.
It could be especially useful for libraries with many transitive dependencies which are expected to be on the cluster classpath.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>"org.slf4j" % "slf4j-log4j12" % "1.7.10" intransitive()</span></code></pre></td></tr></table></div></figure>


<h2>Spark Streaming Kafka dependency</h2>

<p>Now we are ready to define dependency to &ldquo;spark-streaming-kafka&rdquo;.
Because Spark integration with Kafka typically is not a part of Spark assembly,
it must be embedded into application assembly.
The artifact should not be defined within &ldquo;provided&rdquo; scope.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val sparkVersion = "1.6.0"
</span><span class='line'>
</span><span class='line'>(...)
</span><span class='line'>"org.apache.spark" %% "spark-streaming-kafka" % sparkVersion
</span><span class='line'>  exclude("log4j", "log4j")
</span><span class='line'>  exclude("org.spark-project.spark", "unused"),
</span><span class='line'>(...)</span></code></pre></td></tr></table></div></figure>


<p>Again, &ldquo;log4j&rdquo; transitive dependency of Kafka needs to be explicitly excluded.
I also found that marker class from weird Spark &ldquo;unused&rdquo; artifact breaks default SBT Assembly Plugin merge strategy.
It is much easier to exclude this dependency than customize merge strategy of the plugin.</p>

<h2>Where is Guava?</h2>

<p>When you look at your project dependencies you could easily find Guava (version 14.0.1 for Spark 1.6.0).
Ok, Guava is an excellent library so you decide to use the library in your application.</p>

<p><em>WRONG!</em></p>

<p>Guava is on the classpath during compilation and tests but at runtime you will get &ldquo;ClassNotFoundException&rdquo; or method not found error.
First, Guava is shaded in Spark distribution assembly under <code>org/spark-project/guava</code> package and should not be used directly.
Second, there is a huge chance for outdated Guava library on the cluster classpath.
In CDH 5.3 distribution, the installed Guava version is 11.0.2 released on Feb 22, 2012 &ndash; more than 4 years ago!
Since the Guava is <a href="http://i.stack.imgur.com/8K6N8.jpg">binary compatible</a> only between 2 or 3 latest major releases it is a real blocker.</p>

<p>There are experimental configuration flags for Spark <code>spark.driver.userClassPathFirst</code> and <code>spark.executor.userClassPathFirst</code>.
In theory it gives user-added jars precedence over Spark&rsquo;s own jars when loading classes in the the driver.
But in practice it does not work, at least for me :&ndash;(.</p>

<p>In general you should avoid external dependencies at all cost when you develop application deployed on the YARN cluster.
Classloader hell is even bigger than in JEE containers like JBoss or WebLogic.
Look for the libraries with minimal transitive dependencies and narrowed features.
For example, if you need a cache, choose <a href="https://github.com/ben-manes/caffeine">Caffeine</a> over Guava.</p>

<h2>Deployment optimization for YARN cluster</h2>

<p>When application is deployed on YARN cluster using <code>spark-submit</code> script,
the script upload Spark distribution assembly to the cluster during every deployment.
The distribution assembly size is over 100MB, ten times more than typical application assembly!</p>

<p>So I really recommend to install Spark distribution assembly on well known location on the cluster
and define <code>spark.yarn.jar</code> property for <code>spark-submit</code>.
The assembly will not be copied over the network during every deployment.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark.yarn.jar=hdfs:///apps/spark/assembly/spark-assembly-1.6.0.jar</span></code></pre></td></tr></table></div></figure>


<h2>Summary</h2>

<p>I witnessed a few Spark projects where <code>build.sbt</code> were more complex than application itself.
And application assembly was bloated with unnecessary 3rd party classes and deployment process took ages.
Build configuration described in this blog post should help you deploy Spark application on the cluster smoothly
and still keep SBT configuration easy to maintain.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark and Kafka Integration Patterns, Part 2]]></title>
    <link href="http://mkuthan.github.io/blog/2016/01/29/spark-kafka-integration2/"/>
    <updated>2016-01-29T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2016/01/29/spark-kafka-integration2</id>
    <content type="html"><![CDATA[<p>In the <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101">world beyond batch</a>,
streaming data processing is a future of dig data.
Despite of the streaming framework using for data processing, tight integration with replayable data source like Apache Kafka is often required.
The streaming applications often use Apache Kafka as a data source, or as a destination for processing results.</p>

<p>Apache Spark distribution has built-in support for reading from Kafka, but surprisingly does not offer any
integration for sending processing result back to Kafka.
This blog post aims to fill this gap in the Spark ecosystem.</p>

<p>In the <a href="http://mkuthan.github.io/blog/2015/08/06/spark-kafka-integration1/">first part</a> of the series
you learned how to manage Kafka producer using Scala lazy evaluation feature
and how to reuse single Kafka producer instance on Spark executor.</p>

<p>In this blog post you will learn how to publish stream processing results to Apache Kafka in reliable way.
First you will learn how Kafka Producer is working,
how to configure Kafka producer and how to setup Kafka cluster to achieve desired reliability.
In the second part of the blog post,
I will present how to implement convenient library for sending continuous sequence of RDDs
(<a href="https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.streaming.dstream.DStream">DStream</a>)
to Apache Kafka topic, as easy as in the code snippet below.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// enable implicit conversions</span>
</span><span class='line'><span class="k">import</span> <span class="nn">KafkaDStreamSink._</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// send dstream to Kafka</span>
</span><span class='line'><span class="n">dstream</span><span class="o">.</span><span class="n">sendToKafka</span><span class="o">(</span><span class="n">kafkaProducerConfig</span><span class="o">,</span> <span class="n">topic</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Quick introduction to Kafka</h2>

<p>Kafka is a distributed, partitioned, replicated message broker.
Basic architecture knowledge is a prerequisite to understand Spark and Kafka integration challenges.
You can safely skip this section, if you are already familiar with Kafka concepts.</p>

<p>For convenience I copied essential terminology definitions directly from Kafka
<a href="http://kafka.apache.org/documentation.html#introduction">documentation</a>:</p>

<ul>
<li>Kafka maintains feeds of messages in categories called topics.</li>
<li>We&rsquo;ll call processes that publish messages to a Kafka topic producers.</li>
<li>We&rsquo;ll call processes that subscribe to topics and process the feed of published messages consumers.</li>
<li>Kafka is run as a cluster comprised of one or more servers each of which is called a broker.</li>
</ul>


<p>So, at a high level, producers send messages over the network to the Kafka cluster which in turn serves them up to consumers like this:</p>

<p><img src="http://kafka.apache.org/images/producer_consumer.png"></p>

<p>This is a bare minimum you have to know but I really encourage you to read Kafka reference manual thoroughly.</p>

<h2>Kafka producer API</h2>

<p>First we need to know how Kafka producer is working.
Kafka producer exposes very simple API for sending messages to Kafka topics.
The most important methods from <code>KafkaProducer</code> class are listed below:</p>

<figure class='code'><figcaption><span>KafkaProducer API</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">j</span><span class="o">.</span><span class="na">u</span><span class="o">.</span><span class="na">c</span><span class="o">.</span><span class="na">Future</span><span class="o">&lt;</span><span class="n">RecordMetadata</span><span class="o">&gt;</span> <span class="nf">send</span><span class="o">(</span><span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">K</span><span class="o">,</span><span class="n">V</span><span class="o">&gt;</span> <span class="n">record</span><span class="o">)</span>
</span><span class='line'><span class="n">j</span><span class="o">.</span><span class="na">u</span><span class="o">.</span><span class="na">c</span><span class="o">.</span><span class="na">Future</span><span class="o">&lt;</span><span class="n">RecordMetadata</span><span class="o">&gt;</span> <span class="nf">send</span><span class="o">(</span><span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">K</span><span class="o">,</span><span class="n">V</span><span class="o">&gt;</span> <span class="n">record</span><span class="o">,</span> <span class="n">Callback</span> <span class="n">callback</span><span class="o">)</span>
</span><span class='line'><span class="kt">void</span> <span class="nf">flush</span><span class="o">()</span>
</span><span class='line'><span class="kt">void</span> <span class="nf">close</span><span class="o">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>send()</code> methods asynchronously send a key-value record to a topic and will return immediately once the record has been stored in the buffer of records waiting to be sent.
This kind of API is not very convenient for developers, but is crucial to achieve high throughput and low latency.</p>

<p>If you want to ensure that request has been completed, you can invoke blocking <code>get()</code> on the future returned by the <code>send()</code> methods.
The main drawback of calling <code>get()</code> is a huge performance penalty because it disables batching effectively.
You can not expect high throughput and low latency if the execution is blocked on every message and every single message needs to be sent separately.</p>

<p>Fully non-blocking usage requires use of the callback. The callback will be invoked when the request is complete.
Note that callback is executed in Kafka producer I/O thread so should not block the caller, the callback must be as lightweight as possible.
The callback must be also properly synchronized due to <a href="https://en.wikipedia.org/wiki/Java_memory_model">Java memory model</a>.</p>

<p>If the Kafka producer caller does not check result of the <code>send()</code> method using future or callback,
it means that if Kafka producer crashed all messages from the internal Kafka producer buffer will be lost.
This is the first, very important element of any integration library with Kafka,
we should expect callback handling to avoid data lost and achieve good performance.</p>

<p>The <code>flush()</code> method makes all buffered messages ready to send, and blocks on the completion of the requests associated with these messages.
The <code>close()</code> method is like the <code>flush()</code> method but also closes the producer.</p>

<p>The <code>flush()</code> method could be very handy if the Streaming framework wants to ensure that all messages have been sent before processing next part of the stream.
With <code>flush()</code> method streaming framework is able to flush the messages to Kafka brokers to simulate commit behaviour.</p>

<p>Method <code>flush()</code> was added in Kafka 0.9 release (<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-8+-+Add+a+flush+method+to+the+producer+API">KIP-8</a>).
Before Kafka 0.9, the only safe and straightforward way to flush messages from Kafka producer internal buffer was to close the producer.</p>

<h2>Kafka configuration</h2>

<p>If the message must be reliable published on Kafka cluster, Kafka producer and Kafka cluster needs to be configured with care.
It needs to be done independently of chosen streaming framework.</p>

<p>Kafka producer buffers messages in memory before sending.
When our memory buffer is exhausted, Kafka producer must either stop accepting new records (block) or throw errors.
By default Kafka producer blocks and this behavior is legitimate for stream processing.
The processing should be delayed if Kafka producer memory buffer is full and could not accept new messages.
Ensure that <code>block.on.buffer.full</code> Kafka producer configuration property is set.</p>

<p>With default configuration, when Kafka broker (leader of the partition) receive the message, store the message in memory and immediately send acknowledgment to Kafka producer.
To avoid data loss the message should be replicated to at least one replica (follower).
Only when the follower acknowledges the leader, the leader acknowledges the producer.</p>

<p>This guarantee you will get with <code>ack=all</code> property in Kafka producer configuration.
This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.</p>

<p>But this is not enough. The minimum number of replicas in-sync must be defined.
You should configure <code>min.insync.replicas</code> property for every topic.
I recommend to configure at least 2 in-sync replicas (leader and one follower).
If you have datacenter with two zones, I also recommend to keep leader in the first zone and 2 followers in the second zone.
This configuration guarantees that every message will be stored in both zones.</p>

<p>We are almost done with Kafka cluster configuration.
When you set <code>min.insync.replicas=2</code> property, the topic should be replicated with factor 2 + N.
Where N is the number of brokers which could fail, and Kafka producer will still be able to publish messages to the cluster.
I recommend to configure replication factor 3 for the topic (or more).</p>

<p>With replication factor 3, the number of brokers in the cluster should be at least 3 + M.
When one or more brokers are unavailable, you will get underreplicated partitions state of the topics.
With more brokers in the cluster than replication factor, you can reassign underreplicated partitions and achieve fully replicated cluster again.
I recommend to build the 4 nodes cluster at least for topics with replication factor 3.</p>

<p>The last important Kafka cluster configuration property is <code>unclean.leader.election.enable</code>.
It should be disabled (by default it is enabled) to avoid unrecoverable exceptions from Kafka consumer.
Consider the situation when the latest committed offset is N,
but after leader failure, the latest offset on the new leader is M &lt; N.
M &lt; N because the new leader was elected from the lagging follower (not in-sync replica).
When the streaming engine ask for data from offset N using Kafka consumer, it will get an exception because the offset N does not exist yet.
Someone will have to fix offsets manually.</p>

<p>So the minimal recommended Kafka setup for reliable message processing is:</p>

<ul>
<li>4 nodes in the cluster</li>
<li><code>unclean.leader.election.enable=false</code> in the brokers configuration</li>
<li>replication factor for the topics &ndash; 3</li>
<li><code>min.insync.replicas=2</code> property in topic configuration</li>
<li><code>ack=all</code> property in the producer configuration</li>
<li><code>block.on.buffer.full=true</code> property in the producer configuration</li>
</ul>


<p>With the above setup your configuration should be resistant to single broker failure,
and Kafka consumers will survive new leader election.</p>

<p>You could also take look at <code>replica.lag.max.messages</code> and <code>replica.lag.time.max.ms</code> properties
for tuning when the follower is removed from ISR by the leader.
But this is out of this blog post scope.</p>

<h2>How to expand Spark API?</h2>

<p>After this not so short introduction, we are ready to disassembly
<a href="https://github.com/mkuthan/example-spark-kafka">integration library</a> for Spark Streaming and Apache Kafka.
First <code>DStream</code> needs to be somehow expanded to support new method <code>sendToKafka()</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">dstream</span><span class="o">.</span><span class="n">sendToKafka</span><span class="o">(</span><span class="n">kafkaProducerConfig</span><span class="o">,</span> <span class="n">topic</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>In Scala, the only way to add methods to existing API, is to use an implicit conversion feature.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">KafkaDStreamSink</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">import</span> <span class="nn">scala.language.implicitConversions</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">implicit</span> <span class="k">def</span> <span class="n">createKafkaDStreamSink</span><span class="o">(</span><span class="n">dstream</span><span class="k">:</span> <span class="kt">DStream</span><span class="o">[</span><span class="kt">KafkaPayload</span><span class="o">])</span><span class="k">:</span> <span class="kt">KafkaDStreamSink</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">new</span> <span class="nc">KafkaDStreamSink</span><span class="o">(</span><span class="n">dstream</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Whenever Scala compiler finds call to non-existing method <code>sendToKafka()</code> on <code>DStream</code> class,
the stream will be implicitly wrapped into <code>KafkaDStreamSink</code> class,
where method <code>sendToKafka</code> is finally defined.
To enable implicit conversion for <code>DStream</code> add the import statement to your code, that&rsquo;s all.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">KafkaDStreamSink._</span>
</span></code></pre></td></tr></table></div></figure>


<h2>How to send to Kafka in reliable way?</h2>

<p>Let&rsquo;s check how <code>sendToKafka()</code> method is defined step by step, this is the core part of the integration library.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">KafkaDStreamSink</span><span class="o">(</span><span class="n">dstream</span><span class="k">:</span> <span class="kt">DStream</span><span class="o">[</span><span class="kt">KafkaPayload</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">sendToKafka</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">],</span> <span class="n">topic</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">dstream</span><span class="o">.</span><span class="n">foreachRDD</span> <span class="o">{</span> <span class="n">rdd</span> <span class="k">=&gt;</span>
</span><span class='line'>      <span class="n">rdd</span><span class="o">.</span><span class="n">foreachPartition</span> <span class="o">{</span> <span class="n">records</span> <span class="k">=&gt;</span>
</span><span class='line'>        <span class="c1">// send records from every partition to Kafka</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>There are two loops, first on wrapped <code>dstream</code> and second on <code>rdd</code> for every partition.
Quite standard pattern for Spark programming model.
Records from every partition are ready to be sent to Kafka topic by Spark executors.
The destination topic name is given explicitly as the last parameter of the <code>sendToKafka()</code> method.</p>

<p>First step in the inner loop is getting Kafka producer instance from the <code>KafkaProducerFactory</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">rdd</span><span class="o">.</span><span class="n">foreachPartition</span> <span class="o">{</span> <span class="n">records</span> <span class="k">=&gt;</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">producer</span> <span class="k">=</span> <span class="nc">KafkaProducerFactory</span><span class="o">.</span><span class="n">getOrCreateProducer</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
</span><span class='line'>  <span class="o">(...)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The factory creates only single instance of the producer for any given producer configuration.
If the producer instance has been already created, the existing instance is returned and reused.
Kafka producer caching is crucial for the performance reasons,
because establishing a connection to the cluster takes time.
It is a much more time consuming operation than opening plain socket connection,
as Kafka producer needs to discover leaders for all partitions.
Please refer to <a href="http://mkuthan.github.io/blog/2015/08/06/spark-kafka-integration1/">first part</a> of this blog post
and <code>KafkaProducerFactory</code>
<a href="https://github.com/mkuthan/example-spark-kafka/blob/master/src/main/scala/org/mkuthan/spark/KafkaProducerFactory.scala">source</a>
for more details about the factory implementation.</p>

<p>For debugging purposes logger and Spark task context are needed.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.TaskContext</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.slf4j.LoggerFactory</span>
</span><span class='line'><span class="o">(...)</span>
</span><span class='line'>
</span><span class='line'><span class="n">rdd</span><span class="o">.</span><span class="n">foreachPartition</span> <span class="o">{</span> <span class="n">records</span> <span class="k">=&gt;</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">producer</span> <span class="k">=</span> <span class="nc">KafkaProducerFactory</span><span class="o">.</span><span class="n">getOrCreateProducer</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">val</span> <span class="n">context</span> <span class="k">=</span> <span class="nc">TaskContext</span><span class="o">.</span><span class="n">get</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">logger</span> <span class="k">=</span> <span class="nc">Logger</span><span class="o">(</span><span class="nc">LoggerFactory</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">KafkaDStreamSink</span><span class="o">]))</span>
</span><span class='line'>  <span class="o">(...)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You could use any logging framework but the logger itself has to be defined in the foreachPartition loop
to avoid weird serialization issues.
Spark task context will be used to get current partition identifier.
I don&rsquo;t like static call for getting task context, but this is an official way to do that.
See pull request <a href="https://github.com/apache/spark/pull/5927">SPARK-5927</a> for more details.</p>

<p>Before we go further, Kafka producer callback for error handling needs to be introduced.</p>

<figure class='code'><figcaption><span>KafkaDStreamSinkExceptionHandler</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">java.util.concurrent.atomic.AtomicReference</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.kafka.clients.producer.Callback</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">KafkaDStreamSinkExceptionHandler</span> <span class="k">extends</span> <span class="nc">Callback</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">lastException</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AtomicReference</span><span class="o">[</span><span class="kt">Option</span><span class="o">[</span><span class="kt">Exception</span><span class="o">]](</span><span class="nc">None</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">override</span> <span class="k">def</span> <span class="n">onCompletion</span><span class="o">(</span><span class="n">metadata</span><span class="k">:</span> <span class="kt">RecordMetadata</span><span class="o">,</span> <span class="n">exception</span><span class="k">:</span> <span class="kt">Exception</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span>
</span><span class='line'>    <span class="n">lastException</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="nc">Option</span><span class="o">(</span><span class="n">exception</span><span class="o">))</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">throwExceptionIfAny</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span>
</span><span class='line'>    <span class="n">lastException</span><span class="o">.</span><span class="n">getAndSet</span><span class="o">(</span><span class="nc">None</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">ex</span> <span class="k">=&gt;</span> <span class="k">throw</span> <span class="n">ex</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Method <code>onCompletion()</code> of the callback is called when the message sent to the Kafka cluster has been acknowledged.
Exactly one of the callback arguments will be non-null, <code>metadata</code> or <code>exception</code>.
<code>KafkaDStreamSinkExceptionHandler</code> class keeps last exception registered by the callback (if any).
The client of the callback is able to rethrow registered exception using <code>throwExceptionIfAny()</code> method.
Because <code>onCompletion()</code> and <code>throwExceptionIfAny()</code> methods are called from different threads,
last exception has to be kept in thread-safe data structure <code>AtomicReference</code>.</p>

<p>Finally we are ready to send records to Kafka using created callback.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">rdd</span><span class="o">.</span><span class="n">foreachPartition</span> <span class="o">{</span> <span class="n">records</span> <span class="k">=&gt;</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">producer</span> <span class="k">=</span> <span class="nc">KafkaProducerFactory</span><span class="o">.</span><span class="n">getOrCreateProducer</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">val</span> <span class="n">context</span> <span class="k">=</span> <span class="nc">TaskContext</span><span class="o">.</span><span class="n">get</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">logger</span> <span class="k">=</span> <span class="nc">Logger</span><span class="o">(</span><span class="nc">LoggerFactory</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">KafkaDStreamSink</span><span class="o">]))</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">val</span> <span class="n">callback</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaDStreamSinkExceptionHandler</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;Send Spark partition: ${context.partitionId} to Kafka topic: $topic&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">metadata</span> <span class="k">=</span> <span class="n">records</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">record</span> <span class="k">=&gt;</span>
</span><span class='line'>    <span class="n">callback</span><span class="o">.</span><span class="n">throwExceptionIfAny</span><span class="o">()</span>
</span><span class='line'>    <span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">record</span><span class="o">.</span><span class="n">key</span><span class="o">.</span><span class="n">orNull</span><span class="o">,</span> <span class="n">record</span><span class="o">.</span><span class="n">value</span><span class="o">),</span> <span class="n">callback</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}.</span><span class="n">toList</span>
</span></code></pre></td></tr></table></div></figure>


<p>First the callback is examined for registered exception.
If one of the previous record could not be sent, the exception is propagated to Spark framework.
If any redelivery policy is needed it should be configured on Kafka producer level.
Look at Kafka producer configuration properties <code>retries</code> and <code>retry.backoff.ms</code>.
Finally Kafka producer metadata are collected and materialized by calling <code>toList()</code> method.
At this moment, Kafka producer starts sending records in background I/O thread.
To achieve high throughput Kafka producer sends records in batches.</p>

<p>Because we want to achieve natural back pressure for our stream processing,
next batch needs to be blocked until records from current batch are really acknowledged by the Kafka brokers.
So for each collected metadata (Java <code>j.u.c.Future</code>), method <code>get()</code> is called to ensure that record has been sent to the brokers.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">rdd</span><span class="o">.</span><span class="n">foreachPartition</span> <span class="o">{</span> <span class="n">records</span> <span class="k">=&gt;</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">producer</span> <span class="k">=</span> <span class="nc">KafkaProducerFactory</span><span class="o">.</span><span class="n">getOrCreateProducer</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">val</span> <span class="n">context</span> <span class="k">=</span> <span class="nc">TaskContext</span><span class="o">.</span><span class="n">get</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">logger</span> <span class="k">=</span> <span class="nc">Logger</span><span class="o">(</span><span class="nc">LoggerFactory</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">KafkaDStreamSink</span><span class="o">]))</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">val</span> <span class="n">callback</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaDStreamSinkExceptionHandler</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;Send Spark partition: ${context.partitionId} to Kafka topic: $topic&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">metadata</span> <span class="k">=</span> <span class="n">records</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">record</span> <span class="k">=&gt;</span>
</span><span class='line'>    <span class="n">callback</span><span class="o">.</span><span class="n">throwExceptionIfAny</span><span class="o">()</span>
</span><span class='line'>    <span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">record</span><span class="o">.</span><span class="n">key</span><span class="o">.</span><span class="n">orNull</span><span class="o">,</span> <span class="n">record</span><span class="o">.</span><span class="n">value</span><span class="o">),</span> <span class="n">callback</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}.</span><span class="n">toList</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;Flush Spark partition: ${context.partitionId} to Kafka topic: $topic&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">metadata</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="n">metadata</span> <span class="k">=&gt;</span> <span class="n">metadata</span><span class="o">.</span><span class="n">get</span><span class="o">()</span> <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>As long as records sending was started moment ago, it is likelihood that records have been already sent
and <code>get()</code> method does not block.
However if the <code>get()</code> call is blocked, it means that there are unsent messages in the internal Kafka producer buffer
and the processing should be blocked as well.</p>

<p>Finally <code>sendToKafka()</code> method should propagate exception recorded by the callback (if any).
Complete method is presented below for reference.</p>

<figure class='code'><figcaption><span>sendToKafka</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">sendToKafka</span><span class="o">(</span><span class="n">config</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">],</span> <span class="n">topic</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">dstream</span><span class="o">.</span><span class="n">foreachRDD</span> <span class="o">{</span> <span class="n">rdd</span> <span class="k">=&gt;</span>
</span><span class='line'>    <span class="n">rdd</span><span class="o">.</span><span class="n">foreachPartition</span> <span class="o">{</span> <span class="n">records</span> <span class="k">=&gt;</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">producer</span> <span class="k">=</span> <span class="nc">KafkaProducerFactory</span><span class="o">.</span><span class="n">getOrCreateProducer</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="k">val</span> <span class="n">context</span> <span class="k">=</span> <span class="nc">TaskContext</span><span class="o">.</span><span class="n">get</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">logger</span> <span class="k">=</span> <span class="nc">Logger</span><span class="o">(</span><span class="nc">LoggerFactory</span><span class="o">.</span><span class="n">getLogger</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">KafkaDStreamSink</span><span class="o">]))</span>
</span><span class='line'>
</span><span class='line'>      <span class="k">val</span> <span class="n">callback</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaDStreamSinkExceptionHandler</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;Send Spark partition: ${context.partitionId} to Kafka topic: $topic&quot;</span><span class="o">)</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">metadata</span> <span class="k">=</span> <span class="n">records</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">record</span> <span class="k">=&gt;</span>
</span><span class='line'>        <span class="n">callback</span><span class="o">.</span><span class="n">throwExceptionIfAny</span><span class="o">()</span>
</span><span class='line'>        <span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="o">(</span><span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">record</span><span class="o">.</span><span class="n">key</span><span class="o">.</span><span class="n">orNull</span><span class="o">,</span> <span class="n">record</span><span class="o">.</span><span class="n">value</span><span class="o">),</span> <span class="n">callback</span><span class="o">)</span>
</span><span class='line'>      <span class="o">}.</span><span class="n">toList</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;Flush Spark partition: ${context.partitionId} to Kafka topic: $topic&quot;</span><span class="o">)</span>
</span><span class='line'>      <span class="n">metadata</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="n">metadata</span> <span class="k">=&gt;</span> <span class="n">metadata</span><span class="o">.</span><span class="n">get</span><span class="o">()</span> <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">callback</span><span class="o">.</span><span class="n">throwExceptionIfAny</span><span class="o">()</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The method is not very complex but there are a few important elements
if you don&rsquo;t want to lose processing results and if you need back pressure mechanism:</p>

<ul>
<li>Method <code>sendToKafka()</code> should fail fast if record could not be sent to Kafka. Don&rsquo;t worry Spark will execute failed task again.</li>
<li>Method <code>sendToKafka()</code> should block Spark processing if Kafka producer slows down.</li>
<li>Method <code>sendToKafka()</code> should flush records buffered by Kafka producer explicitly, to avoid data loss.</li>
<li>Kafka producer needs to be reused by Spark executor to avoid connection to Kafka overhead.</li>
<li>Kafka producer needs to be explicitly closed when Spark shutdowns executors to avoid data loss.</li>
</ul>


<h2>Summary</h2>

<p>The complete, working project is published on
<a href="https://github.com/mkuthan/example-spark-kafka">https://github.com/mkuthan/example-spark-kafka</a>.
You can clone/fork the project and do some experiments by yourself.</p>

<p>There is also alternative library developed by Cloudera
<a href="https://github.com/cloudera/spark-kafka-writer">spark-kafka-writer</a>
emerged from closed pull request <a href="https://github.com/apache/spark/pull/2994">SPARK-2994</a>.
Unfortunately at the time of this writing,
the library used obsolete Scala Kafka producer API and did not send processing results in reliable way.</p>

<p>I hope that some day we will find reliable, mature library for sending processing result to Apache Kafka
in the official Spark distribution.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark and Kafka Integration Patterns, Part 1]]></title>
    <link href="http://mkuthan.github.io/blog/2015/08/06/spark-kafka-integration1/"/>
    <updated>2015-08-06T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2015/08/06/spark-kafka-integration1</id>
    <content type="html"><![CDATA[<p>I published post on the <a href="http://allegro.tech/">allegro.tech</a> blog, how to integrate Spark Streaming and Kafka.
In the blog post you will find how to avoid <code>java.io.NotSerializableException</code> exception
when Kafka producer is used for publishing results of the Spark Streaming processing.</p>

<p><a href="http://allegro.tech/2015/08/spark-kafka-integration.html">http://allegro.tech/spark-kafka-integration.html</a></p>

<p>You could be also interested in the
<a href="http://mkuthan.github.io/blog/2016/01/29/spark-kafka-integration2/">following part</a> of this blog post where
I presented complete library for sending Spark Streaming processing results to Kafka.</p>

<p>Happy reading :&ndash;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark and Spark Streaming Unit Testing]]></title>
    <link href="http://mkuthan.github.io/blog/2015/03/01/spark-unit-testing/"/>
    <updated>2015-03-01T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2015/03/01/spark-unit-testing</id>
    <content type="html"><![CDATA[<p>When you develop distributed system, it is crucial to make it easy to test.
Execute tests in controlled environment, ideally from your IDE.
Long develop-test-develop cycle for complex systems could kill your productivity.
Below you find my testing strategy for Spark and Spark Streaming applications.</p>

<h2>Unit or integration tests, that is the question</h2>

<p>Our hypothetical Spark application pulls data from Apache Kafka, apply transformations using
<a href="https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.rdd.RDD">RDDs</a>
and
<a href="https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.streaming.dstream.DStream">DStreams</a>
and persist outcomes into Cassandra or Elastic Search database.
On production Spark application is deployed on YARN or Mesos cluster, and everything is glued with ZooKeeper.
Big picture of the stream processing architecture is presented below:</p>

<p><img src="http://yuml.me/diagram/scruffy;dir:LR/class/[Apache%20Kafka]-[Spark%20Streaming],[Spark%20Streaming]-[Cassandra],[Spark%20Streaming]-[Elastic%20Search],[Spark%20Streaming],[Zookeeper{bg:cornsilk}],[YARN%20or%20Mesos%20Cluster{bg:cornsilk}]"></p>

<p>Lots of moving parts, not so easy to configure and test.
Even with automated provisioning implemented with Vagrant, Docker and Ansible.
If you can&rsquo;t test everything, test at least the most important part of your application &ndash; transformations &ndash; implemented with Spark.</p>

<p>Spark claims, that it is friendly to unit testing with any popular unit test framework.
To be strict, Spark supports rather lightweight integration testing, not unit testing, IMHO.
But still it is much more convenient to test transformation logic locally, than deploying all parts on YARN.</p>

<p>There is a pull request <a href="https://github.com/apache/spark/pull/1751">SPARK-1751</a> that adds &ldquo;unit tests&rdquo; support for Apache Kafka streams.
Should we follow that way? Embedded ZooKeeper and embedded Apache Kafka are needed, the test fixture is complex and cumbersome.
Perhaps tests would be fragile and hard to maintain. This approach makes sense for Spark core team, they want to test Spark and Kafka integration.</p>

<h2>What should be tested?</h2>

<p>Our transformation logic implemented with Spark, nothing more. But how to test the logic so tightly coupled to Spark API (RDD, DStream)?
Let&rsquo;s define how typical Spark application is organized. Our hypothetical application structure looks like this:</p>

<ol>
<li>Initialize <code>SparkContext</code> or <code>StreamingContext</code>.</li>
<li>Create RDD or DStream for given source (e.g: Apache Kafka)</li>
<li>Evaluate transformations on RDD or DStream API.</li>
<li>Put transformation outcomes (e.g: aggregations) into external database.</li>
</ol>


<h3>Context</h3>

<p><code>SparkContext</code> and <code>StreamingContext</code> could be easily initialized for testing purposes.
Set master URL to <code>local</code>, run the operations and then stop context gracefully.</p>

<figure class='code'><figcaption><span>SparkContext Initialization</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">SparkExampleSpec</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">BeforeAndAfter</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">master</span> <span class="k">=</span> <span class="s">&quot;local[2]&quot;</span>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">appName</span> <span class="k">=</span> <span class="s">&quot;example-spark&quot;</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">var</span> <span class="n">sc</span><span class="k">:</span> <span class="kt">SparkContext</span> <span class="o">=</span> <span class="k">_</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">before</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">()</span>
</span><span class='line'>      <span class="o">.</span><span class="n">setMaster</span><span class="o">(</span><span class="n">master</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="n">setAppName</span><span class="o">(</span><span class="n">appName</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">after</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(</span><span class="n">sc</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">sc</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>  <span class="o">(...)</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>StreamingContext Initialization</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">SparkStreamingExampleSpec</span> <span class="k">extends</span> <span class="nc">FlatSpec</span> <span class="k">with</span> <span class="nc">BeforeAndAfter</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">master</span> <span class="k">=</span> <span class="s">&quot;local[2]&quot;</span>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">appName</span> <span class="k">=</span> <span class="s">&quot;example-spark-streaming&quot;</span>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">batchDuration</span> <span class="k">=</span> <span class="nc">Seconds</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</span><span class='line'>  <span class="k">private</span> <span class="k">val</span> <span class="n">checkpointDir</span> <span class="k">=</span> <span class="nc">Files</span><span class="o">.</span><span class="n">createTempDirectory</span><span class="o">(</span><span class="n">appName</span><span class="o">).</span><span class="n">toString</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">var</span> <span class="n">sc</span><span class="k">:</span> <span class="kt">SparkContext</span> <span class="o">=</span> <span class="k">_</span>
</span><span class='line'>  <span class="k">private</span> <span class="k">var</span> <span class="n">ssc</span><span class="k">:</span> <span class="kt">StreamingContext</span> <span class="o">=</span> <span class="k">_</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">before</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">()</span>
</span><span class='line'>      <span class="o">.</span><span class="n">setMaster</span><span class="o">(</span><span class="n">master</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="n">setAppName</span><span class="o">(</span><span class="n">appName</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">ssc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StreamingContext</span><span class="o">(</span><span class="n">conf</span><span class="o">,</span> <span class="n">batchDuration</span><span class="o">)</span>
</span><span class='line'>    <span class="n">ssc</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">(</span><span class="n">checkpointDir</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">sc</span> <span class="k">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">sparkContext</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">after</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(</span><span class="n">ssc</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">ssc</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="o">(...)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>RDD and DStream</h3>

<p>The problematic part is how to create RDD or DStream.
For testing purposes it must be simplified to avoid embedded Kafka and ZooKeeper.
Below you can find examples how to create in-memory RDD and DStream.</p>

<figure class='code'><figcaption><span>In-memory RDD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;To be or not to be.&quot;</span><span class="o">,</span> <span class="s">&quot;That is the question.&quot;</span><span class="o">)</span>
</span><span class='line'><span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">lines</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>In-memory DStream</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">Queue</span><span class="o">[</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]]()</span>
</span><span class='line'><span class="k">val</span> <span class="n">dstream</span> <span class="k">=</span> <span class="n">streamingContext</span><span class="o">.</span><span class="n">queueStream</span><span class="o">(</span><span class="n">lines</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// append data to DStream</span>
</span><span class='line'><span class="n">lines</span> <span class="o">+=</span> <span class="n">sparkContext</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;To be or not to be.&quot;</span><span class="o">,</span> <span class="s">&quot;That is the question.&quot;</span><span class="o">))</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Transformation logic</h3>

<p>The most important part of our application &ndash; transformations logic &ndash; must be encapsulated in separate class or object.
Object is preferred to avoid class serialization overhead. Exactly the same code is used by the application and by the test.</p>

<figure class='code'><figcaption><span>WordCount.scala</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">case</span> <span class="k">class</span> <span class="nc">WordCount</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">object</span> <span class="nc">WordCount</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">count</span><span class="o">(</span><span class="n">lines</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">],</span> <span class="n">stopWords</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">WordCount</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">words</span> <span class="k">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;\\s&quot;</span><span class="o">))</span>
</span><span class='line'>      <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">strip</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">).</span><span class="n">strip</span><span class="o">(</span><span class="s">&quot;.&quot;</span><span class="o">).</span><span class="n">toLowerCase</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="n">filter</span><span class="o">(!</span><span class="n">stopWords</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="k">_</span><span class="o">)).</span><span class="n">filter</span><span class="o">(!</span><span class="k">_</span><span class="o">.</span><span class="n">isEmpty</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">word</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="mi">1</span><span class="o">)).</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">case</span> <span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">WordCount</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="n">count</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">sortedWordCounts</span> <span class="k">=</span> <span class="n">wordCounts</span><span class="o">.</span><span class="n">sortBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">word</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">sortedWordCounts</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Spark test</h2>

<p>Now it is time to implement our first test for WordCount transformation.
The code of test is very straightforward and easy to read.
Single point of truth, the best documentation of your system, always up-to-date.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="s">&quot;Shakespeare most famous quote&quot;</span> <span class="n">should</span> <span class="s">&quot;be counted&quot;</span> <span class="n">in</span> <span class="o">{</span>
</span><span class='line'>    <span class="nc">Given</span><span class="o">(</span><span class="s">&quot;quote&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;To be or not to be.&quot;</span><span class="o">,</span> <span class="s">&quot;That is the question.&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nc">Given</span><span class="o">(</span><span class="s">&quot;stop words&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">stopWords</span> <span class="k">=</span> <span class="nc">Set</span><span class="o">(</span><span class="s">&quot;the&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nc">When</span><span class="o">(</span><span class="s">&quot;count words&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="nc">WordCount</span><span class="o">.</span><span class="n">count</span><span class="o">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">lines</span><span class="o">),</span> <span class="n">stopWords</span><span class="o">).</span><span class="n">collect</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'>    <span class="nc">Then</span><span class="o">(</span><span class="s">&quot;words counted&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="n">wordCounts</span> <span class="n">should</span> <span class="n">equal</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;be&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;is&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;not&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;or&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;question&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;that&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;to&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Spark Streaming test</h2>

<p>Spark Streaming transformations are much more complex to test.
The full control over clock is needed to manually manage batches, slides and windows.
Without controlled clock you would end up with complex tests with many <code>Thread.sleeep</code> calls.
And the test execution would take ages.
The only downside is that you will not have extra time for coffee during tests execution.</p>

<p>Spark Streaming provides necessary abstraction over system clock, <code>ManualClock</code> class.
Unfortunately <code>ManualClock</code> class is declared as package private. Some hack is needed.
The wrapper presented below, is an adapter for the original <code>ManualClock</code> class but without access restriction.</p>

<figure class='code'><figcaption><span>ClockWrapper.scala</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">package</span> <span class="nn">org.apache.spark.streaming</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.streaming.util.ManualClock</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">ClockWrapper</span><span class="o">(</span><span class="n">ssc</span><span class="k">:</span> <span class="kt">StreamingContext</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">getTimeMillis</span><span class="o">()</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="n">manualClock</span><span class="o">().</span><span class="n">currentTime</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">setTime</span><span class="o">(</span><span class="n">timeToSet</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span> <span class="k">=</span> <span class="n">manualClock</span><span class="o">().</span><span class="n">setTime</span><span class="o">(</span><span class="n">timeToSet</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">advance</span><span class="o">(</span><span class="n">timeToAdd</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span> <span class="k">=</span> <span class="n">manualClock</span><span class="o">().</span><span class="n">addToTime</span><span class="o">(</span><span class="n">timeToAdd</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">waitTillTime</span><span class="o">(</span><span class="n">targetTime</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="n">manualClock</span><span class="o">().</span><span class="n">waitTillTime</span><span class="o">(</span><span class="n">targetTime</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">private</span> <span class="k">def</span> <span class="n">manualClock</span><span class="o">()</span><span class="k">:</span> <span class="kt">ManualClock</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">ssc</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">clock</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">ManualClock</span><span class="o">]</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now Spark Streaming test can be implemented in efficient way.
The test does not have to wait for system clock and test is implemented with millisecond precision.
You can easily test your windowed scenario from the very beginning to very end.
With given\when\then structure you should be able to understand tested logic without further explanations.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="s">&quot;Sample set&quot;</span> <span class="n">should</span> <span class="s">&quot;be counted&quot;</span> <span class="n">in</span> <span class="o">{</span>
</span><span class='line'>  <span class="nc">Given</span><span class="o">(</span><span class="s">&quot;streaming context is initialized&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">Queue</span><span class="o">[</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]]()</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">var</span> <span class="n">results</span> <span class="k">=</span> <span class="nc">ListBuffer</span><span class="o">.</span><span class="n">empty</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">WordCount</span><span class="o">]]</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">WordCount</span><span class="o">.</span><span class="n">count</span><span class="o">(</span><span class="n">ssc</span><span class="o">.</span><span class="n">queueStream</span><span class="o">(</span><span class="n">lines</span><span class="o">),</span> <span class="n">windowDuration</span><span class="o">,</span> <span class="n">slideDuration</span><span class="o">)</span> <span class="o">{</span> <span class="o">(</span><span class="n">wordsCount</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">WordCount</span><span class="o">],</span> <span class="n">time</span><span class="k">:</span> <span class="kt">Time</span><span class="o">)</span> <span class="k">=&gt;</span>
</span><span class='line'>    <span class="n">results</span> <span class="o">+=</span> <span class="n">wordsCount</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">ssc</span><span class="o">.</span><span class="n">start</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">When</span><span class="o">(</span><span class="s">&quot;first set of words queued&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">lines</span> <span class="o">+=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">))</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">Then</span><span class="o">(</span><span class="s">&quot;words counted after first slide&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">clock</span><span class="o">.</span><span class="n">advance</span><span class="o">(</span><span class="n">slideDuration</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">)</span>
</span><span class='line'>  <span class="n">eventually</span><span class="o">(</span><span class="n">timeout</span><span class="o">(</span><span class="mi">1</span> <span class="n">second</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">results</span><span class="o">.</span><span class="n">last</span> <span class="n">should</span> <span class="n">equal</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">When</span><span class="o">(</span><span class="s">&quot;second set of words queued&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">lines</span> <span class="o">+=</span> <span class="n">sc</span><span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">))</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">Then</span><span class="o">(</span><span class="s">&quot;words counted after second slide&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">clock</span><span class="o">.</span><span class="n">advance</span><span class="o">(</span><span class="n">slideDuration</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">)</span>
</span><span class='line'>  <span class="n">eventually</span><span class="o">(</span><span class="n">timeout</span><span class="o">(</span><span class="mi">1</span> <span class="n">second</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">results</span><span class="o">.</span><span class="n">last</span> <span class="n">should</span> <span class="n">equal</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">When</span><span class="o">(</span><span class="s">&quot;nothing more queued&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">Then</span><span class="o">(</span><span class="s">&quot;word counted after third slide&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">clock</span><span class="o">.</span><span class="n">advance</span><span class="o">(</span><span class="n">slideDuration</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">)</span>
</span><span class='line'>  <span class="n">eventually</span><span class="o">(</span><span class="n">timeout</span><span class="o">(</span><span class="mi">1</span> <span class="n">second</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">results</span><span class="o">.</span><span class="n">last</span> <span class="n">should</span> <span class="n">equal</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">When</span><span class="o">(</span><span class="s">&quot;nothing more queued&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="nc">Then</span><span class="o">(</span><span class="s">&quot;word counted after fourth slide&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">clock</span><span class="o">.</span><span class="n">advance</span><span class="o">(</span><span class="n">slideDuration</span><span class="o">.</span><span class="n">milliseconds</span><span class="o">)</span>
</span><span class='line'>  <span class="n">eventually</span><span class="o">(</span><span class="n">timeout</span><span class="o">(</span><span class="mi">1</span> <span class="n">second</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">results</span><span class="o">.</span><span class="n">last</span> <span class="n">should</span> <span class="n">equal</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span>
</span><span class='line'>      <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>One comment to <code>Eventually</code> trait usage.
The trait is needed because Spark Streaming is a multithreaded application, and results are not computed immediately.
I found that 1 second timeout is enough for Spark Streaming to calculate the results.
The timeout is not related to batch, slide or window duration.</p>

<h2>Summary</h2>

<p>The complete, working project is published on <a href="https://github.com/mkuthan/example-spark">GitHub</a>.
You can clone/fork the project and do some experiments by yourself.</p>

<p>I hope that Spark committers expose <code>ManualClock</code> for others, eventually.
Control of time is necessary for efficient Spark Streaming application testing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Learn DDD]]></title>
    <link href="http://mkuthan.github.io/blog/2014/09/22/ddd-how-to-learn/"/>
    <updated>2014-09-22T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/09/22/ddd-how-to-learn</id>
    <content type="html"><![CDATA[<h2>Books</h2>

<p><a href="https:///show/179133.Domain_Driven_Designwww.goodreads.com/book">Domain Driven Design</a> by Eric Evans.</p>

<p>You have to read this book, period. From the very beginning to very end.
Do not stop reading after first part of the book, the part about strategic design is much more important.
Study this book again and again. I did not read this book at once, it would be impossible mission.
Every time I back to this book I found something new, every single word in this book is important and brings some meaning.</p>

<p><a href="https://www.goodreads.com/book/show/15756865-implementing-domain-driven-design">Implementing Domain Driven Design</a> by Vaughn Vernon.</p>

<p>More practical and easier to digest book than previous one. Not so brilliant but still worth reading.</p>

<p><a href="https://www.goodreads.com/book/show/19086899-exploring-cqrs-and-event-sourcing">Exploring CQRS and Event Sourcing</a></p>

<p>Excellent DDD/CQRS case study with working code on GitHub.
Real world example how to define bounded context and how to integrate them using domain events.
Awesome!</p>

<p><a href="https://www.goodreads.com/book/show/434826.Enterprise_Patterns_and_MDA">Enterprise Patterns and MDA</a> by Jim Arlow and Ila Neusandt</p>

<p>Do not reinvent the wheel when you discover your domain model. At least for e-commerce :&ndash;)
Apply presented archetype patterns wisely and save your ass.</p>

<h2>My examples</h2>

<p><a href="http://mkuthan.github.io/presentations/ddd.html">http://mkuthan.github.io/presentations/ddd.html</a> &ndash; &ldquo;Domain Driven Desing &ndash; from trenches for practitioners&rdquo; presentation.</p>

<p><a href="http://mkuthan.github.io/blog/2013/11/04/ddd-architecture-summary/">http://mkuthan.github.io/blog/2013/11/04/ddd-architecture-summary/</a> &ndash; Blog post &ndash; my DDD check list.</p>

<p><a href="https://github.com/mkuthan/example-ddd-cqrs-server">https://github.com/mkuthan/example-ddd-cqrs-server</a> &ndash; Experiment based on Vernon book.</p>

<p><a href="https://github.com/mkuthan/example-axon">https://github.com/mkuthan/example-axon</a> &ndash; Experiment based on Exploring CQRS and Event Sourcing book.</p>

<h2>Other sources</h2>

<p><a href="http://www.udidahan.com/?blog=true">http://www.udidahan.com/</a> &ndash; Udi Dahan &ndash; one of my mentor in distributed systems and DDD architecture.</p>

<p><a href="https://groups.yahoo.com/neo/groups/domaindrivendesign">https://groups.yahoo.com/neo/groups/domaindrivendesign</a> &ndash; official DDD discussion group, addictive reading for long winter evenings.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Programming Language Does Not Matter]]></title>
    <link href="http://mkuthan.github.io/blog/2014/09/15/programming_language_does_not_matter/"/>
    <updated>2014-09-15T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/09/15/programming_language_does_not_matter</id>
    <content type="html"><![CDATA[<p>A few days ago I participated in quick presentation of significant e-commerce platform.
The custom platform implemented mostly in PHP and designed as scalable and distributed system.
And I was really impressed! Below you can find a short summary of chosen libraries, frameworks and tools.</p>

<p><em>Symfony</em> &ndash; The leading PHP framework to create web applications.
Very similar to Spring Framework, you will get dependency injection, layered architecture and good support for automated testing.</p>

<p><em>Doctrine</em> &ndash; Object to relational mapper (ORM), part of the Symfony framework.  Very similar to JPA.</p>

<p><em>Composer</em> &ndash; Dependency manager for PHP, very similar to NPM.</p>

<p><em>Gearman</em> &ndash; Generic application framework to farm out work to other machines or processes. Somehow similar to YARN.</p>

<p><em>Varnish</em> &ndash; HTTP reverse proxy.</p>

<p><em>Memcached</em> &ndash; Distributed key value cache.</p>

<p><em>RabbitMQ</em> &ndash; Messaging middleware based on AMPQ protocol. Used for distributed services integration but also for decoupled request reply communication.</p>

<p><em>logstash</em> &ndash; Log manager with tons of plugins to almost everything. The monitoring is really crucial in distributed systems.</p>

<p>The programming language does not really matter if you need scalable, distributed, easy to maintain and enhance system.
You can apply excellent design using PHP or produce big ball of mud in Java.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mastering Node.js - Book Review]]></title>
    <link href="http://mkuthan.github.io/blog/2014/08/20/mastering-nodejs-book-review/"/>
    <updated>2014-08-20T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/08/20/mastering-nodejs-book-review</id>
    <content type="html"><![CDATA[<h2>Overview</h2>

<p>I&rsquo;m really impressed by Node.js (and JavaScript) ecosystem. I took <em>Mastering Node.js</em> book to understand Node.js philosophy and compare to JVM world.</p>

<h2>V8</h2>

<p>JavaScript virtual machine, conceptually very similar to JVM.
The most important element of JavaScript ecosystem if you want to do something more than client side web application.
I really like Node.js REPL, experimentation is as easy as with Scala.</p>

<h2>Event loop</h2>

<p>Elegant simulation of concurrency. Do you remember Swing event dispatch thread and <code>invokeLater()</code> method? Event loop is the same.
It is crucial to understand events handling order:</p>

<ul>
<li>emitted event</li>
<li>timers</li>
<li>IO callbacks</li>
<li>deferred execution blocks</li>
</ul>


<h2>Event driven concurrency</h2>

<p>Process is a first class citizen. The easiest (and cheapest) way to achieve concurrency with horizontal scalability.</p>

<h2>Real-time applications</h2>

<p>I enhanced drawing board presented in the book. It was great fun together with my 2 years old son :&ndash;)
Scalable server side implementation is presented below, I could not even imagine Java version.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">var</span> <span class="nx">express</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;express&#39;</span><span class="p">)</span>
</span><span class='line'><span class="kd">var</span> <span class="nx">path</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">);</span>
</span><span class='line'><span class="kd">var</span> <span class="nx">app</span> <span class="o">=</span> <span class="nx">express</span><span class="p">();</span>
</span><span class='line'><span class="kd">var</span> <span class="nx">http</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;http&#39;</span><span class="p">).</span><span class="nx">Server</span><span class="p">(</span><span class="nx">app</span><span class="p">);</span>
</span><span class='line'><span class="kd">var</span> <span class="nx">io</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;socket.io&#39;</span><span class="p">)(</span><span class="nx">http</span><span class="p">);</span>
</span><span class='line'><span class="kd">var</span> <span class="nx">redis</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;socket.io-redis&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="nx">io</span><span class="p">.</span><span class="nx">adapter</span><span class="p">(</span><span class="nx">redis</span><span class="p">({</span> <span class="nx">host</span><span class="o">:</span> <span class="s1">&#39;localhost&#39;</span><span class="p">,</span> <span class="nx">port</span><span class="o">:</span> <span class="mi">6379</span> <span class="p">}));</span>
</span><span class='line'>
</span><span class='line'><span class="kd">var</span> <span class="nx">port</span> <span class="o">=</span> <span class="nb">parseInt</span><span class="p">(</span><span class="nx">process</span><span class="p">.</span><span class="nx">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
</span><span class='line'>
</span><span class='line'><span class="nx">app</span><span class="p">.</span><span class="nx">use</span><span class="p">(</span><span class="nx">express</span><span class="p">.</span><span class="kr">static</span><span class="p">(</span><span class="nx">path</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span><span class="nx">__dirname</span><span class="p">,</span> <span class="s1">&#39;assets&#39;</span><span class="p">)));</span>
</span><span class='line'>
</span><span class='line'><span class="nx">app</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">){</span>
</span><span class='line'>  <span class="nx">res</span><span class="p">.</span><span class="nx">sendfile</span><span class="p">(</span><span class="s1">&#39;index.html&#39;</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span><span class='line'>
</span><span class='line'><span class="nx">io</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;connection&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">socket</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">socket</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;move&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">socket</span><span class="p">.</span><span class="nx">broadcast</span><span class="p">.</span><span class="nx">emit</span><span class="p">(</span><span class="s1">&#39;moving&#39;</span><span class="p">,</span> <span class="nx">data</span><span class="p">);</span>
</span><span class='line'>  <span class="p">});</span>
</span><span class='line'><span class="p">});</span>
</span><span class='line'>
</span><span class='line'><span class="nx">http</span><span class="p">.</span><span class="nx">listen</span><span class="p">(</span><span class="nx">port</span><span class="p">,</span> <span class="kd">function</span><span class="p">(){</span>
</span><span class='line'>  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s1">&#39;Board started on: &#39;</span> <span class="o">+</span> <span class="nx">port</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>Keep in mind that SSE is unidirectional from server to clients and requires funny 2KB padding. I didn&rsquo;t know that before.</p>

<h2>Scaling on single node</h2>

<p>Spawning, forking child processes is easy, communication between parent and children processes is easy as well.
Cluster module simplifies web application implementation for multi-core processors and it is very easy to understand and control.</p>

<h2>Horizontal scaling</h2>

<p>Keep shared state in horizontally scalable store, e.g: session data in Redis or RabbitMq for events.</p>

<h2>Apache Bench</h2>

<p>Command line tool for load/stress testing. Using JMeter or Gatling is not always the only way to perform simple test.</p>

<h2>UDP / Multicast</h2>

<p>Good to know the world behind HTTP/REST/SOAP &hellip; There is a lot of important layers between application and wire, do you remember OSI?</p>

<h2>AWS</h2>

<p>I have to practice using S3 or DynamoDB eventually.</p>

<h2>Node debugger</h2>

<p>OMG &ndash; I used to debug application using console 10 years ago or so ;&ndash;)</p>

<h2>Express, Socket.io, Path</h2>

<p>Implementing web application using Node.js only is feasible but with Express it is much easier.</p>

<p>Be aware that there are thousands of web frameworks for Node.js on the market. Much more that for Java 10 years ago ;&ndash;)
It seems that frameworks built around WebSocket and Single Page App should be the leaders.</p>

<h2>Interesing resources</h2>

<p><a href="https://cs.uwaterloo.ca/~brecht/papers/getpaper.php?file=eurosys-2007.pdf">Comparing the Performance of Web Server Architectures</a></p>

<p><a href="http://www.futurealoof.com/posts/broken-promises.html">Broken Promises</a></p>

<h2>Summary</h2>

<p>JavaScript and Node.js seem to be one of the most vital ecosystem for web development.
The adoption in the enterprise world is still low but I really like this ecosystem and its community.
And I&rsquo;m still waiting for final version of ES6, sometimes JavaScript really sucks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SOA Patterns - Book Review]]></title>
    <link href="http://mkuthan.github.io/blog/2014/06/26/soa-patterns-book-review/"/>
    <updated>2014-06-26T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/06/26/soa-patterns-book-review</id>
    <content type="html"><![CDATA[<h2>Overview</h2>

<p>I took this book from my bookshelf when I was preparing internal presentation about micro services for my Roche colleagues.
I was mainly interested in <em>Saga</em> and <em>Composite Front End</em> patterns. But when I started, I decided to read rest of the book.</p>

<h2>Patterns</h2>

<p>Below you can find my short summary about every pattern described in the book:</p>

<h3>Service Host</h3>

<p>Every service needs the host where it works. For me <em>Spring Framework</em> is excellent example of the service host.</p>

<h3>Active Service</h3>

<p>Very similar to Micro Services concept, when the service should be autonomous.</p>

<h3>Transactional Service</h3>

<p>I know a few alternative names of this pattern: Unit of Work, Open Session in View. In JEE world implemented using <code>ThreadLocal</code>.</p>

<h3>Workflodize</h3>

<p>Strange pattern name. I don&rsquo;t really like complexity of workflow engines and prefer simple object oriented finite state machine implementation.</p>

<h3>Edge Component</h3>

<p>Separate infrastructure code from domain. Just simple like that.</p>

<h3>Decoupled Invocation</h3>

<p>Use event / command bus for communication.</p>

<h3>Parallel Pipelines</h3>

<p>Apply Unix philosophy to your services. SRP on the higher level.</p>

<h3>Gridable Service</h3>

<p>Horizontal scaling.</p>

<h3>Service Instance</h3>

<p>Horizonatal scaling.</p>

<h3>Virtual Endpoint</h3>

<p>Make your deployment configuration flexible.</p>

<h3>Service Watchdog</h3>

<p>Service monitoring should be built-in.</p>

<h3>Secured Message</h3>

<p>Encrypt what should be secured on the message level (privacy, integrity, impersonation).</p>

<h3>Secured Infrastructure</h3>

<p>Encrypt what should be secured on the protocol level (privacy, integrity, impersonation).</p>

<h3>Service Firewall</h3>

<p>Security on the network level. Expose only what is really needed.</p>

<h3>Identity Provider</h3>

<p>Single Sign On.</p>

<h3>Service Monitor</h3>

<p>Monitoring on the business process level.</p>

<h3>Request/Reply</h3>

<p>Synchronous point to point communication.</p>

<h3>Request/Reaction</h3>

<p>Asynchronous point to point communication.</p>

<h3>Inversion of Communications</h3>

<p>Command Bus, Event Bus, messaging middleware in general. Complex Event Processing (CEP).</p>

<h3>Saga</h3>

<p>Long running business transactions. Distributed transactions without XA.</p>

<h3>Reservation</h3>

<p>Related to Saga, how to avoid XA transactions.</p>

<h3>Composite Front End</h3>

<p>How to compose services into single web application? Author does not answer my doubts in this chapter.</p>

<h3>Client/Server/Service</h3>

<p>How to deal with legacy systems. How to move from monolithic architecture to SOA.</p>

<h3>Service Bus</h3>

<p>Message Bus, Service Bus, ESB &ndash; nice explanation.</p>

<h3>Orchestration</h3>

<p>Externalize business long running processes. But still encapsulate business logic in services not in the orchestrator!</p>

<h3>Aggregated Reporting</h3>

<p>Looks like CQRS for me.</p>

<h2>Antipatterns</h2>

<p>Funny names for real problems when SOA is used:</p>

<ul>
<li>Knot &ndash; problems with coupling.</li>
<li>Nanoservice &ndash; problems with bounded contexts.</li>
<li>Transactional Integration &ndash; problems with XA transations.</li>
<li>Same Old Way &ndash; problems with CRUD like services.</li>
</ul>


<h2>Summary</h2>

<p>For sure it&rsquo;s worth reading but I expected more from Arnon Rotem-Gal-Oz.
Sometimes I felt that author covers only the top of the iceberg, when demons are under the hood.
The sample code fragments are not very helpful, with high accidental complexity but do not clearly show the problem.</p>

<p>In addition the book was published in 2012 but you will easily realized that author had started ten years before, some parts seems to be outdated.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rrelease It! - Book Review]]></title>
    <link href="http://mkuthan.github.io/blog/2014/06/21/release-it-book-review/"/>
    <updated>2014-06-21T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/06/21/release-it-book-review</id>
    <content type="html"><![CDATA[<p>Recently I read excellent book <em>Release It!</em> written by Michael Nygard.
The book is 7 years old and I don&rsquo;t know how I could miss the book until now.</p>

<p>Michael Nygard shows how to design and architect medium or large scale web applications.
Real lessons learnt from the trenches not golden rules from ivory architects.</p>

<p>This blog post is a dump of taken notes when I was reading the book.
The list could be used as a checklist for system architects and developers.
There is no particular order of the notes, perhaps there are duplications too.</p>

<ul>
<li><p><em>admin access</em> &ndash; should use separate networks than regular traffic, if not administrator will not be able connect to the system when something is wrong.</p></li>
<li><p><em>network timeouts</em> &ndash; should be always defined, if not our system could hang if there is a problem with remote service.</p></li>
<li><p><em>firewall</em> &ndash; be aware of timeouts on firewall connection tracking tables, if the connection is unused for long time (e.g connection from the pool), firewall could drop packets silently.</p></li>
<li><p><em>failure probability</em> &ndash; are dependant, not like during coin toss.</p></li>
<li><p><em>3rd party vendors</em> &ndash; their client library often sucks, you can not define timeouts, you can not configure threading correctly.</p></li>
<li><p><em>method wait</em> &ndash; always provide the timeout, do not use method <code>Object.wait()</code>.</p></li>
<li><p><em>massive email with deep links</em> &ndash; do not send massive emails with deep links, bunch of requests to single resource could kill your application.</p></li>
<li><p><em>threads ratio</em> &ndash; check front-end and back-end threads ratio, the system is as fast as its slowest part.</p></li>
<li><p><em>SLA</em> &ndash; define different SLAs for different subsystems, not everything must have 99.99%</p></li>
<li><p><em>high CPU utilization</em> &ndash; check GC logs first.</p></li>
<li><p><em>JVM crash</em> &ndash; typical after OOM, when native code is trying to allocate memory &ndash; <code>malloc()</code> returns error but only few programmers handle this error.</p></li>
<li><p><em>Collection size</em> &ndash; do not use unbounded collections, huge data set kills your application eventually.</p></li>
<li><p><em>Outgoing communication</em> &ndash; define timeouts.</p></li>
<li><p><em>Incoming communication</em> &ndash; fail fast, be pleasant for other systems.</p></li>
<li><p><em>separate threads pool</em> &ndash; for admin access, your last way to fix the system.</p></li>
<li><p><em>input validation</em> &ndash; fail fast, use JS validation even if validation must be duplicated.</p></li>
<li><p><em>circuit braker</em> &ndash; design pattern for handling unavailable remote services.</p></li>
<li><p><em>handshake in protocol</em> &ndash; alternative for <em>circuit braker</em> if you desing your own protocol.</p></li>
<li><p><em>test harness</em> &ndash; test using production like environment (but how to do that???)</p></li>
<li><p><em>capacity</em> &ndash; always multiply by number of users, requests, etc.</p></li>
<li><p><em>safety limits on everything</em> &ndash; nice general rule.</p></li>
<li><p><em>oracle and connection pool</em> &ndash; Oracle in default configuration spawns separate process for every connection, check how much memory is used only for handling client connections.</p></li>
<li><p><em>unbalanced resources</em> &ndash; underestimated part will fail first, and it could hang whole system.</p></li>
<li><p><em>JSP and GC</em> &ndash; be aware of <code>noclassgc</code> JVM option, compiled JSP files use perm gen space.</p></li>
<li><p><em>http sessions</em> &ndash; users do not understand the concept, do not keep shopping card in the session :&ndash;)</p></li>
<li><p><em>whitespaces</em> &ndash; remove any unnecessary whitespace from the pages, in large scale it saves a lot of traffic.</p></li>
<li><p><em>avoid hand crafted SQLs</em> &ndash; hard to predict the outcome, and hard to optimize for performance.</p></li>
<li><p><em>database tests</em> &ndash; use the real data volume.</p></li>
<li><p><em>unicast</em> &ndash; could be used for up to ~10 servers, for bigger cluster use multicast.</p></li>
<li><p><em>cache</em> &ndash; always limit cache size.</p></li>
<li><p><em>hit ratio</em> &ndash; always monitor cache hit ratio.</p></li>
<li><p><em>precompute html</em> &ndash; huge server resource saver, not everything changes on every request.</p></li>
<li><p><em>JVM tuning</em> &ndash; is application release specific, on every release memory utilization could be different.</p></li>
<li><p><em>multihomed servers</em> &ndash; on production network topology is much more complex.</p></li>
<li><p><em>bonding</em> &ndash; single network configured with multiple network cards and multiple switch ports.</p></li>
<li><p><em>backup</em> &ndash; use separate network, backup always consumes your whole bandwidth.</p></li>
<li><p><em>virtual IP</em> &ndash; always configure virtual IP, your configuration will be much more flexible.</p></li>
<li><p><em>technical accounts</em> &ndash; do not share accounts between services, it would be security flaws.</p></li>
<li><p><em>cluster configuration verification</em> &ndash; periodically check configuration on the cluster nodes, even if the configuration is deployed automatically.</p></li>
<li><p><em>separate configuration specific for the single cluster node</em> &ndash; keep node specific configuration separated from shared configuration.</p></li>
<li><p><em>configuration property names</em> &ndash; based on function not nature (e.g: hostname is too generic).</p></li>
<li><p><em>graceful shutdown</em> &ndash; do not terminate existing business transations.</p></li>
<li><p><em>thread dumps</em> &ndash; prepare scripts for that, during accident time is really precious (SLAs).</p></li>
<li><p><em>recovery oriented computing</em> &ndash; be prepared for restarting only part of the system, restarting everything is time consuming.</p></li>
<li><p><em>transparency</em> &ndash; be able to monitor everything.</p></li>
<li><p><em>monitoring policy, alerts</em> &ndash; should not be defined by the service, configure the policies outside (perhaps in central place).</p></li>
<li><p><em>log format</em> &ndash; should be human readable, humans are the best in pattern matching, use tabulators and fixed width columns.</p></li>
<li><p><em>CIM</em> &ndash; <em>SNMP</em> superior.</p></li>
<li><p><em>SSL accelerator</em> &ndash; what it really is???</p></li>
<li><p><em>OpsDB monitoring</em> &ndash; measurements and expectations, end to end business process monitoring.</p></li>
<li><p><em>Node Identifiers</em> &ndash; assign to teams in block.</p></li>
<li><p><em>Observe, Orient, Decide, Act</em> &ndash; military methodology, somehow similar to Agile :&ndash;)</p></li>
<li><p><em>review</em> &ndash; tickets, stack traces in log files, volume of problems, data volumes, query statistics periodically.</p></li>
<li><p><em>DB migration</em> &ndash; expansion phase for incompatible schema changes.</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Acceptance Testing Using JBehave, Spring Framework and Maven]]></title>
    <link href="http://mkuthan.github.io/blog/2014/05/29/acceptance-testing-using-jbehave-spring-framework-and-maven/"/>
    <updated>2014-05-29T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/05/29/acceptance-testing-using-jbehave-spring-framework-and-maven</id>
    <content type="html"><![CDATA[<p>This post documents acceptance testing best practices collected in regular projects I was working on.
Best practices materialized into working <a href="https://github.com/mkuthan/example-jbehave">project</a>, using <em>Jbehave</em>, <em>Spring Framework</em> and <em>Maven</em>.</p>

<p>After the lecture you will know:</p>

<ul>
<li>How to implement automated acceptance tests and avoid common traps.</li>
<li>How to organize project build using <em>Maven</em>.</li>
<li>How to configure project and glue everything together using <em>Spring Framework</em>.</li>
<li>How to write test scenarios using <em>JBehave</em>.</li>
<li>Finally how to run tests from command line and from your favourite IDE.</li>
</ul>


<h2>Automated acceptance tests</h2>

<p>Automated acceptance test suite is a system documentation, the real single source of truth.
The best documentation I&rsquo;ve ever seen: always up-to-date, unambiguous and precise.</p>

<p>But I found many traps when I was trying to apply acceptance tests automation in practice.</p>

<blockquote><p>Acceptance Testing is about collaboration not tools.</p></blockquote>

<p>You will get much better results if you will collaborate closely with product owner, end users and customer.
You could write test scenario only by yourself but perhaps you will fail.
When you are able to work on test scenarios together, you could think about tools and automation.
Do not let that tools interfere in collaboration, all team members must be committed to acceptance tests contribution.</p>

<blockquote><p>Acceptance Testing needs to be done using user interface.</p></blockquote>

<p>In most situation you don&rsquo;t need to implement tests using user interface.</p>

<p>User interface tends to be changed frequently, business logic not so often.
I don&rsquo;t want to change my tests when business logic stays unchanged, even if user interface has been changed significantly.</p>

<p>User interface tests are very fragile and slow. You will lost one of the automated tests advantages: fast and precise feedback loop.
It is really hard to setup and maintain the infrastructure for user interface testing.</p>

<blockquote><p>Everything should be tested.</p></blockquote>

<p>Acceptance tests are mainly for happy path scenarios verification.
Acceptance tests are expensive to maintain, so do not test corner cases, validation and error handling, on that level.
Focus only on the relevant assertions for the given scenario, do not verify everything only because you can.</p>

<h2>Project build organization</h2>

<p>After bunch of theory it is time to show real code. Let&rsquo;s start with proper project organization.
I found that acceptance testing is a cross cutting aspect of the application, and should be separated from the application code.
Acceptance tests build configuration is very specific and I don&rsquo;t want to clutter application build configuration.
You can also utilize multi module project, to ensure that acceptance tests module is allowed to call application public API only.
This segregation applies only for acceptance testing, the best place for unit tests is still in an application module under <code>src/test</code> directory.</p>

<p>With <em>Maven</em> (and other build tools like <em>Gradle</em>), application code and acceptance tests code can be located in separate modules.</p>

<figure class='code'><figcaption><span>Parent module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;project&gt;</span>
</span><span class='line'>    <span class="nt">&lt;groupId&gt;</span>example<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>example-jbehave<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;version&gt;</span>1.0-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;packaging&gt;</span>pom<span class="nt">&lt;/packaging&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;modules&gt;</span>
</span><span class='line'>        <span class="nt">&lt;module&gt;</span>example-jbehave-app<span class="nt">&lt;/module&gt;</span>
</span><span class='line'>        <span class="nt">&lt;module&gt;</span>example-jbehave-tests<span class="nt">&lt;/module&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/modules&gt;</span>
</span><span class='line'><span class="nt">&lt;/project&gt;</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>Web application module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;project&gt;</span>
</span><span class='line'>    <span class="nt">&lt;parent&gt;</span>
</span><span class='line'>        <span class="nt">&lt;groupId&gt;</span>example<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>        <span class="nt">&lt;artifactId&gt;</span>example-jbehave<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>        <span class="nt">&lt;version&gt;</span>1.0-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/parent&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>example-jbehave-app<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;packaging&gt;</span>war<span class="nt">&lt;/packaging&gt;</span>
</span><span class='line'><span class="nt">&lt;/project&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<figure class='code'><figcaption><span>Tests module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;project&gt;</span>
</span><span class='line'>    <span class="nt">&lt;parent&gt;</span>
</span><span class='line'>        <span class="nt">&lt;groupId&gt;</span>example<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>        <span class="nt">&lt;artifactId&gt;</span>example-jbehave<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>        <span class="nt">&lt;version&gt;</span>1.0-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/parent&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>example-jbehave-tests<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;packaging&gt;</span>jar<span class="nt">&lt;/packaging&gt;</span>
</span><span class='line'><span class="nt">&lt;/project&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>The parent module is the best place to define common configuration properties inherited by child modules.</p>

<figure class='code'><figcaption><span>Configuration properties in parent module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;properties&gt;</span>
</span><span class='line'>    <span class="nt">&lt;project.build.sourceEncoding&gt;</span>UTF-8<span class="nt">&lt;/project.build.sourceEncoding&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;maven.compiler.source&gt;</span>1.7<span class="nt">&lt;/maven.compiler.source&gt;</span>
</span><span class='line'>    <span class="nt">&lt;maven.compiler.target&gt;</span>1.7<span class="nt">&lt;/maven.compiler.target&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;jbehave.version&gt;</span>3.9.2<span class="nt">&lt;/jbehave.version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;logback.version&gt;</span>1.1.1<span class="nt">&lt;/logback.version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;slf4j.version&gt;</span>1.7.6<span class="nt">&lt;/slf4j.version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;spring.version&gt;</span>4.0.5.RELEASE<span class="nt">&lt;/spring.version&gt;</span>
</span><span class='line'><span class="nt">&lt;/properties&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the parent module you could also define <em>Spring Framework</em> BOM (Bill Of Materials), to ensure consistent dependency management.
This is quite new <em>Spring Framework</em> ecosystem feature.</p>

<figure class='code'><figcaption><span>Dependency management in parent module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependencyManagement&gt;</span>
</span><span class='line'>    <span class="nt">&lt;dependencies&gt;</span>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.springframework<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>spring-framework-bom<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${spring.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;type&gt;</span>pom<span class="nt">&lt;/type&gt;</span>
</span><span class='line'>            <span class="nt">&lt;scope&gt;</span>import<span class="nt">&lt;/scope&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>        (...)
</span><span class='line'>    <span class="nt">&lt;/dependencies&gt;</span>
</span><span class='line'><span class="nt">&lt;dependencyManagement&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Because I prefer <em>SLF4J</em> over <em>Apache Commons Logging</em>, unwanted dependency is excluded globally from <code>spring-core</code> artifact.</p>

<figure class='code'><figcaption><span>Dependency management in parent module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependencyManagement&gt;</span>
</span><span class='line'>    <span class="nt">&lt;dependencies&gt;</span>
</span><span class='line'>        (...)
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.springframework<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>spring-core<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${spring.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;exclusions&gt;</span>
</span><span class='line'>                <span class="nt">&lt;exclusion&gt;</span>
</span><span class='line'>                    <span class="nt">&lt;groupId&gt;</span>commons-logging<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>                    <span class="nt">&lt;artifactId&gt;</span>commons-logging<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>                <span class="nt">&lt;/exclusion&gt;</span>
</span><span class='line'>            <span class="nt">&lt;/exclusions&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dependencies&gt;</span>
</span><span class='line'><span class="nt">&lt;/dependencyManagement&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>In the application module declare all application dependencies.
In real application the list will be much longer.</p>

<figure class='code'><figcaption><span>Dependency management in application module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependencies&gt;</span>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.springframework<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>spring-webmvc<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.slf4j<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>slf4j-api<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${slf4j.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.slf4j<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>jcl-over-slf4j<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${slf4j.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;scope&gt;</span>runtime<span class="nt">&lt;/scope&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>ch.qos.logback<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>logback-classic<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${logback.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;scope&gt;</span>runtime<span class="nt">&lt;/scope&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dependencies&gt;</span>
</span><span class='line'><span class="nt">&lt;/project&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Maven War Plugin</em> must be configured specifically, classes (the content of the WEB-INF/classes directory) must be attached to the project as an additional artifact.
Acceptance test module depends on this additional artifact. Set <code>attachClasses</code> property to <code>true</code>.</p>

<figure class='code'><figcaption><span>War plugin configuration in application module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="o">&lt;</span><span class="n">plugin</span><span class="o">&gt;</span>
</span><span class='line'>    <span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">maven</span><span class="o">.</span><span class="na">plugins</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
</span><span class='line'>    <span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">maven</span><span class="o">-</span><span class="n">war</span><span class="o">-</span><span class="n">plugin</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
</span><span class='line'>    <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span><span class="mf">2.4</span><span class="o">&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
</span><span class='line'>    <span class="o">&lt;</span><span class="n">configuration</span><span class="o">&gt;</span>
</span><span class='line'>        <span class="o">&lt;</span><span class="n">attachClasses</span><span class="o">&gt;</span><span class="kc">true</span><span class="o">&lt;/</span><span class="n">attachClasses</span><span class="o">&gt;</span>
</span><span class='line'>    <span class="o">&lt;/</span><span class="n">configuration</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">plugin</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Alternatively you can use two separate modules for the application.
One <em>jar</em> type with domain and infrastructure and separate <em>war</em> type with web layer.
Then you would declare dependency to your <em>jar</em> application module only.
In my example I would keep it simple, and use single <em>war</em> type module for all layers in the application.</p>

<p>In the tests module declare all dependencies as well.
There is also an extra dependency to the application module, additional <em>jar</em> type artifact generated by <em>Maven War Plugin</em>.
The last two dependencies of <code>zip</code> type are needed to generate <em>JBehave</em> tests report.</p>

<figure class='code'><figcaption><span>Dependency management in tests module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependencies&gt;</span>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>${project.groupId}<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>example-jbehave-app<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${project.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;classifier&gt;</span>classes<span class="nt">&lt;/classifier&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.springframework<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>spring-test<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.jbehave<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>jbehave-core<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${jbehave.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.jbehave<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>jbehave-spring<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${jbehave.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.jbehave.site<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>jbehave-site-resources<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>3.1.1<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;type&gt;</span>zip<span class="nt">&lt;/type&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>org.jbehave<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>jbehave-core<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${jbehave.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;classifier&gt;</span>resources<span class="nt">&lt;/classifier&gt;</span>
</span><span class='line'>            <span class="nt">&lt;type&gt;</span>zip<span class="nt">&lt;/type&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dependencies&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Two <em>Maven</em> plugins must be configured specifically in the tests module: <code>maven-surefire-plugin</code> and <code>jbehave-maven-plugin</code>.</p>

<p>Because we separated tests into it&rsquo;s own module, test classes might be located under <code>src/main</code> as first class citizen.
<em>Surefire</em> is configured to execute test scenarios under <code>example/jbehave/tests/stories</code> package.</p>

<figure class='code'><figcaption><span>Surefire plugin configuration in tests module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;plugin&gt;</span>
</span><span class='line'>    <span class="nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>maven-surefire-plugin<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;version&gt;</span>2.17<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;configuration&gt;</span>
</span><span class='line'>        <span class="nt">&lt;testSourceDirectory&gt;</span>${basedir}/src/main/java/<span class="nt">&lt;/testSourceDirectory&gt;</span>
</span><span class='line'>        <span class="nt">&lt;testClassesDirectory&gt;</span>${project.build.directory}/classes/<span class="nt">&lt;/testClassesDirectory&gt;</span>
</span><span class='line'>        <span class="nt">&lt;includes&gt;</span>
</span><span class='line'>            <span class="nt">&lt;include&gt;</span>example/jbehave/tests/stories/**/*.java<span class="nt">&lt;/include&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/includes&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/configuration&gt;</span>
</span><span class='line'><span class="nt">&lt;/plugin&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>In my setup <em>JBehave</em> plugin will be responsible only for unpacking resources used by tests report.
I do not use plugin to run stories at all, I found better way to do that. It will be described later in the post.</p>

<figure class='code'><figcaption><span>JBehave plugin configuration in tests module</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;plugin&gt;</span>
</span><span class='line'>    <span class="nt">&lt;groupId&gt;</span>org.jbehave<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>jbehave-maven-plugin<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;version&gt;</span>${jbehave.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;executions&gt;</span>
</span><span class='line'>        <span class="nt">&lt;execution&gt;</span>
</span><span class='line'>            <span class="nt">&lt;id&gt;</span>unpack-view-resources<span class="nt">&lt;/id&gt;</span>
</span><span class='line'>            <span class="nt">&lt;phase&gt;</span>generate-resources<span class="nt">&lt;/phase&gt;</span>
</span><span class='line'>            <span class="nt">&lt;goals&gt;</span>
</span><span class='line'>                <span class="nt">&lt;goal&gt;</span>unpack-view-resources<span class="nt">&lt;/goal&gt;</span>
</span><span class='line'>            <span class="nt">&lt;/goals&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/execution&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/executions&gt;</span>
</span><span class='line'><span class="nt">&lt;/plugin&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Spring Framework configuration</h2>

<p>The application implements shopping basket simplified functionality.
Do not use my shopping basket implementation on production, it is only for this post educational purposes :&ndash;)</p>

<p>The application is composed from three main packages: <code>domain</code>, <code>infrastructure</code> and <code>web</code>.
This convention comes from Domain Driven Design, you can read more in my post <a href="http://mkuthan.github.io/blog/2013/11/04/ddd-architecture-summary/">DDD Architecture Summary</a>.</p>

<p>Each package is configured using <em>Spring Framework</em> annotation support.
In general you should keep the configuration as modular as possible.
It is very important for testing, with modular configuration you can load only needed context and speed up tests execution.</p>

<figure class='code'><figcaption><span>DomainConfiguration.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Configuration</span>
</span><span class='line'><span class="nd">@ComponentScan</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">DomainConfiguration</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>InfrastructureConfiguration.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Configuration</span>
</span><span class='line'><span class="nd">@ComponentScan</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">InfrastructureConfiguration</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>WebConfiguration.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Configuration</span>
</span><span class='line'><span class="nd">@ComponentScan</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WebConfiguration</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you are interested in application functionality, go to the <a href="https://github.com/mkuthan/example-jbehave/tree/master/example-jbehave-app/src/main/java/example/jbehave/app">source code</a>.
The application is really simple, just old plain Java.</p>

<p>Much more interesting is <em>Spring Framework</em> configuration in tests module.
First the meta annotation for acceptance tests is defined.
This is a new way to avoid repetition in tests definition, introduced in <em>Spring Framework</em> recently.</p>

<figure class='code'><figcaption><span>AcceptanceTest.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@ContextConfiguration</span><span class="o">(</span><span class="n">classes</span> <span class="o">=</span> <span class="n">AcceptanceTestsConfiguration</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
</span><span class='line'><span class="nd">@ImportResource</span><span class="o">({</span><span class="s">&quot;classpath:/application.properties&quot;</span><span class="o">,</span> <span class="s">&quot;classpath:/tests.properties&quot;</span><span class="o">})</span>
</span><span class='line'><span class="nd">@ActiveProfiles</span><span class="o">(</span><span class="s">&quot;tests&quot;</span><span class="o">)</span>
</span><span class='line'><span class="nd">@DirtiesContext</span>
</span><span class='line'><span class="nd">@Target</span><span class="o">(</span><span class="n">ElementType</span><span class="o">.</span><span class="na">TYPE</span><span class="o">)</span>
</span><span class='line'><span class="nd">@Retention</span><span class="o">(</span><span class="n">RetentionPolicy</span><span class="o">.</span><span class="na">RUNTIME</span><span class="o">)</span>
</span><span class='line'><span class="kd">public</span> <span class="nd">@interface</span> <span class="n">AcceptanceTest</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Tests configuration is loaded, again using Java config instead of XML.</li>
<li>Load application properties and overwrite defaults using tests properties if needed.</li>
<li>Activate some special <em>Spring Framework</em> profile(s). Another way to customize tests configuration.</li>
<li>Acceptance tests have side effects typically. Reload context before every story execution.</li>
</ol>


<p>The <code>AcceptanceTestsConfiguration</code> class is again very simple.
It imports application configurations: domain and infrastructure.
Because we will implement acceptance tests using service layer, we don&rsquo;t need to load web module or run web container.</p>

<figure class='code'><figcaption><span>AcceptanceTestsConfiguration</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Configuration</span>
</span><span class='line'><span class="nd">@Import</span><span class="o">({</span><span class="n">DomainConfiguration</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">InfrastructureConfiguration</span><span class="o">.</span><span class="na">class</span><span class="o">})</span>
</span><span class='line'><span class="nd">@ComponentScan</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AcceptanceTestsConfiguration</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Meta annotation support is also used to define very specific annotations, one for <em>JBehave</em> test steps, second for <em>JBehave</em> converters.
Well crafted annotations are better than generic <code>@Component</code>, even if they do not provide additional features.</p>

<figure class='code'><figcaption><span>Steps.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Target</span><span class="o">(</span><span class="n">value</span> <span class="o">=</span> <span class="n">ElementType</span><span class="o">.</span><span class="na">TYPE</span><span class="o">)</span>
</span><span class='line'><span class="nd">@Retention</span><span class="o">(</span><span class="n">value</span> <span class="o">=</span> <span class="n">RetentionPolicy</span><span class="o">.</span><span class="na">RUNTIME</span><span class="o">)</span>
</span><span class='line'><span class="nd">@Documented</span>
</span><span class='line'><span class="nd">@Component</span>
</span><span class='line'><span class="kd">public</span> <span class="nd">@interface</span> <span class="n">Steps</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>Converter.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Target</span><span class="o">(</span><span class="n">value</span> <span class="o">=</span> <span class="n">ElementType</span><span class="o">.</span><span class="na">TYPE</span><span class="o">)</span>
</span><span class='line'><span class="nd">@Retention</span><span class="o">(</span><span class="n">value</span> <span class="o">=</span> <span class="n">RetentionPolicy</span><span class="o">.</span><span class="na">RUNTIME</span><span class="o">)</span>
</span><span class='line'><span class="nd">@Documented</span>
</span><span class='line'><span class="nd">@Component</span>
</span><span class='line'><span class="kd">public</span> <span class="nd">@interface</span> <span class="n">Converter</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>JBehave configuration</h2>

<p>The last infrastructure element in tests module is a base class for stories.
<em>JBehave</em> provides plenty of integration methods with <em>Spring Framework</em> and I spent a lot of time to select the best one.</p>

<p>I have following requirements:</p>

<ul>
<li>The ability to run single story from my IDE.</li>
<li>Meet Open Close Principle. When I add new story I do not want to modify any existing file. I want to add new one(s).</li>
<li>Have a full control over <em>JBehave</em> configuration.</li>
</ul>


<p>To meet my requirements some base class for all tests must be defined.
I do not like the idea to use inheritance here but I did not find better way.</p>

<p>Let me describe <code>AbstractSpringJBehaveStory</code> step by step:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">AbstractSpringJBehaveStory</span> <span class="kd">extends</span> <span class="n">JUnitStory</span> <span class="o">{</span>
</span><span class='line'><span class="o">...</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>JUnitStory</code> is a <em>JBehave</em> class with single test to run single story.
It means that any subclass of this class can be executed as regular <em>JUnit</em> test.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">STORY_TIMEOUT</span> <span class="o">=</span> <span class="mi">120</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="nf">AbstractSpringJBehaveStory</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">Embedder</span> <span class="n">embedder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Embedder</span><span class="o">();</span>
</span><span class='line'>    <span class="n">embedder</span><span class="o">.</span><span class="na">useEmbedderControls</span><span class="o">(</span><span class="n">embedderControls</span><span class="o">());</span>
</span><span class='line'>    <span class="n">embedder</span><span class="o">.</span><span class="na">useMetaFilters</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;-skip&quot;</span><span class="o">));</span>
</span><span class='line'>    <span class="n">useEmbedder</span><span class="o">(</span><span class="n">embedder</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">private</span> <span class="n">EmbedderControls</span> <span class="nf">embedderControls</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">EmbedderControls</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">doIgnoreFailureInView</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">useStoryTimeoutInSecs</span><span class="o">(</span><span class="n">STORY_TIMEOUT</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The constructor initialize <em>JBehave</em> embedder, a fascade to embed <em>JBehave</em> functionality in JUnit runner.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Autowired</span>
</span><span class='line'><span class="kd">private</span> <span class="n">ApplicationContext</span> <span class="n">applicationContext</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="nd">@Override</span>
</span><span class='line'><span class="kd">public</span> <span class="n">InjectableStepsFactory</span> <span class="nf">stepsFactory</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">SpringStepsFactory</span><span class="o">(</span><span class="n">configuration</span><span class="o">(),</span> <span class="n">applicationContext</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Configure <em>JBehave</em> to load steps and converters from <em>Spring Framework</em> context.
What is also important, the steps and converters are managed by <em>Spring Framework</em>, you can inject whatever you want.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Override</span>
</span><span class='line'><span class="kd">public</span> <span class="n">Configuration</span> <span class="nf">configuration</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">MostUsefulConfiguration</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">useStoryPathResolver</span><span class="o">(</span><span class="n">storyPathResolver</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">useStoryLoader</span><span class="o">(</span><span class="n">storyLoader</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">useStoryReporterBuilder</span><span class="o">(</span><span class="n">storyReporterBuilder</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">useParameterControls</span><span class="o">(</span><span class="n">parameterControls</span><span class="o">());</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>configuration</code> method is surprisingly responsible for <em>JBehave</em> configuration.
The most useful configuration is used with some customizations.
Let&rsquo;s check what kind of customization are applied.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">private</span> <span class="n">StoryPathResolver</span> <span class="nf">storyPathResolver</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">UnderscoredCamelCaseResolver</span><span class="o">();</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The story path resolver is responsible for resolving story based on test class name.
With <code>UnderscoredCamelCaseResolver</code> implementation, story <code>learn_jbehave_story.story</code> will be correlated with <code>LearnJbehaveStory.java</code> class.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">private</span> <span class="n">StoryLoader</span> <span class="nf">storyLoader</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">LoadFromClasspath</span><span class="o">();</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Stories will be resolved and loaded from the current classpath (from <code>src/main/resources</code> to be more specific).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">private</span> <span class="n">StoryReporterBuilder</span> <span class="nf">storyReporterBuilder</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">StoryReporterBuilder</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withCodeLocation</span><span class="o">(</span><span class="n">CodeLocations</span><span class="o">.</span><span class="na">codeLocationFromClass</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="na">getClass</span><span class="o">()))</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withPathResolver</span><span class="o">(</span><span class="k">new</span> <span class="n">ResolveToPackagedName</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withFailureTrace</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withDefaultFormats</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withFormats</span><span class="o">(</span><span class="n">IDE_CONSOLE</span><span class="o">,</span> <span class="n">TXT</span><span class="o">,</span> <span class="n">HTML</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The configuration how the reports will look like.
Nothing special, please refer to <em>JBehave</em> reference documentation for more details.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">private</span> <span class="n">ParameterControls</span> <span class="nf">parameterControls</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">ParameterControls</span><span class="o">()</span>
</span><span class='line'>            <span class="o">.</span><span class="na">useDelimiterNamedParameters</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The configuration how the steps parameters will be handled.</p>

<h2>Test scenarios definition</h2>

<p>Test scenarios are rather straightforward, if you are familiar with BDD and Gherkin like syntax. If not please read
<a href="http://jbehave.org/reference/stable/concepts.html">BDD Concepts</a> short definition.</p>

<p>Look, in the scenarios there is nothing specific to the application user interface.
It is not important how product price editor looks like, and how the shopping basket is presented.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nl">Narrative:</span>
</span><span class='line'><span class="n">In</span> <span class="n">order</span> <span class="n">to</span> <span class="n">learn</span> <span class="n">JBehave</span>
</span><span class='line'><span class="n">As</span> <span class="n">a</span> <span class="n">tester</span>
</span><span class='line'><span class="n">I</span> <span class="n">want</span> <span class="n">to</span> <span class="n">define</span> <span class="n">sample</span> <span class="n">story</span> <span class="k">for</span> <span class="n">shopping</span> <span class="n">cart</span>
</span><span class='line'>
</span><span class='line'><span class="nl">Lifecycle:</span>
</span><span class='line'><span class="nl">Before:</span>
</span><span class='line'><span class="n">Given</span> <span class="n">product</span> <span class="n">Domain</span> <span class="n">Driven</span> <span class="n">Design</span> <span class="n">with</span> <span class="n">SKU</span> <span class="mi">1234</span>
</span><span class='line'><span class="n">And</span> <span class="n">product</span> <span class="n">Domain</span> <span class="n">Driven</span> <span class="n">Design</span> <span class="n">price</span> <span class="n">is</span> <span class="mi">35</span> <span class="n">EUR</span>
</span><span class='line'>
</span><span class='line'><span class="n">Given</span> <span class="n">product</span> <span class="n">Specification</span> <span class="n">By</span> <span class="n">Example</span> <span class="n">with</span> <span class="n">SKU</span> <span class="mi">2345</span>
</span><span class='line'><span class="n">And</span> <span class="n">product</span> <span class="n">Specification</span> <span class="n">By</span> <span class="n">Example</span> <span class="n">price</span> <span class="n">is</span> <span class="mi">30</span> <span class="n">EUR</span>
</span><span class='line'>
</span><span class='line'><span class="nl">Scenario:</span> <span class="n">Empty</span> <span class="n">shopping</span> <span class="n">cart</span>
</span><span class='line'>
</span><span class='line'><span class="n">Given</span> <span class="n">empty</span> <span class="n">shopping</span> <span class="n">cart</span>
</span><span class='line'><span class="n">Then</span> <span class="n">shopping</span> <span class="n">cart</span> <span class="n">is</span> <span class="n">empty</span>
</span><span class='line'>
</span><span class='line'><span class="nl">Scenario:</span> <span class="n">Products</span> <span class="n">are</span> <span class="n">added</span> <span class="n">to</span> <span class="n">empty</span> <span class="n">shopping</span> <span class="n">cart</span>
</span><span class='line'>
</span><span class='line'><span class="n">Given</span> <span class="n">empty</span> <span class="n">shopping</span> <span class="n">cart</span>
</span><span class='line'><span class="n">When</span> <span class="n">products</span> <span class="n">are</span> <span class="n">added</span> <span class="n">to</span> <span class="n">the</span> <span class="n">shopping</span> <span class="nl">cart:</span>
</span><span class='line'><span class="o">|</span><span class="n">PRODUCT</span>                 <span class="o">|</span><span class="n">QTY</span><span class="o">|</span>
</span><span class='line'><span class="o">|</span><span class="n">Domain</span> <span class="n">Driven</span> <span class="n">Design</span>    <span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
</span><span class='line'><span class="o">|</span><span class="n">Specification</span> <span class="n">By</span> <span class="n">Example</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
</span><span class='line'>
</span><span class='line'><span class="n">Then</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">products</span> <span class="n">in</span> <span class="n">shopping</span> <span class="n">cart</span> <span class="n">is</span> <span class="mi">2</span>
</span><span class='line'><span class="n">And</span> <span class="n">total</span> <span class="n">price</span> <span class="n">is</span> <span class="mi">95</span> <span class="n">EUR</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Test steps implementation</h2>

<p>Test steps are implemented in Java classes annotated with <code>@Steps</code>.
The common mistake is to develop steps only for single story.
The steps should be reusable across many user stories if feasible.
With reusable steps you will find, that writing next user stories are much easier and faster.
You can just use existing steps implementation to define new user story.</p>

<p>For example steps for product catalog and product prices are defined in <code>SharedSteps</code> class.
The repositories are used to manage products and prices.
In real application, you should use application service and it&rsquo;s public API instead of direct access to the repositories.
Please think about steps implementation complexity, if we would need to use user interface, instead of repositories or service API.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Steps</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SharedSteps</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Autowired</span>
</span><span class='line'>    <span class="kd">private</span> <span class="n">ProductRepository</span> <span class="n">productRepository</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Autowired</span>
</span><span class='line'>    <span class="kd">private</span> <span class="n">PriceRepository</span> <span class="n">priceRepository</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Given</span><span class="o">(</span><span class="s">&quot;product $name with SKU $sku&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">product</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">,</span> <span class="n">StockKeepingUnit</span> <span class="n">sku</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">productRepository</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="k">new</span> <span class="n">Product</span><span class="o">(</span><span class="n">sku</span><span class="o">,</span> <span class="n">name</span><span class="o">));</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Given</span><span class="o">(</span><span class="s">&quot;product $name price is $price&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">price</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">,</span> <span class="n">Money</span> <span class="n">price</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Product</span> <span class="n">product</span> <span class="o">=</span> <span class="n">productRepository</span><span class="o">.</span><span class="na">findByName</span><span class="o">(</span><span class="n">name</span><span class="o">);</span>
</span><span class='line'>        <span class="n">priceRepository</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">product</span><span class="o">.</span><span class="na">getSku</span><span class="o">(),</span> <span class="n">price</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>You could ask, how does <em>JBehave</em> know about <code>StockKeepingUnit</code> and <code>Money</code> classes?
You will have to implement custom converters but it is much more convenient to use well defined API, instead of dozen of <code>String</code> based values.</p>

<figure class='code'><figcaption><span>MoneyConverter</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Converter</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MoneyConverter</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@AsParameterConverter</span>
</span><span class='line'>    <span class="kd">public</span> <span class="n">Money</span> <span class="nf">convertPercent</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">(</span><span class="n">StringUtils</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">(</span><span class="n">value</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">return</span> <span class="kc">null</span><span class="o">;</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">String</span><span class="o">[]</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot;\\s&quot;</span><span class="o">);</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">(</span><span class="n">tokens</span><span class="o">.</span><span class="na">length</span> <span class="o">!=</span> <span class="mi">2</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">throw</span> <span class="k">new</span> <span class="n">ParameterConverters</span><span class="o">.</span><span class="na">ParameterConvertionFailed</span><span class="o">(</span><span class="s">&quot;Expected 2 tokens (amount and currency) but got &quot;</span> <span class="o">+</span> <span class="n">tokens</span><span class="o">.</span><span class="na">length</span> <span class="o">+</span> <span class="s">&quot;, value: &quot;</span> <span class="o">+</span> <span class="n">value</span> <span class="o">+</span> <span class="s">&quot;.&quot;</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">return</span> <span class="k">new</span> <span class="nf">Money</span><span class="o">(</span><span class="n">tokens</span><span class="o">[</span><span class="mi">0</span><span class="o">],</span> <span class="n">tokens</span><span class="o">[</span><span class="mi">1</span><span class="o">]);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The class <code>MoneyConverter</code> is annotated with <code>@Converter</code> annotation defined before.
<code>StringUtils</code> is a utility class from <em>Spring Framework</em>, look at the API documentation how many helpful utils classes are implemented in the framework.
If the value cannot be converted, <em>JBehave</em> <code>ParameterConvertionFailed</code> exception is thrown.</p>

<p>The shopping cart related steps are implemented in <code>ShoppingCartSteps</code> class.</p>

<figure class='code'><figcaption><span>ShoppingCartSteps</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@Steps</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">ShoppingCartSteps</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Autowired</span>
</span><span class='line'>    <span class="kd">private</span> <span class="n">ShoppingCartService</span> <span class="n">shoppingCartService</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Autowired</span>
</span><span class='line'>    <span class="kd">private</span> <span class="n">ProductDao</span> <span class="n">productRepository</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Given</span><span class="o">(</span><span class="s">&quot;empty shopping cart&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">emptyShoppingCart</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">shoppingCartService</span><span class="o">.</span><span class="na">createEmptyShoppingCart</span><span class="o">();</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@When</span><span class="o">(</span><span class="s">&quot;products are added to the shopping cart: $rows&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">addProducts</span><span class="o">(</span><span class="n">List</span><span class="o">&lt;</span><span class="n">ShoppingCartRow</span><span class="o">&gt;</span> <span class="n">rows</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">for</span> <span class="o">(</span><span class="n">ShoppingCartRow</span> <span class="n">row</span> <span class="o">:</span> <span class="n">rows</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">Product</span> <span class="n">product</span> <span class="o">=</span> <span class="n">productRepository</span><span class="o">.</span><span class="na">findByName</span><span class="o">(</span><span class="n">row</span><span class="o">.</span><span class="na">getProductName</span><span class="o">());</span>
</span><span class='line'>            <span class="n">shoppingCartService</span><span class="o">.</span><span class="na">addProductToShoppingCart</span><span class="o">(</span><span class="n">product</span><span class="o">.</span><span class="na">getSku</span><span class="o">(),</span> <span class="n">row</span><span class="o">.</span><span class="na">getQuantity</span><span class="o">());</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Then</span><span class="o">(</span><span class="s">&quot;shopping cart is empty&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">isEmpty</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">ShoppingCart</span> <span class="n">shoppingCart</span> <span class="o">=</span> <span class="n">shoppingCartService</span><span class="o">.</span><span class="na">getShoppingCart</span><span class="o">();</span>
</span><span class='line'>        <span class="n">assertEquals</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">shoppingCart</span><span class="o">.</span><span class="na">numberOfItems</span><span class="o">());</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Then</span><span class="o">(</span><span class="s">&quot;the number of products in shopping cart is $numberOfItems&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">numberOfItems</span><span class="o">(</span><span class="kt">int</span> <span class="n">numberOfItems</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">ShoppingCart</span> <span class="n">shoppingCart</span> <span class="o">=</span> <span class="n">shoppingCartService</span><span class="o">.</span><span class="na">getShoppingCart</span><span class="o">();</span>
</span><span class='line'>        <span class="n">assertEquals</span><span class="o">(</span><span class="n">numberOfItems</span><span class="o">,</span> <span class="n">shoppingCart</span><span class="o">.</span><span class="na">numberOfItems</span><span class="o">());</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Then</span><span class="o">(</span><span class="s">&quot;total price is $price&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="nd">@Pending</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">totalPrice</span><span class="o">(</span><span class="n">Money</span> <span class="n">price</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="c1">// TODO: implement missing functionality and enable step</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>There are two interesting elements:</p>

<ul>
<li>Last step annotated with <code>@Pending</code> annotation.</li>
<li><code>ShoppingCartRow</code> class used to defined products added to the cart.</li>
</ul>


<p>Typically user story is prepared before implementation.
In this situation you will have several pending steps, slowly implemented during the sprint.
Pending step does not mean that acceptance tests have failed, it only means that functionality has not been implemented yet.</p>

<p><code>ShoppingCartRow</code> is a simple bean prepared for tabular parameters definition in the story. Do you remember this step?</p>

<figure class='code'><figcaption><span>ShoppingCartSteps</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">When</span> <span class="n">products</span> <span class="n">are</span> <span class="n">added</span> <span class="n">to</span> <span class="n">the</span> <span class="n">shopping</span> <span class="nl">cart:</span>
</span><span class='line'><span class="o">|</span><span class="n">PRODUCT</span>                 <span class="o">|</span><span class="n">QTY</span><span class="o">|</span>
</span><span class='line'><span class="o">|</span><span class="n">Domain</span> <span class="n">Driven</span> <span class="n">Design</span>    <span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
</span><span class='line'><span class="o">|</span><span class="n">Specification</span> <span class="n">By</span> <span class="n">Example</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
</span></code></pre></td></tr></table></div></figure>


<p>Basket presented in tabular form is much easier to read than if it would be defined line by line.
To use this kind of parameter you have to prepare a class with a few annotations.</p>

<figure class='code'><figcaption><span>ShoppingCartRow</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@AsParameters</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">ShoppingCartRow</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Parameter</span><span class="o">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">&quot;PRODUCT&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">private</span> <span class="n">String</span> <span class="n">productName</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Parameter</span><span class="o">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">&quot;QTY&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="kd">private</span> <span class="n">Integer</span> <span class="n">quantity</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="n">String</span> <span class="nf">getProductName</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">productName</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setProductName</span><span class="o">(</span><span class="n">String</span> <span class="n">productName</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">this</span><span class="o">.</span><span class="na">productName</span> <span class="o">=</span> <span class="n">productName</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">getQuantity</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">quantity</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setQuantity</span><span class="o">(</span><span class="n">Integer</span> <span class="n">quantity</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">this</span><span class="o">.</span><span class="na">quantity</span> <span class="o">=</span> <span class="n">quantity</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>JBehave</em> uses this annotated class to convert table row from user story to Java object.</p>

<h2>Running tests</h2>

<p>The last part of this post is about running tests.</p>

<p>For every user story definition, one test class is defined.
The test class is only the marker and does not define any logic.</p>

<figure class='code'><figcaption><span>LearnJBehaveStory.java</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="nd">@RunWith</span><span class="o">(</span><span class="n">SpringJUnit4ClassRunner</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
</span><span class='line'><span class="nd">@AcceptanceTest</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">LearnJbehaveStory</span> <span class="kd">extends</span> <span class="n">AbstractSpringJBehaveStory</span> <span class="o">{</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The test can be executed directly from your favourite IDE, at least if the IDE provides support for JUnit runner.</p>

<p>The second way to execute tests is to use <em>Maven</em> from command line.
As long as tests are executed by regular <em>Maven Surefire Plugin</em>, the tests are executed exactly the same way like any other tests.
Run the following command from the project parent directory.
<em>Maven</em> builds the application module first, add the classes to the reactor classpath and then execute acceptance tests from tests module.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">mvn -pl example-jbehave-tests -am test</span>
</span></code></pre></td></tr></table></div></figure>


<p>The convenient way to execute single test from command line is to use regular Java property <code>-Dtest</code> recognized by <em>Surefire</em>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">mvn -pl example-jbehave-tests -am test -Dtest=LearnJbehaveStory</span>
</span><span class='line'><span class="go">...</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Summary</h2>

<p>In the post I presented the most important elements from example project.
The complete project is hosted on <a href="https://github.com/mkuthan/example-jbehave">GitHub</a>, you can clone/fork the project and do some experiments by yourself.
I configure <a href="https://travis-ci.org/mkuthan/example-jbehave">Travis</a> continuous integration build to ensure that the project really works.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Twelve-Factor App - Part 2]]></title>
    <link href="http://mkuthan.github.io/blog/2014/05/27/the-twelve-factor-app-part2/"/>
    <updated>2014-05-27T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/05/27/the-twelve-factor-app-part2</id>
    <content type="html"><![CDATA[<p>This blog post is a continuation of <a href="http://mkuthan.github.io/blog/2014/05/26/the-twelve-factor-app-part1/">first part</a> of this blog series.</p>

<h2>7. Port Binding</h2>

<blockquote><p>The twelve-factor app is completely self-contained and does not rely on runtime injection of a webserver into the execution environment to create a web-facing service.</p></blockquote>

<p>I developed self-contained web application once, with embedded Jetty server.
There are many product with embedded web server on the market, e.g: Artifactory.
Now most of my POC (Proof of Concept) use Spring Boot, when you can run web application as regular system process.
After hell of JBoss class loader issues it seems to be the correct way to run the application.</p>

<h2>8. Concurrency</h2>

<blockquote><p>In the twelve-factor app, processes are a first class citizen.</p></blockquote>

<p>Using processes instead of threads is controversial in JVM world.
But I agree that you can not scale out using threads only.
What is also interesting, you should never daemonize process or write PID file.
Just align to the system process management tools like upstart.</p>

<h2>9. Disposability</h2>

<blockquote><p>The twelve-factor apps processes are disposable, meaning they can be started or stopped at a moments notice.</p></blockquote>

<p>I faced disposability issues, when I was developing applications hosted on GAE (Google App Engine).
Forget about any heavy duty frameworks on GAE, the startup process must be really light.
In general it is problematic in JVM world.
Startup time of the JVM is significant itself, and JMV must spin up our application as well.
If I could compare JVM startup performance to the node.js there is a huge difference.</p>

<p>I also remember how easily you can reconfigure system service when you can send -HUP signal.
It would be nice to have this possibility for my applications.</p>

<h2>10. Dev/prod parity</h2>

<blockquote><p>The twelve-factor app is designed for continuous deployment by keeping the gap between development and production small.</p></blockquote>

<p>Clear for me, test your production like environment as often as possible to minimize the risk.
If the production database is Oracle, use Oracle XE for local development, not MySQL or H2.
If the production applications server is JBoss, use JBoss locally or Apache Tomcat at last resort.
Use the same JVM with similar memory settings if feasible.
If you deploy your application on Linux, do not use Windows for local development.
Virtualization or lightweight containers are your friends.
And so on &hellip;</p>

<h2>11. Logs</h2>

<blockquote><p>A twelve-factor app never concerns itself with routing or storage of its output stream.</p></blockquote>

<p>Hmm, I would prefer to use any logger (SLF4J) with configured appender instead of stdout.
Instead file appender I could use Syslog appender and gather logs from all cluster nodes.
But maybe I&rsquo;m wrong with this. I understand the point, than stdout is a basic common denominator for all runtime platform.</p>

<h2>12. Admin processes</h2>

<blockquote><p>Twelve-factor strongly favors languages which provide a REPL shell out of the box, and which make it easy to run one-off scripts.</p></blockquote>

<p>For almost all my web application, I embedded BSH web servlet (Bean Shell Console). It rescued me out of trouble many times.
It isn&rsquo;t full fledged REPL like this one from Scala but still usable.
Oh, I forgot to mention about H2 web servlet, also embedded into most of my application.</p>

<p>Sometimes it is much easier to expose some admin functionality as JMX beans.
You can use Jolokia as REST JMX connector and easily prepare admin console using a few line of HTML and JavaScript.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Twelve-Factor App - Part 1]]></title>
    <link href="http://mkuthan.github.io/blog/2014/05/26/the-twelve-factor-app-part1/"/>
    <updated>2014-05-26T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2014/05/26/the-twelve-factor-app-part1</id>
    <content type="html"><![CDATA[<p>During my studies about &ldquo;Micro Services&rdquo; I found comprehensive (but short) document about <em>Twelve-Factor App</em> methodology
for building software-as-a-service applications. The orginal paper is published at <a href="http://12factor.net/">12factor.net</a>.</p>

<p>Below you can find a short summary of my experiences for the first part of the document.
There is also a <a href="http://mkuthan.github.io/blog/2014/05/27/the-twelve-factor-app-part2/">second part</a> of this blog post series.</p>

<h2>1. Codebase</h2>

<blockquote><p>There is always a one-to-one correlation between the codebase and the app</p></blockquote>

<p>I had the chance to use setup, where Subversion repository was shared for many projects.
Only once, and I said &ndash; &ldquo;never again&rdquo;.
I remember problems with release management, setting up access rights, and crazy revision numbers.</p>

<h2>2. Dependencies</h2>

<blockquote><p>A twelve-factor app never relies on implicit existence of system-wide packages</p></blockquote>

<p>I remember a setup where you spent whole day to build all dependencies (a lot of C and C++ code).
The solution was a repository with compiled and versioned dependencies.
Almost everything was compiled statically with minimal dependency to the core system libraries like stdc.</p>

<p>Right now I build projects using Maven repositories and artifacts.
But it is not enough for twelve-factor app, and I fully agree.
My next step should be using &ldquo;Infrastructure as a code&rdquo; principle in practice.</p>

<h2>3. Config</h2>

<blockquote><p>strict separation of config from code</p></blockquote>

<p>Some time ago my application was deployed on the wrong environment (WAR file prepared for QA environment was deployed on PROD).
It was one of the worst week in my career to rollback everything back.
Never again, I fully agree that binary should be environment independent. Keep configuration out of binary artifact.</p>

<h2>4. Backing Services</h2>

<blockquote><p>The code for a twelve-factor app makes no distinction between local and third party services</p></blockquote>

<p>I do not fully understand this chapter.
What I understood is that I should separate my domain from attached resources (local and third party services).
And it is what I have done many times:</p>

<ul>
<li>Externalize connection configuration</li>
<li>Use Anti Corruption Layer between my domain and infrastructure (e.g: hexagonal architecture)</li>
<li>Do not mix domain logic with infrastructure code.</li>
</ul>


<h2>5. Build, release, run</h2>

<blockquote><p>The twelve-factor app uses strict separation between the build, release, and run stages</p></blockquote>

<p>The difference between build and release stages is somehow new for me.
My JEE applications are released and deployed to the Maven repository.
The deployed WAR files are deployable on any environment, the configuration is externalized and applied during Maven WAR overlay process.
The outcome of the overlay is not stored as a reference but maybe it should. The question is where to put release?
Again in the Maven repository or as a Bamboo build artifact?</p>

<p>What I apply during the <em>run stage</em> is the database schema migration using <em>Liquibase</em> or <em>Flyway</em> and it really works.
I agree with author to keep this stage as small as possible.</p>

<p>And for sure direct changes on the production are prohibited.
I had to clean up the project when the changes were not checked in to the repository once, never again.</p>

<h2>6. Processes</h2>

<blockquote><p>Twelve-factor processes are stateless and share-nothing.</p></blockquote>

<p>I have never used this concept but I agree with author.
From the scalability perspective share-nothing architecture of stateless services is good.</p>

<p>Ok, 10 years ago I developed application using CORBA and there were remote calls to fully stateful remote object.
Bad idea, really.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Send Email From JEE Application]]></title>
    <link href="http://mkuthan.github.io/blog/2013/12/06/how-to-send-email-from-jee-application/"/>
    <updated>2013-12-06T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2013/12/06/how-to-send-email-from-jee-application</id>
    <content type="html"><![CDATA[<p>Sending email notifications from enterprise application is very common scenario.
I know several methods to solve this puzzle, below you can find short summary.</p>

<p>To send an email from the application at least SMTP server address must be configured.
Because released application binary (e.g: WAR file) should be portable across environments (integration, QA, staging,
production) configuration must be externalized.<br/>
Below I present code snippets to configure SMTP server address as JNDI entry.</p>

<p>Sample JNDI entry for JBoss:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
</span><span class='line'><span class="nt">&lt;server&gt;</span>
</span><span class='line'>  <span class="nt">&lt;mbean</span> <span class="na">code=</span><span class="s">&quot;org.jboss.mail.MailService&quot;</span> <span class="na">name=</span><span class="s">&quot;jboss:service=mailSession&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;attribute</span> <span class="na">name=</span><span class="s">&quot;JNDIName&quot;</span><span class="nt">&gt;</span>mail/mailSession<span class="nt">&lt;/attribute&gt;</span>
</span><span class='line'>    <span class="nt">&lt;attribute</span> <span class="na">name=</span><span class="s">&quot;Configuration&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;configuration&gt;</span>
</span><span class='line'>        <span class="nt">&lt;property</span> <span class="na">name=</span><span class="s">&quot;mail.smtp.host&quot;</span> <span class="na">value=</span><span class="s">&quot;smtp.company.com&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/configuration&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/attribute&gt;</span>
</span><span class='line'>    <span class="nt">&lt;depends&gt;</span>jboss:service=Naming<span class="nt">&lt;/depends&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/mbean&gt;</span>
</span><span class='line'><span class="nt">&lt;/server&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Sample JNDI entry for Tomcat:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
</span><span class='line'><span class="nt">&lt;Context&gt;</span>
</span><span class='line'>  <span class="nt">&lt;Resource</span> <span class="na">name=</span><span class="s">&quot;mail/mailSession&quot;</span>
</span><span class='line'>    <span class="na">auth=</span><span class="s">&quot;Container&quot;</span>
</span><span class='line'>    <span class="na">type=</span><span class="s">&quot;javax.mail.Session&quot;</span>
</span><span class='line'>    <span class="na">mail.smtp.host=</span><span class="s">&quot;smtp.company.com&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/Context&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>When mail session is configured as JNDI resource, it can be easily utilized by Spring Framework mail sender:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;jee:jndi-lookup</span> <span class="na">id=</span><span class="s">&quot;mailSession&quot;</span> <span class="na">jndi-name=</span><span class="s">&quot;mail/mailSession&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;bean</span> <span class="na">id=</span><span class="s">&quot;mailSender&quot;</span> <span class="na">class=</span><span class="s">&quot;org.springframework.mail.javamail.JavaMailSenderImpl&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;property</span> <span class="na">name=</span><span class="s">&quot;session&quot;</span> <span class="na">ref=</span><span class="s">&quot;mailSession&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/bean&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now it is time for more tough part, how to use mail sender correctly?
There are at least four options, choose the best one for you:</p>

<ul>
<li><em>Direct (Sync)</em> Use mail session directly from the application service in the web request thread.</li>
<li><em>Direct (Async)</em> Use mail session directly from the application service using <code>@Async</code> Spring annotation.</li>
<li><em>Database Queue</em> Save messages into database table and create cron job to send the emails periodically.</li>
<li><em>JMS Queue</em> Put messages into JMS queue and attach JMS listener to process and send emails.</li>
</ul>


<p>I collected a few non-functional and functional common requirements together with short categorization for each method.</p>

<table>
<thead>
<tr>
<th></th>
<th>                                           </th>
<th align="center">Direct (Sync)</th>
<th align="center">Direct (Async)</th>
<th align="center">Database Queue</th>
<th align="center">JMS Queue</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Application works even if the SMTP is down </td>
<td align="center">no</td>
<td align="center">no</td>
<td align="center">yes</td>
<td align="center">yes</td>
</tr>
<tr>
<td></td>
<td>Web request thread is not blocked          </td>
<td align="center">no</td>
<td align="center">yes</td>
<td align="center">yes</td>
<td align="center">yes</td>
</tr>
<tr>
<td></td>
<td>Mail aggregation, scheduled sending, etc.  </td>
<td align="center">no</td>
<td align="center">no</td>
<td align="center">yes</td>
<td align="center">limited</td>
</tr>
<tr>
<td></td>
<td>Control over SMTP requests throttle        </td>
<td align="center">no</td>
<td align="center">limited</td>
<td align="center">limited</td>
<td align="center">yes</td>
</tr>
<tr>
<td></td>
<td>Redelivery policy, do not lost messages if SMTP is down </td>
<td align="center">no</td>
<td align="center">no</td>
<td align="center">limited</td>
<td align="center">yes</td>
</tr>
<tr>
<td></td>
<td>Monitoring                                 </td>
<td align="center">no</td>
<td align="center">no</td>
<td align="center">yes</td>
<td align="center">yes</td>
</tr>
</tbody>
</table>


<p>I would start with &ldquo;Database Queue&rdquo; approach, at least if JMS is not already used in the project or you do not have to send thousands of emails.
&ldquo;Direct&rdquo; method is not an option at all IMHO.</p>

<p>Separate part of the subject is to how to create email body. In most situation
I used some template engine, like <em>Freemarker</em> or <em>Thymeleaf</em>. The
template can be defined as internal WAR resource or can be loaded from
database if the template needs to be adjusted on runtime.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DDD Architecture Summary]]></title>
    <link href="http://mkuthan.github.io/blog/2013/11/04/ddd-architecture-summary/"/>
    <updated>2013-11-04T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2013/11/04/ddd-architecture-summary</id>
    <content type="html"><![CDATA[<p>In this blog post you can find my general rules for implementing system using <em>Domain Driven Design</em>. Do not use them
blindly but it is good starting point for DDD practitioners.</p>

<h2><a name="bc"></a>Bounded Context</h2>

<ul>
<li>Separate bounded context for each important module of the application (important from business partner perspective).</li>
<li>Independent of each other (if feasible).</li>
<li>For monolithic application separate <em>Spring Framework</em> context for each bounded context, e.g: <code>applicationContext-domain-crm.xml</code>,
<code>applicationContext-domain-shipping.xml</code>, etc.</li>
<li>CRUD like bounded contexts (user management, dictionaries, etc.) should be implemented as <em>Anemic Domain Model</em>.</li>
</ul>


<h2><a name="domain"></a>Domain</h2>

<ul>
<li>Place for application business logic.</li>
<li>Must be independent of the technical complexity, move technical complexity into <a href="#infrastructure">infrastructure</a>.</li>
<li>Must be independent of the particular presentation technology, move presentation related stuff into <a href="#web">web</a>.</li>
<li>Internal package structure must reflect business concepts (<a href="#bc">bounded contexts</a>), e.g: <code>crm</code>, <code>shipping</code>, <code>sales</code>,
<code>shared</code>, etc.</li>
</ul>


<h2><a name="dm"></a> Domain Model</h2>

<ul>
<li>Rich model, place for: entities, domain services, factories, strategies, specifications, etc.</li>
<li>Best object oriented practices applied (SOLID, GRASP).</li>
<li>Unit tested heavily (with mocks in the last resort).</li>
<li>Unit tests executed concurrently (on method or class level).</li>
<li>Meaningful names for domain services e.g: <code>RebateCalculator</code>, <code>PermissionChecker</code>, not <code>RebateManager</code> or
<code>SecurityService</code>.</li>
<li>Domain services dependencies are injected by constructor.</li>
<li>Having more than 2~3 dependencies is suspicious.</li>
<li>Entities are not managed by containers.</li>
<li>Aggregate root entities are domain events publishers (events collectors).</li>
<li>Aggregates in single bounded context might be strongly referenced (navigation across objects tree).</li>
<li>Aggregates from different bounded contexts are referenced by business keys (if feasible).</li>
<li>No security, no transactions, no aspects, no magic, only plain old Java.</li>
<li>Interfaces for domain services when the service is provided by <a href="#infrastructure">infrastructure</a>.</li>
<li>No interfaces for domain services implemented in the domain model itself.</li>
</ul>


<h2><a name="as"></a>Application Services</h2>

<ul>
<li>Orchestrator and facade for actors under Model.</li>
<li>Place for security handling.</li>
<li>Place for transactions handling.</li>
<li>Must not deliver any business logic, move business logic into <a href="#dm">domain model</a>. Almost no conditionals and loops.</li>
<li>Implemented as transactional script.</li>
<li>No unit tests.</li>
<li>Acceptance tests executed against this layer.</li>
<li>Cglib proxied, proxy must be serialized by session scoped beans in <a href="#web">web</a> layer.</li>
<li>Dependencies are injected on field level (private fields).</li>
<li>Ten or more dependencies for single application service is not a problem.</li>
<li>Application services are also domain event listeners.</li>
<li>Always stateless.</li>
<li>No interfaces, just implementation.</li>
</ul>


<h2><a name="ab"></a>Application Bootstrap</h2>

<ul>
<li>Initial application data.</li>
<li>Loaded during application startup (fired by <code>BootstrapEvent</code>) if application storage is empty.</li>
<li>Loading order is defined with Spring <code>Ordered</code> interface.</li>
<li>Data is loaded within Model API.</li>
<li>Data might be loaded within <a href="#as">application services</a>, e.g: load sample Excel when application is integrated with
external world this way.</li>
<li>No tests, bootstrap is tested during application startup on daily basis.</li>
</ul>


<h2><a name="infrastructure"></a>Infrastructure</h2>

<ul>
<li>Place for technical services</li>
<li>Must not deliver any business logic, move business logic into <a href="#domain">domain</a>.</li>
<li>Internal package structure must reflect technical concepts, e.g: <code>~infrastructure.jpa</code>, <code>~infrastructure.jms</code>,
<code>~infrastructure.jsf</code>, <code>~infrastructure.freemarker</code>, <code>~infrastructure.jackson</code>, etc.</li>
<li>Shared for all bounded context of the application. For more complex applications, separate technical services e.g:
<code>~infrastructure.jpa.crm</code>, <code>~infrastructure.jpa.shipping</code>, etc.</li>
<li>Class names must reflect technical concepts, e.g.: <code>JpaCustomerRepository</code>, <code>JaksonJsonSerializer</code>,
not <code>CustomerRepositoryImpl</code>, <code>JsonSerializerImpl</code>.</li>
<li>Integration tested heavily (with <em>Spring Framework</em> context loaded).</li>
<li>Integration tests executed by single thread.</li>
<li>Test execution separated from unit tests within test groups.</li>
<li>Separate <em>Spring Framework</em> context for each technical concept, e.g: <code>applicationContext-infrastructure-jpa.xml</code>,
<code>applicationContext-infrastructure-jms.xml</code>, etc.</li>
<li>Separate and independent Spring test context for each technical module, e.g: <code>testContext-jpa.xml</code>,
<code>testContext-jms.xml</code>, etc.</li>
</ul>


<h2><a name="web"></a>Web</h2>

<ul>
<li>Client specific facade (REST, MVC, JSF, etc.)</li>
<li>Place for UI logic (not applicable for JavaScript client and REST)</li>
<li>Delegates requests to <a href="#as">application services</a></li>
<li>No transactions, no method level security, move security and transactions to <a href="#as">application services</a>.</li>
<li>No business logic, move business logic into <a href="#domain">domain</a>.</li>
<li>Tested with mocked application services.</li>
<li>Tested with loaded spring context for MVC controllers (if applicable).</li>
<li>Serializable session scoped beans (to be safe all beans in this module should be <code>java.io.Serializable</code>).</li>
<li>Internal package structure must reflect UI organization structure, it might be similar to project <em>sitemap</em>.</li>
<li>Top level package might reflect technology or architecture e.g: <code>presentation</code>, <code>rest</code>, <code>mvc</code>, <code>jsf</code>, etc.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Development Environment Setup]]></title>
    <link href="http://mkuthan.github.io/blog/2013/10/09/development-environment-setup/"/>
    <updated>2013-10-09T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2013/10/09/development-environment-setup</id>
    <content type="html"><![CDATA[<p>This document is a manual how to configure flexible development environment for <em>Java</em>, <em>JavaScript</em>, <em>Ruby</em> and <em>Python</em> &ndash; my primary set of tools.
Even if the runtimes installation with <code>apt-get</code> seems to be a trivial task, there is limited control over installed version of the runtime.
The goal is to configure environment where you can easily change <em>Java</em>, <em>Ruby</em> , <em>node.js</em> and <em>python</em> versions.
Where you can define the runtime version on project level.</p>

<p>The most convenient way to configure and manage runtimes is to use environment managers.
Environment manager is nothing more than shell script, the script intercepts executed commands using shim executables injected into your <code>PATH</code>.
There are two flavours of the environment managers: <code>rvm</code> and <code>rbenv</code> like.
I prefer the second one, it is less obtrusive and follows general unix principle: &ldquo;do one thing and do it well&rdquo;.</p>

<p>Let&rsquo;s start and install environment managers (for <em>Java</em>, <em>Ruby</em>, <em>node.js</em> and <em>Python</em>) into your home directory:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">git clone https://github.com/gcuisinier/jenv.git ~/.jenv</span>
</span><span class='line'><span class="go">git clone https://github.com/sstephenson/rbenv.git ~/.rbenv</span>
</span><span class='line'><span class="go">git clone https://github.com/OiNutter/nodenv.git ~/.nodenv</span>
</span><span class='line'><span class="go">git clone https://github.com/yyuu/pyenv.git .pyenv</span>
</span></code></pre></td></tr></table></div></figure>


<p>For <code>rbenv</code> and <code>nodenv</code> you can install plugins that provide <code>rbenv install</code> and <code>nodenv install</code> commands to compile and install runtimes automatically.
For Java you have to download and install JVM manually.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">$</span>git clone https://github.com/sstephenson/ruby-build.git ~/.rbenv/plugins/ruby-build
</span><span class='line'><span class="gp">$</span>git clone https://github.com/OiNutter/node-build.git ~/.nodenv/plugins/node-build
</span></code></pre></td></tr></table></div></figure>


<p>Add environment managers to the <code>PATH</code> variable and initialize them to get command auto completion.
Append the following snippet at the end of <code>.bashrc</code> (or <code>.bash_profile</code> on Mac) file.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;$HOME/.jenv/bin:$PATH&quot;</span>
</span><span class='line'><span class="nb">eval</span> <span class="s2">&quot;$(jenv init -)&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;$HOME/.rbenv/bin:$PATH&quot;</span>
</span><span class='line'><span class="nb">eval</span> <span class="s2">&quot;$(rbenv init -)&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;$HOME/.nodenv/bin:$PATH&quot;</span>
</span><span class='line'><span class="nb">eval</span> <span class="s2">&quot;$(nodenv init -)&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;$HOME/.pyenv/bin:$PATH&quot;</span>
</span><span class='line'><span class="nb">eval</span> <span class="s2">&quot;$(pyenv init -)&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Install runtimes using environment managers (Java needs to be installed manually):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">$</span>jenv add /path/to/already/installed/jdk
</span><span class='line'><span class="gp">$</span>rbenv install 1.9.3-p448
</span><span class='line'><span class="gp">$</span>nodenv install 0.10.12
</span><span class='line'><span class="gp">$</span>pyenv install 3.4.1
</span></code></pre></td></tr></table></div></figure>


<p>Install build tools (<em>maven</em>, <em>gradle</em>, <em>sbt</em>, etc.), create symbolic links, and configure <code>PATH</code> in <code>.profile</code> file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">APPS</span><span class="o">=</span><span class="s2">&quot;$HOME/apps&quot;</span>
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;$APPS/apache-maven/bin:$APPS/gradle/bin:$APPS/sbt/bin:$PATH&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Make build tools <em>jenv</em> aware:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">$</span>jenv <span class="nb">enable</span>-plugin maven
</span><span class='line'><span class="gp">$</span>jenv <span class="nb">enable</span>-plugin gradle
</span><span class='line'><span class="gp">$</span>jenv <span class="nb">enable</span>-plugin sbt
</span></code></pre></td></tr></table></div></figure>


<p>Finally add shell helper functions for JVM configuration to the <code>.profile</code> file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="k">function </span>jdebug_set<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options <span class="s2">&quot;$JENV_OPTIONS -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,suspend=n&quot;</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>jdebug_unset<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options --unset
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>gc_set<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options <span class="s2">&quot;$JENV_OPTIONS -XX:+PrintGCDetails -Xloggc:gc.log&quot;</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>gc_unset<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options --unset
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>jrebel_set<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options <span class="s2">&quot;$JENV_OPTIONS -javaagent:$APPS/jrebel/jrebel.jar -noverify&quot;</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>jrebel_unset<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options --unset
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>jprofiler_set<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options <span class="s2">&quot;$JENV_OPTIONS -javaagent:$APPS/jprofiler/bin/agent.jar&quot;</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>jprofiler_unset<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    jenv shell-options --unset
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The last step is to read environment managers manual. As long as all four managers are very similar it should not take more than one evening.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GitFlow Step by Step]]></title>
    <link href="http://mkuthan.github.io/blog/2013/07/21/gitflow-step-by-step/"/>
    <updated>2013-07-21T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2013/07/21/gitflow-step-by-step</id>
    <content type="html"><![CDATA[<p>Git Flow is a mainstream process for branch per feature development. Git Flow  is the best method I&rsquo;ve found for
managing project developed by small to medium project teams. Before you start reading this post you should read two
mandatory lectures:</p>

<p><a href="https://www.atlassian.com/git/workflows#!workflow-gitflow">Git Workflows by Atlassian</a></p>

<p><a href="https://bitbucket.org/atlassian/jgit-flow/wiki/Home">Maven JGit-Flow Plugin</a></p>

<p>This blog post is a step by step instruction how to use Git Flow together with Maven build tool, continuous integration
server (e.g: Bamboo) and bug tracker (e.g: JIRA). If you are interested in how to automate the whole process, watch this
<a href="https://www.youtube.com/watch?v=YIgX67c-2hQ">Flow with Bamboo</a> video. But I really recommend to start using Git Flow
with pure git commands, when you understand the concept move to Git Flow, and then automate everything eventually.</p>

<h2>Start feature branch</h2>

<ol>
<li>Assign JIRA task to you.</li>
<li>Move JIRA tasks from &ldquo;To Do&rdquo; to &ldquo;In Progress&rdquo;.</li>
<li><p>Create feature branch for the JIRA user story (if it is a first task of the user story).
Feature branch must reflect JIRA issue number and have meaningful name, e.g: <em>PROJ-01_user_registration</em>.</p>

<pre><code>  mvn jgitflow:feature-start
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>New local feature branch <em>feature/PROJ-01_user_registration</em> is created.</li>
</ul>
</li>
<li><p>Optionally push feature branch into remote repository.</p>

<pre><code> git push origin feature/PROJ-01_user_registration
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>The feature branch is pushed into remote repository.</li>
<li>New Bamboo build plan is created for the feature branch.</li>
</ul>
</li>
</ol>


<h2>Checkout the feature branch</h2>

<ol>
<li><p>Checkout the feature branch created by other developer (e.g for code review).</p>

<pre><code> git checkout feature/PROJ-01_user_registration
</code></pre></li>
</ol>


<h2>Work on the feature branch</h2>

<ol>
<li><p>Periodically push changes to the remote repository.</p>

<pre><code> git push origin feature/PROJ-01_user_registration
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>Bamboo build plan for feature branch is green.</li>
</ul>
</li>
</ol>


<h2>Finish feature branch</h2>

<ol>
<li><p>Ensure your local develop branch is up to date.</p>

<pre><code> git checkout develop
 git pull origin develop
</code></pre></li>
<li><p>To avoid conflicts during finishing feature branch, ensure that all changes from develop are merged to the feature branch.</p>

<pre><code> git checkout feature/PROJ-01_user_registration
 git pull origin develop
</code></pre></li>
<li><p>Resolve all conflicts (if any) and commit changes.</p>

<pre><code> git commit -a -m "Conflicts resolved"
</code></pre></li>
<li><p>Finish the feature.</p>

<pre><code> mvn jgitflow:feature-finish
</code></pre></li>
<li><p>Push changes from develop into remote repository</p>

<pre><code> git push origin develop
</code></pre></li>
<li><p>Move JIRA task to &ldquo;Done&rdquo; category.</p></li>
<li><p>Verify that:</p>

<ul>
<li>Feature branch is merged into develop branch.</li>
<li>Local feature branch is removed.</li>
<li>Bamboo build plan for develop is green.</li>
</ul>
</li>
</ol>


<h2>Start release branch</h2>

<ol>
<li><p>Create release branch.</p>

<pre><code> mvn jgitflow:release-start
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>New local release branch release/version is created.</li>
<li>Work with release branch</li>
</ul>
</li>
</ol>


<h2>Work with release branch</h2>

<ol>
<li><p>Clean the database (Database).</p></li>
<li><p>Run the application (Running Application) and perform exploratory tests.</p></li>
<li><p>Fix all issues (if any).</p></li>
<li><p>Commit changes to the release branch.</p>

<pre><code> git commit -a -m "Fixes release candidate"
</code></pre></li>
</ol>


<h2>Finish release branch</h2>

<ol>
<li><p>Make sure your local master branch is up to date</p>

<pre><code> git fetch origin master
</code></pre></li>
<li><p>Finish the release branch</p>

<pre><code> mvn jgitflow:release-finish
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>Release branch is merged into local develop branch.</li>
<li>Project version is updated in local develop branch.</li>
</ul>
</li>
<li><p>Push changes from develop into remote repository</p>

<pre><code> git push origin develop
</code></pre></li>
<li><p>Checkout master</p>

<pre><code> git checkout master
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>Release branch is merged into local master branch.</li>
<li>Project version is updated in local master branch.</li>
</ul>
</li>
<li><p>Push changes from master into remote repository</p>

<pre><code> git push --tags origin master
</code></pre></li>
<li><p>Verify that:</p>

<ul>
<li>Release tag is pushed to the remote repository.</li>
<li>Build plan on master is green and new version is deployed.</li>
</ul>
</li>
<li><p>Delete released feature branches from remote repository.</p>

<pre><code> git push origin :feature/PROJ-01_user_registration
</code></pre></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Document Your Professional Experiences]]></title>
    <link href="http://mkuthan.github.io/blog/2013/03/21/how-to-document-your-professional/"/>
    <updated>2013-03-21T00:00:00+00:00</updated>
    <id>http://mkuthan.github.io/blog/2013/03/21/how-to-document-your-professional</id>
    <content type="html"><![CDATA[<p>Have you considered what is important for prospective employer?
What is the most valuable information source about your professional experience?
How to document that you are an expert in software engineering?</p>

<p>Below you can find some of my tricks:</p>

<ul>
<li>Write a blog, teaching is the best learning method :&ndash;)</li>
<li>Write an article to the software magazine</li>
<li>Contribute to open source project(s) like <a href="http://mytourbook.sourceforge.net/mytourbook/index.php/contributors">MyTourbook</a></li>
<li>Report <a href="https://jira.spring.io/issues/?jql=creator%20in%20(mkuthan)">bugs</a> to the open source project(s), send pull requests and patches.</li>
<li>Manage your profile @ <a href="https://github.com/mkuthan/">GitHub</a></li>
<li>Manage your profile @ StackOverflow</li>
<li>Manage your profile @ <a href="https://www.goodreads.com/mkuthan">Goodreads</a></li>
<li>Manage your profile @ <a href="http://pl.linkedin.com/in/marcinkuthan/">LinkedIn</a></li>
<li>Post to discussion <a href="http://maven.40175.n5.nabble.com/template/NamlServlet.jtp?macro=user_nodes&amp;user=146149">groups</a>, be helpful for others</li>
<li>Be active in local software groups (e.g JUG)</li>
<li>Attend university lectures (@ <a href="https://www.coursera.org/user/i/3d908cbf919e14af793fae9a5fc732f4">Coursera</a>), 100% free</li>
</ul>


<p>To be honest, I have done only few of them for myself :&ndash;(</p>
]]></content>
  </entry>
  
</feed>
